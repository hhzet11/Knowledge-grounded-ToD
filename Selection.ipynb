{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3UTEUDN7eZDRyhH/0Z1gt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cznLEo2n0Rw_","executionInfo":{"status":"ok","timestamp":1682573700259,"user_tz":-540,"elapsed":51511,"user":{"displayName":"이하영","userId":"16656722516517244964"}},"outputId":"3d42a825-570d-4ba2-fc53-593754376a1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!cd \"/content/drive/My Drive/dstc11-track5/\""],"metadata":{"id":"nQZ4OdZk0V_9","executionInfo":{"status":"ok","timestamp":1682573701154,"user_tz":-540,"elapsed":901,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install nltk==3.6.6\n","!pip install numpy==1.22.0\n","!pip install rouge_score==0.1.2\n","!pip install scikit_learn==1.1.1\n","!pip install sentencepiece==0.1.96\n","!pip install strsimpy==0.2.1\n","!pip install summ_eval==0.892\n","!pip install tensorboard==2.9.0\n","!pip install tensorboardX==2.5\n","!pip install torch==1.13.1\n","!pip install tqdm==4.62.3\n","!pip install transformers==4.20.1\n","!python -m nltk.downloader 'punkt'\n","!python -m nltk.downloader 'wordnet'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtBGQKfJ2aHo","executionInfo":{"status":"ok","timestamp":1682573932505,"user_tz":-540,"elapsed":231353,"user":{"displayName":"이하영","userId":"16656722516517244964"}},"outputId":"a94cfd2f-c877-431c-a6b5-c7ef641f3b09"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.6.6\n","  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk==3.6.6) (2022.10.31)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk==3.6.6) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk==3.6.6) (4.65.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk==3.6.6) (8.1.3)\n","Installing collected packages: nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.8.1\n","    Uninstalling nltk-3.8.1:\n","      Successfully uninstalled nltk-3.8.1\n","Successfully installed nltk-3.6.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numpy==1.22.0\n","  Downloading numpy-1.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.22.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge_score==0.1.2\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score==0.1.2) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score==0.1.2) (3.6.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score==0.1.2) (1.22.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score==0.1.2) (1.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score==0.1.2) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score==0.1.2) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score==0.1.2) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score==0.1.2) (4.65.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=3c6c144d23a46499a0fb3d7a514646c6aefd633ff49f97d1effc3dbec383f414\n","  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit_learn==1.1.1\n","  Downloading scikit_learn-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.1.1) (3.1.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.1.1) (1.22.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.1.1) (1.10.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn==1.1.1) (1.2.0)\n","Installing collected packages: scikit_learn\n","  Attempting uninstall: scikit_learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scikit_learn-1.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting strsimpy==0.2.1\n","  Downloading strsimpy-0.2.1-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: strsimpy\n","Successfully installed strsimpy-0.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting summ_eval==0.892\n","  Downloading summ_eval-0.892-py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.9/111.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (3.1)\n","Collecting moverscore\n","  Downloading moverscore-1.0.3.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (8.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (1.16.0)\n","Collecting pyemd==0.5.1\n","  Downloading pyemd-0.5.1.tar.gz (91 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/91.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (3.5.2)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (1.22.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (0.29.34)\n","Collecting transformers>=2.2.0\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (0.5.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (5.9.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (3.6.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from summ_eval==0.892) (1.10.1)\n","Collecting blanc\n","  Downloading blanc-0.3.0-py3-none-any.whl (29 kB)\n","Collecting stanza\n","  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (1.1.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (2.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (4.65.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (2.4.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (1.0.4)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (0.7.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (3.1.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (8.1.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (67.7.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (6.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (1.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (1.10.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (3.0.12)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (23.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (3.0.8)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (0.10.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (2.27.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2.0->summ_eval==0.892) (3.3.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->summ_eval==0.892) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->summ_eval==0.892) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.2.0->summ_eval==0.892) (2022.10.31)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from bert-score->summ_eval==0.892) (3.7.1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from bert-score->summ_eval==0.892) (2.0.0+cu118)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from bert-score->summ_eval==0.892) (1.5.3)\n","Collecting torch>=1.0.0\n","  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->summ_eval==0.892) (1.2.0)\n","Collecting typing\n","  Downloading typing-3.7.4.3.tar.gz (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Collecting boto3\n","  Downloading boto3-1.26.121-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu->summ_eval==0.892) (4.9.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu->summ_eval==0.892) (0.8.10)\n","Collecting emoji\n","  Downloading emoji-2.2.0.tar.gz (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from stanza->summ_eval==0.892) (3.20.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.2.0->summ_eval==0.892) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.2.0->summ_eval==0.892) (4.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->bert-score->summ_eval==0.892) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->bert-score->summ_eval==0.892) (2022.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->summ_eval==0.892) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->summ_eval==0.892) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->summ_eval==0.892) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->summ_eval==0.892) (1.26.15)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2.0->summ_eval==0.892) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2.0->summ_eval==0.892) (0.7.9)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score->summ_eval==0.892) (0.40.0)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.30.0,>=1.29.121\n","  Downloading botocore-1.29.121-py3-none-any.whl (10.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=2.2.0->summ_eval==0.892) (2.1.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (4.39.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (8.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (1.4.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (5.12.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score->summ_eval==0.892) (1.0.7)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->bert-score->summ_eval==0.892) (3.15.0)\n","Building wheels for collected packages: pyemd, moverscore, sacremoses, emoji, typing\n","  Building wheel for pyemd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyemd: filename=pyemd-0.5.1-cp39-cp39-linux_x86_64.whl size=541053 sha256=3832f34393feba4be8fe616f4105a5a200be158038b256d2ed7703012997f093\n","  Stored in directory: /root/.cache/pip/wheels/64/bf/3e/0859be9a0108fc932a29b943792dcafb3b979555cf1bb5add6\n","  Building wheel for moverscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for moverscore: filename=moverscore-1.0.3-py3-none-any.whl size=7963 sha256=042a803ea203ec8df5dc7dcf88aa8c5218ad860cf89a2d16d3fe5efcf8a0b943\n","  Stored in directory: /root/.cache/pip/wheels/ec/c2/18/826e61ab6e3989b946b3dea345711552870ce9096209c9378c\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=c0fcc7c842f7025ae23168243bf5fd1ded64e40b2cede0311c3be55e2eaecb99\n","  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=286e0824db33385ed0b2a0323c4a20ee190303b2a9d4a47251752c565c33fb72\n","  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n","  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26321 sha256=cf44be08eebe8636d52055b1b77da658da2d4501531bbc814bd8bcbece4213b9\n","  Stored in directory: /root/.cache/pip/wheels/fa/17/1f/332799f975d1b2d7f9b3f33bbccf65031e794717d24432caee\n","Successfully built pyemd moverscore sacremoses emoji typing\n","Installing collected packages: tokenizers, typing, sacremoses, pyemd, portalocker, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, jmespath, emoji, colorama, sacrebleu, nvidia-cudnn-cu11, moverscore, huggingface-hub, botocore, transformers, torch, s3transfer, stanza, boto3, blanc, bert-score, pytorch-pretrained-bert, summ_eval\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.0+cu118\n","    Uninstalling torch-2.0.0+cu118:\n","      Successfully uninstalled torch-2.0.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n","torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n","torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bert-score-0.3.13 blanc-0.3.0 boto3-1.26.121 botocore-1.29.121 colorama-0.4.6 emoji-2.2.0 huggingface-hub-0.14.1 jmespath-1.0.1 moverscore-1.0.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.7.0 pyemd-0.5.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 sacrebleu-2.3.1 sacremoses-0.0.53 stanza-1.5.0 summ_eval-0.892 tokenizers-0.13.3 torch-1.13.1 transformers-4.28.1 typing-3.7.4.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard==2.9.0\n","  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (0.40.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (2.27.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (1.4.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (2.2.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (67.7.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (2.17.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (1.54.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (3.4.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (3.20.3)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard==2.9.0) (1.22.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (1.16.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard==2.9.0) (6.6.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard==2.9.0) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.9.0) (3.15.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.0) (3.2.2)\n","Installing collected packages: tensorboard-data-server, google-auth-oauthlib, tensorboard\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 tensorboard-2.9.0 tensorboard-data-server-0.6.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX==2.5\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX==2.5) (3.20.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX==2.5) (1.22.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from tensorboardX==2.5) (1.16.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (1.13.1)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (4.5.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1) (8.5.0.96)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.40.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tqdm==4.62.3\n","  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.65.0\n","    Uninstalling tqdm-4.65.0:\n","      Successfully uninstalled tqdm-4.65.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tqdm-4.62.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.20.1\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (2.27.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (2022.10.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (3.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (1.22.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.20.1) (0.14.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.20.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.20.1) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.20.1) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.20.1) (3.4)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.28.1\n","    Uninstalling transformers-4.28.1:\n","      Successfully uninstalled transformers-4.28.1\n","Successfully installed tokenizers-0.12.1 transformers-4.20.1\n","/usr/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","/usr/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n","  warn(RuntimeWarning(msg))\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import re\n","import logging\n","import random\n","import copy\n","\n","from collections import defaultdict\n","from itertools import chain\n","\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","from tqdm import tqdm\n","\n","logger = logging.getLogger(__name__)\n","\n","SPECIAL_TOKENS = {\n","    \"additional_special_tokens\": [\"<speaker1>\", \"<speaker2>\", \"<knowledge_sep>\", \"<knowledge_tag>\"],\n","}"],"metadata":{"id":"aMh-Ghmq0aMB","executionInfo":{"status":"ok","timestamp":1682573935470,"user_tz":-540,"elapsed":2971,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# utils/data"],"metadata":{"id":"pNbDZOt701MO"}},{"cell_type":"code","source":["RE_ART = re.compile(r'\\b(a|an|the)\\b')\n","RE_PUNC = re.compile(r'[!\"#$%&()*+,-./:;<=>?@\\[\\]\\\\^`{|}~_\\']')\n","\n","def remove_articles(_text):\n","    return RE_ART.sub(' ', _text)\n","\n","def white_space_fix(_text):\n","    return ' '.join(_text.split())\n","\n","def remove_punc(_text):\n","    return RE_PUNC.sub(' ', _text)  # convert punctuation to spaces\n","\n","def lower(_text):\n","    return _text.lower()\n","\n","def normalize(text):\n","    \"\"\"Lower text and remove punctuation, articles and extra whitespace. \"\"\"\n","    return white_space_fix(remove_articles(remove_punc(lower(text))))\n","\n","def pad_ids(arrays, padding, max_length=-1):\n","    if max_length < 0:\n","        max_length = max(list(map(len, arrays)))\n","\n","    arrays = [\n","        array + [padding] * (max_length - len(array))\n","        for array in arrays\n","    ]\n","\n","    return arrays\n","\n","\n","def truncate_sequences(sequences, max_length):\n","    words_to_cut = sum(list(map(len, sequences))) - max_length\n","    if words_to_cut <= 0:\n","        return sequences\n","\n","    while words_to_cut > len(sequences[0]):\n","        words_to_cut -= len(sequences[0])\n","        sequences = sequences[1:]\n","\n","    sequences[0] = sequences[0][words_to_cut:]\n","    return sequences\n"],"metadata":{"id":"usPEMjI_0eVD","executionInfo":{"status":"ok","timestamp":1682573935471,"user_tz":-540,"elapsed":7,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def write_selection_preds(dataset_walker, output_file, data_infos, sorted_pred_ids, topk=None, all_preds=None):\n","    \"\"\" Write results of knowledge selection to output_file \"\"\"\n","    assert topk is None or topk > 0, f\"topK must be set as None or a positive integer, but it is set as {topk}\"\n","    # Flatten the data_infos\n","    data_infos = [\n","        {\n","            \"dialog_id\": info[\"dialog_ids\"][i],\n","            \"candidate_keys\": info[\"candidate_keys\"][i],\n","        }\n","        for info in data_infos\n","        for i in range(len(info[\"dialog_ids\"]))\n","    ]\n","\n","    labels = [label for log, label in dataset_walker]\n","    new_labels = [{\"target\": False}] * len(dataset_walker)\n","    # Update the dialogs with selected knowledge\n","    for info, sorted_pred_id, all_pred in zip(data_infos, sorted_pred_ids, all_preds):\n","        dialog_id = info[\"dialog_id\"]\n","        candidate_keys = info[\"candidate_keys\"]\n","\n","        snippets = []\n","        sorted_pred_id_iter = sorted_pred_id[:topk] if topk is not None else sorted_pred_id\n","        for pred_id in sorted_pred_id_iter:\n","            selected_cand = candidate_keys[pred_id]\n","            domain, entity_id, doc_id = selected_cand.split(\"__\")\n","            snippet = {\n","                \"domain\": domain,\n","                \"entity_id\": \"*\" if entity_id == \"*\" else int(entity_id),\n","                \"doc_type\": 'review' if '-' in doc_id else 'faq',\n","                \"doc_id\": doc_id,\n","            }\n","            if snippet['doc_type'] == 'review':\n","                doc_id, sent_id = doc_id.split('-')\n","                snippet['doc_id'], snippet['sent_id'] = int(doc_id), int(sent_id)\n","            else:\n","                snippet['doc_id'] = int(snippet['doc_id'])\n","            snippets.append(snippet)\n","\n","        assert len(candidate_keys) == len(all_pred)\n","        new_label = {\"target\": True, \"knowledge\": snippets}\n","        label = labels[dialog_id]\n","        if label is None:\n","            label = new_label\n","        else:\n","            label = label.copy()\n","            if \"response_tokenized\" in label:\n","                label.pop(\"response_tokenized\")\n","            label.update(new_label)\n","        new_labels[dialog_id] = label\n","\n","    if os.path.dirname(output_file) and not os.path.exists(os.path.dirname(output_file)):\n","        os.makedirs(os.path.dirname(output_file))\n","\n","    with open(output_file, \"w\") as jsonfile:\n","        logger.info(\"Writing predictions to {}\".format(output_file))\n","        json.dump(new_labels, jsonfile, indent=2)"],"metadata":{"id":"9aYke4jV0z1h","executionInfo":{"status":"ok","timestamp":1682573935471,"user_tz":-540,"elapsed":6,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# scripts"],"metadata":{"id":"xRnqFkXg1EgL"}},{"cell_type":"code","source":["#scripts/dataset_walker\n","class DatasetWalker(object):\n","    def __init__(self, dataset, dataroot, labels=False, labels_file=None, incl_knowledge=False):\n","        path = os.path.join(os.path.abspath(dataroot))\n","            \n","        if dataset not in ['train', 'val']:\n","            raise ValueError('Wrong dataset name: %s' % (dataset))\n","\n","        logs_file = os.path.join(path, dataset, 'logs.json')\n","        with open(logs_file, 'r') as f:\n","            self.logs = json.load(f)\n","\n","        self.labels = None\n","\n","        if labels is True:\n","            if labels_file is None:\n","                labels_file = os.path.join(path, dataset, 'labels.json')\n","\n","            with open(labels_file, 'r') as f:\n","                self.labels = json.load(f)\n","\n","        self._incl_knowledge = incl_knowledge\n","        if self._incl_knowledge is True:\n","            # knowledge_reader 수정\n","            #self._knowledge = knowledge_reader(dataroot)\n","            self._knowledge = KnowledgeReader(dataroot)\n","\n","    def __iter__(self):\n","        if self.labels is not None:\n","            for log, label in zip(self.logs, self.labels):\n","                if self._incl_knowledge is True and label['target'] is True:\n","                    for idx, snippet in enumerate(label['knowledge']):\n","                        domain = snippet['domain']\n","                        entity_id = snippet['entity_id']\n","                        doc_type = snippet['doc_type']\n","                        doc_id = snippet['doc_id']\n","\n","                        if doc_type == 'review':\n","                            sent_id = snippet['sent_id']                            \n","                            sent = self._knowledge.get_review_sent(domain, entity_id, doc_id, sent_id)\n","                            label['knowledge'][idx]['sent'] = sent\n","                            \n","                        elif doc_type == 'faq':\n","                            doc = self._knowledge.get_faq_doc(domain, entity_id, doc_id)\n","                            question = doc['question']\n","                            answer = doc['answer']\n","\n","                            label['knowledge'][idx]['question'] = question\n","                            label['knowledge'][idx]['answer'] = answer\n","                \n","                yield(log, label)\n","        else:\n","            for log in self.logs:\n","                yield(log, None)\n","\n","    def __len__(self, ):\n","        return len(self.logs)"],"metadata":{"id":"lM79Qx7R04m6","executionInfo":{"status":"ok","timestamp":1682573935471,"user_tz":-540,"elapsed":5,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#scripts/knowledge_reader\n","class KnowledgeReader(object):\n","    def __init__(self, dataroot, knowledge_file='knowledge.json'):\n","        path = os.path.join(os.path.abspath(dataroot))\n","\n","        with open(os.path.join(path, knowledge_file), 'r') as f:\n","            self.knowledge = json.load(f)\n","\n","    def get_domain_list(self):\n","        return list(self.knowledge.keys())\n","\n","    def get_entity_list(self, domain):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name\")\n","\n","        entity_ids = []\n","        for entity_id in self.knowledge[domain].keys():\n","            entity_ids.append(int(entity_id))\n","\n","        result = []\n","        for entity_id in sorted(entity_ids):\n","            entity_name = self.knowledge[domain][str(entity_id)]['name']\n","            result.append({'id': entity_id, 'name': entity_name})\n","\n","        return result\n","\n","    def get_entity_name(self, domain, entity_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","\n","        result = self.knowledge[domain][str(entity_id)]['name'] or None\n","\n","        return result\n","\n","    def get_faq_doc_ids(self, domain, entity_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","        \n","        result = []\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","\n","        entity_obj = self.knowledge[domain][str(entity_id)]\n","        for doc_id, doc_obj in entity_obj['faqs'].items():\n","            result.append(doc_id)\n","\n","        return result\n","\n","    def get_faq_doc(self, domain, entity_id, doc_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","\n","        entity_name = self.get_entity_name(domain, entity_id)\n","\n","        if str(doc_id) not in self.knowledge[domain][str(entity_id)]['faqs']:\n","            raise ValueError(\"invalid doc id: %s\" % str(doc_id))\n","\n","        doc_obj = self.knowledge[domain][str(entity_id)]['faqs'][str(doc_id)]\n","        result = {'domain': domain, 'entity_id': entity_id, 'entity_name': entity_name, 'doc_id': doc_id, 'question': doc_obj['question'], 'answer': doc_obj['answer']}\n","\n","        return result\n","\n","    def get_review_doc_ids(self, domain, entity_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","\n","        result = []\n","        \n","        entity_obj = self.knowledge[domain][str(entity_id)]\n","        for doc_id, doc_obj in entity_obj['reviews'].items():\n","            result.append(doc_id)\n","\n","        return result\n","\n","    def get_review_doc(self, domain, entity_id, doc_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","\n","        entity_name = self.get_entity_name(domain, entity_id)\n","\n","        if str(doc_id) not in self.knowledge[domain][str(entity_id)]['reviews']:\n","            raise ValueError(\"invalid doc id: %s\" % str(doc_id))\n","        \n","        doc_obj = self.knowledge[domain][str(entity_id)]['reviews'][str(doc_id)]\n","        \n","        result = {'domain': domain, 'entity_id': entity_id, 'entity_name': entity_name, 'doc_id': doc_id, 'sentences': doc_obj['sentences']}\n","        if 'traveler_type' in doc_obj:\n","            result['traveler_type'] = doc_obj['traveler_type']\n","        \n","        if 'dishes' in doc_obj:\n","            result['dishes'] = doc_obj['dishes']\n","\n","        if 'drinks' in doc_obj:\n","            result['drinks'] = doc_obj['drinks']\n","\n","        return result\n","    \n","    def get_review_sent(self, domain, entity_id, doc_id, sent_id):\n","        if domain not in self.get_domain_list():\n","            raise ValueError(\"invalid domain name: %s\" % domain)\n","\n","        if str(entity_id) not in self.knowledge[domain]:\n","            raise ValueError(\"invalid entity id: %s\" % str(entity_id))\n","        \n","        if str(doc_id) not in self.knowledge[domain][str(entity_id)]['reviews']:\n","            raise ValueError(\"invalid doc id: %s\" % str(doc_id))\n","\n","        if str(sent_id) not in self.knowledge[domain][str(entity_id)]['reviews'][str(doc_id)]['sentences']:\n","            raise ValueError(\"invalid sentence id: %s\" % str(sent_id))\n","\n","        result = self.knowledge[domain][str(entity_id)]['reviews'][str(doc_id)]['sentences'][str(sent_id)]\n","\n","        return result"],"metadata":{"id":"9-Y_gsxJ0-xu","executionInfo":{"status":"ok","timestamp":1682573935471,"user_tz":-540,"elapsed":5,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# dataset"],"metadata":{"id":"p-YnSChc1Uji"}},{"cell_type":"code","source":["task = \"selection\"\n","dataroot = '/content/drive/MyDrive/dstc11-track5/data'\n","negative_sample_method = 'oracle'\n","knowledge_file = 'knowledge.json'\n","debug = 0\n","knowledge_max_tokens = 256\n","history_max_tokens = 256 \n","history_max_utterances = 1000000\n","n_candidates = 2\n","\n","class BaseDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, split_type, labels=True, labels_file=None):\n","        self.dataroot = dataroot\n","        self.tokenizer = tokenizer\n","        self.split_type = split_type\n","        self.task = task\n","        self.negative_sample_method = negative_sample_method\n","\n","        self.cls = self.tokenizer.cls_token_id\n","        self.sep = self.tokenizer.sep_token_id\n","        self.bos = self.tokenizer.bos_token_id\n","        self.eos = self.tokenizer.eos_token_id\n","        self.pad = self.tokenizer.pad_token_id\n","        self.SPECIAL_TOKENS = SPECIAL_TOKENS\n","\n","        self.speaker1, self.speaker2, self.knowledge_sep, self.knowledge_tag = self.tokenizer.convert_tokens_to_ids(\n","            self.SPECIAL_TOKENS[\"additional_special_tokens\"]\n","        )\n","        self.knowledge_sep_token = self.SPECIAL_TOKENS[\"additional_special_tokens\"][2]\n","        self.dataset_walker = DatasetWalker(split_type, labels=labels, dataroot=self.dataroot, labels_file=labels_file)\n","        self.dialogs = self._prepare_conversations()\n","        self.knowledge_reader = KnowledgeReader(self.dataroot, knowledge_file)\n","        self.snippets = self._prepare_knowledge()\n","        self._create_examples()\n","\n","        self.debug = debug\n","        self.knowledge_max_tokens = knowledge_max_tokens\n","        self.history_max_utterances = history_max_utterances\n","        self.history_max_tokens = history_max_tokens\n","        self.n_candidates = n_candidates\n","\n","\n","    def _prepare_conversations(self):\n","        \"\"\" Tokenize and encode the dialog data \"\"\"\n","        logger.info(\"Tokenize and encode the dialog data\")\n","        tokenized_dialogs = []\n","        for i, (log, label) in enumerate(tqdm(self.dataset_walker, disable=False, desc='tokenizing...')):\n","            dialog = {}\n","            dialog[\"id\"] = i\n","            dialog[\"log\"] = log\n","            if label is not None:\n","                if \"response\" in label:\n","                    label[\"response_tokenized\"] = self.tokenizer.convert_tokens_to_ids(\n","                        self.tokenizer.tokenize(label[\"response\"])\n","                    )\n","            dialog[\"label\"] = label\n","            tokenized_dialogs.append(dialog)\n","        return tokenized_dialogs\n","\n","    def _prepare_knowledge(self):\n","        \"\"\" Tokenize and encode the knowledge snippets \"\"\"\n","        self.knowledge_docs = self._get_snippet_list()\n","\n","        tokenized_snippets = defaultdict(dict)\n","        for snippet_id, snippet in enumerate(self.knowledge_docs):\n","            key = \"{}__{}__{}\".format(snippet[\"domain\"], str(snippet[\"entity_id\"]) or \"\", snippet[\"doc_id\"])\n","            knowledge = self._knowledge_to_string(snippet[\"doc\"], name=snippet[\"entity_name\"] or \"\")\n","\n","            tokenized_knowledge = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(knowledge))\n","            tokenized_snippets[key]['token_ids'] = tokenized_knowledge[:256] # knowledge_max_tokens : 256\n","        return tokenized_snippets\n","\n","    def _get_snippet_list(self):\n","        \"\"\" Get all knowledge snippets in the dataset \"\"\"\n","        result = []\n","        for domain in self.knowledge_reader.get_domain_list():\n","            for entity_id in self.knowledge_reader.knowledge[domain].keys():\n","                for review_doc_id in self.knowledge_reader.get_review_doc_ids(domain, entity_id):\n","                    review_doc = self.knowledge_reader.get_review_doc(domain, entity_id, review_doc_id)\n","                    for review_sent_id, review_sent in review_doc['sentences'].items():\n","                        result.append(\n","                            {'domain': domain, 'entity_id': entity_id, 'entity_name': review_doc['entity_name'],\n","                             'doc_id': f\"{review_doc_id}-{review_sent_id}\",\n","                             'doc': {'body': review_sent}})\n","                for faq_doc_id in self.knowledge_reader.get_faq_doc_ids(domain, entity_id):\n","                    faq_doc = self.knowledge_reader.get_faq_doc(domain, entity_id, faq_doc_id)\n","                    result.append({'domain': domain, 'entity_id': entity_id, 'entity_name': faq_doc['entity_name'],\n","                                   'doc_id': faq_doc_id,\n","                                   'doc': {'body': f\"{faq_doc['question']} {faq_doc['answer']}\"}})\n","        return result\n","\n","    def _knowledge_to_string(self, doc, name=\"\"):\n","        \"\"\" Convert a knowledge snippet to a string \"\"\"\n","        doc_body = f\"{name.title()}: {doc['body']}\"\n","        return doc_body\n","\n","    def _create_examples(self):\n","        \"\"\" Creating examples for model training and evaluation \"\"\"\n","        logger.info(\"Creating examples\")\n","        self.examples = []\n","        token_len, truncated_len = [], []\n","        for dialog in tqdm(self.dialogs, disable=False, desc='creating examples'):\n","            #if self.debug > 0 and len(self.examples) >= self.debug:\n","            #    break\n","            dialog_id = dialog[\"id\"]\n","            label = dialog[\"label\"]\n","\n","            dialog = dialog[\"log\"]\n","            if label is None:\n","                # This will only happen when running knowledge-seeking turn detection on test data\n","                # So we create dummy target here\n","                label = {\"target\": False}\n","\n","            target = label[\"target\"]\n","\n","            if not target and self.task != \"detection\":\n","                # we only care about non-knowledge-seeking turns in turn detection task\n","                continue\n","\n","            # Turn Embedding 수정하기!!!\n","            history = [\n","                self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(turn[\"text\"]))\n","                for turn in dialog\n","            ]\n","            token_len.append(len(history))\n","            \n","            gt_resp = label.get(\"response\", \"\")\n","            tokenized_gt_resp = self.tokenizer.convert_tokens_to_ids(self.tokenizer.tokenize(gt_resp))\n","\n","            # apply history threshold at an utterance-level (a large value can be used to nullify its effect)\n","            truncated_history = history[-1000000:] #history_max_utterances : 1000000\n","            #**************************************\n","            #**************************************\n","            #**************************************\n","\n","            # perform token-level truncation of history from the left \n","            truncated_history = truncate_sequences(truncated_history, 256) #history_max_tokens : 512로 수정하였음\n","            truncated_len.append(len(truncated_history))\n","\n","            if target:\n","                knowledge_keys = []\n","                knowledge_candidates = defaultdict(lambda: 0)\n","                used_knowledge = []\n","                knowledge_prefix_visited = set()\n","\n","                if \"knowledge\" not in label:\n","                    raise ValueError(\"Please run entity matching before running knowledge selection\")\n","\n","                label_knowledge = label[\"knowledge\"]\n","\n","                for knowledge in label_knowledge:\n","                    if not (self.task == 'selection' and eval_only):\n","                        if knowledge['doc_type'] == 'review':\n","                            knowledge_key = f\"{knowledge['domain']}__{knowledge['entity_id']}__{knowledge['doc_id']}-{knowledge['sent_id']}\"\n","                        else:\n","                            knowledge_key = f\"{knowledge['domain']}__{knowledge['entity_id']}__{knowledge['doc_id']}\"\n","\n","                    # find snippets with same entity as candidates\n","                    prefix = \"{}__{}\".format(knowledge[\"domain\"], knowledge[\"entity_id\"])\n","                    if prefix not in knowledge_prefix_visited:\n","                        knowledge_prefix_visited.add(prefix)\n","                        _knowledge_candidates = [\n","                            cand\n","                            for cand in self.snippets.keys()\n","                            if \"__\".join(cand.split(\"__\")[:-1]) == prefix\n","                        ]\n","\n","                        for _knowledge_cand_idx, _knowledge_cand in enumerate(_knowledge_candidates):\n","                            knowledge_candidates[_knowledge_cand] = 1\n","                    if self.split_type == \"train\" and self.negative_sample_method == \"oracle\":\n","                        # if there's not enough candidates during training, we just skip this example\n","                        if len(knowledge_candidates) < 2 or len(knowledge_candidates) <= len(label[\"knowledge\"]): #n_candidates : 2\n","                            logger.info(\"Not enough candidates. Skip this example...\")\n","                            continue\n","\n","                    if not (self.task == 'selection' and eval_only):\n","                        used_knowledge.append(\n","                            self.snippets[knowledge_key]['token_ids'][:256]) # knowledge_max_tokens : 256\n","                        knowledge_keys.append(knowledge_key)\n","                knowledge_candidates = [k for k, v in knowledge_candidates.items()]\n","\n","            else:\n","                knowledge_candidates = None\n","                used_knowledge = []\n","                knowledge_keys = []\n","\n","            self.examples.append({\n","                \"history\": truncated_history,\n","                \"knowledge\": used_knowledge,\n","                \"knowledge_keys\": knowledge_keys,\n","                \"candidates\": knowledge_candidates,\n","                \"response\": tokenized_gt_resp,\n","                \"response_text\": gt_resp,\n","                \"label\": label,\n","                \"knowledge_seeking\": target,\n","                \"dialog_id\": dialog_id\n","            })\n","        print(max(token_len), len(token_len))\n","        print(token_len)\n","\n","        print(max(truncated_len), len(truncated_len))\n","        print(truncated_len)\n","\n","    def __getitem__(self, index):\n","        raise NotImplementedError\n","\n","    def __len__(self):\n","        return len(self.examples)"],"metadata":{"id":"D8QWLCrM0_HO","executionInfo":{"status":"ok","timestamp":1682573935471,"user_tz":-540,"elapsed":4,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class KnowledgeSelectionDataset(BaseDataset):\n","    def __init__(self, tokenizer, split_type, labels=True, labels_file=None):\n","        super(KnowledgeSelectionDataset, self).__init__(tokenizer, split_type, labels, labels_file)\n","\n","        if self.negative_sample_method not in [\"all\", \"mix\", \"oracle\"]:\n","            # Negative sampling method for knowledge selection\n","            # all: use all knowledge snippets of all entities as candidates\n","            # oracle: use all knowledge snippets of oracle entities as candidates\n","            # mix: use oracle candidates & equally sized candidates sampled from other entities\n","            raise ValueError(\n","                \"negative_sample_method must be all, mix, or oracle, got %s\" % self.negative_sample_method)\n","\n","    def _knowledge_to_string(self, doc, name=\"\"):\n","        \"\"\" convert a knowlege snippet to a string \"\"\"\n","        join_str = \" %s \" % self.knowledge_sep_token\n","        doc_body = doc['body']\n","        knowledge_string = join_str.join([name.title(), doc_body])\n","        return knowledge_string\n","\n","    def __getitem__(self, index):\n","        example = self.examples[index]\n","\n","        this_inst = {\n","            \"dialog_id\": example[\"dialog_id\"],\n","            \"input_ids\": [],\n","            \"token_type_ids\": []\n","        }\n","\n","        if self.split_type != \"train\":\n","            # if eval_all_snippets is set, we use all snippets as candidates with no sampling\n","            if self.eval_all_snippets:\n","                candidates = list(self.snippets.keys())\n","            else:\n","                candidates = example[\"candidates\"]\n","        else:\n","            if self.build_input_from_segmentsnegative_sample_method == \"all\":\n","                candidates = list(self.snippets.keys())\n","            elif self.negative_sample_method == \"mix\":\n","                candidates = example[\"candidates\"] + random.sample(list(self.snippets.keys()),\n","                                                                   k=len(example[\"candidates\"]))\n","            elif self.negative_sample_method == \"oracle\":\n","                candidates = example[\"candidates\"]\n","            else:  # although we have already checked for this, still adding this here to be sure\n","                raise ValueError(\n","                    \"negative_sample_method must be all, mix, or oracle, got %s\" % self.negative_sample_method)\n","\n","        candidate_keys = candidates\n","        this_inst[\"candidate_keys\"] = candidate_keys\n","        candidates = [self.snippets[cand_key]['token_ids'] for cand_key in candidates]\n","\n","        if self.split_type == \"train\":\n","            candidates = self._shrink_label_cands(example[\"knowledge\"], candidates)\n","\n","        label_idx = [candidates.index(knowledge) for knowledge in example[\"knowledge\"]]\n","\n","        this_inst[\"label_idx\"] = label_idx\n","        for cand in candidates:\n","            instance, _ = self.build_input_from_segments(\n","                cand,\n","                example[\"history\"]\n","            )\n","            this_inst[\"input_ids\"].append(instance[\"input_ids\"])\n","            this_inst[\"token_type_ids\"].append(instance[\"token_type_ids\"])\n","\n","        return this_inst\n","\n","    def build_input_from_segments(self, knowledge, history):\n","        \"\"\" Build a sequence of input from 2 segments: knowledge and history\"\"\"\n","        instance = {}\n","\n","        sequence = [[self.cls]] + history\n","        sequence_with_speaker = [\n","            [self.speaker1 if (len(sequence) - i) % 2 == 0 else self.speaker2] + s\n","            for i, s in enumerate(sequence[1:])\n","        ]\n","        sequence_with_speaker = list(chain(*sequence_with_speaker))\n","\n","        sequence0 = [self.cls] + sequence_with_speaker + [self.sep]\n","        sequence1 = knowledge + [self.sep]\n","\n","        if 'roberta' in str(type(self.tokenizer)):\n","            sequence0 += [self.sep]\n","        instance[\"input_ids\"] = sequence0 + sequence1\n","        instance[\"token_type_ids\"] = [0 for _ in sequence0] + [1 for _ in sequence1]\n","        return instance, sequence\n","\n","    def _shrink_label_cands(self, label, candidates):\n","        \"\"\" remove positive knowledge snippets from the candidates \"\"\"\n","        shrunk_label_cands = candidates.copy()\n","        for l in label:\n","            if l in shrunk_label_cands:\n","                shrunk_label_cands.remove(l)\n","        sample_size = min(len(label), len(shrunk_label_cands))\n","        shrunk_label_cands = random.sample(shrunk_label_cands, k=sample_size)\n","\n","        shrunk_label_cands.extend(label)\n","        random.shuffle(shrunk_label_cands)\n","        return shrunk_label_cands\n","\n","    def collate_fn(self, batch):\n","        input_ids = [ids for ins in batch for ids in ins[\"input_ids\"]]\n","        token_type_ids = [ids for ins in batch for ids in ins[\"token_type_ids\"]]\n","        label_idx = [1 if i in ins['label_idx'] else 0 for ins in batch for i in range(len(ins['input_ids']))]\n","        data_info = {\n","            \"dialog_ids\": [ins[\"dialog_id\"] for ins in batch],\n","            \"candidate_keys\": [ins[\"candidate_keys\"] for ins in batch]\n","        }\n","\n","        input_ids = torch.tensor(pad_ids(input_ids, self.pad))\n","        attention_mask = 1 - (input_ids == self.pad).int()\n","        token_type_ids = torch.tensor(pad_ids(token_type_ids, 0))\n","        label_idx = torch.tensor(label_idx)\n","        return input_ids, token_type_ids, attention_mask, label_idx, data_info\n"],"metadata":{"id":"61ttxLTr1gb9","executionInfo":{"status":"ok","timestamp":1682573936800,"user_tz":-540,"elapsed":1333,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def set_seed(num):\n","    random.seed(num)\n","    np.random.seed(num)\n","    torch.manual_seed(num)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(num)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Set seed\n","set_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkBRqrJe1jqT","executionInfo":{"status":"ok","timestamp":1682573936802,"user_tz":-540,"elapsed":8,"user":{"displayName":"이하영","userId":"16656722516517244964"}},"outputId":"8c6a7d0f-4beb-492d-9da7-e39963a4ef0e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# utils/model"],"metadata":{"id":"ciz27UYu2gdY"}},{"cell_type":"code","source":["max_candidates_per_forward_train = 4\n","max_candidates_per_forward_eval = 16\n","\n","def run_batch_selection_train(model, batch, **kwargs):\n","    \"\"\" Run batch knowledge selection during training time \"\"\"\n","    candidates_per_forward = max_candidates_per_forward_train\n","    batch = tuple(input_tensor.to(device) for input_tensor in batch if isinstance(input_tensor, torch.Tensor))\n","    input_ids, token_type_ids, attention_mask, labels = batch\n","    for index in range(0, input_ids.size(0), candidates_per_forward):\n","        model_outputs = model(\n","            input_ids=input_ids[index:index + candidates_per_forward],\n","            token_type_ids=None if model.base_model_prefix in ['roberta'] else\n","                           token_type_ids[index:index + candidates_per_forward],\n","            attention_mask=attention_mask[index:index + candidates_per_forward],\n","            labels=labels[index:index + candidates_per_forward],\n","        )\n","        loss, logits = model_outputs[0], model_outputs[1]\n","        yield loss, logits, None\n","\n","\n","def run_batch_selection_eval(model, batch, **kwargs):\n","    \"\"\" Run batch knowledge selection during evaluation time \"\"\"\n","    # return: loss, logits, labels\n","    candidates_per_forward = max_candidates_per_forward_eval\n","    batch = tuple(input_tensor.to(device) for input_tensor in batch if isinstance(input_tensor, torch.Tensor))\n","    input_ids, token_type_ids, attention_mask, labels = batch\n","    original_labels = copy.deepcopy(labels)\n","\n","    all_logits = []\n","    eval_loss = 0\n","    for index in range(0, input_ids.size(0), candidates_per_forward):\n","        model_outputs = model(\n","            input_ids=input_ids[index:index + candidates_per_forward],\n","            token_type_ids=None if model.base_model_prefix in ['roberta'] else\n","                           token_type_ids[index:index + candidates_per_forward],\n","            attention_mask=attention_mask[index:index + candidates_per_forward],\n","            labels=labels[index:index + candidates_per_forward]\n","        )\n","        eval_loss += model_outputs.loss * len(input_ids[index:index + candidates_per_forward])\n","        logits = model_outputs.logits\n","        all_logits.append(logits.detach())\n","    all_logits = torch.cat(all_logits, dim=0)\n","    return eval_loss, all_logits, original_labels\n"],"metadata":{"id":"IQsNbBRv2erd","executionInfo":{"status":"ok","timestamp":1682573936802,"user_tz":-540,"elapsed":6,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# PolyEncoder Model\n"],"metadata":{"id":"gaf1BeLuNTEp"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers import BertPreTrainedModel, BertModel\n","\n","class PolyEncoder(BertPreTrainedModel):\n","    # *input : tuple 형태, **kwargs : dictation 형태\n","    def __init__(self, config, *inputs, **kwargs):\n","        super().__init__(config, *inputs, **kwargs)\n","        self.bert = kwargs['bert']\n","        self.poly_m = kwargs['poly_m']\n","        self.poly_code_embeddings = nn.Embedding(self.poly_m, config.hidden_size)\n","        # https://github.com/facebookresearch/ParlAI/blob/master/parlai/agents/transformer/polyencoder.py#L355\n","        torch.nn.init.normal_(self.poly_code_embeddings.weight, config.hidden_size ** -0.5)\n","\n","    def dot_attention(self, q, k, v):\n","        # q: [bs, poly_m, dim] or [bs, res_cnt, dim]\n","        # k=v: [bs, length, dim] or [bs, poly_m, dim]\n","        attn_weights = torch.matmul(q, k.transpose(2, 1)) # [bs, poly_m, length]\n","        attn_weights = F.softmax(attn_weights, -1)\n","        output = torch.matmul(attn_weights, v) # [bs, poly_m, dim]\n","        return output\n","\n","    def forward(self, context_input_ids, context_input_masks,\n","                            responses_input_ids, responses_input_masks, labels=None):\n","        # during training, only select the first response\n","        # we are using other instances in a batch as negative examples\n","        if labels is not None:\n","            responses_input_ids = responses_input_ids[:, 0, :].unsqueeze(1)\n","            responses_input_masks = responses_input_masks[:, 0, :].unsqueeze(1)\n","        batch_size, res_cnt, seq_length = responses_input_ids.shape # res_cnt is 1 during training\n","\n","        # context encoder\n","        ctx_out = self.bert(context_input_ids, context_input_masks)[0]  # [bs, length, dim]\n","        poly_code_ids = torch.arange(self.poly_m, dtype=torch.long).to(context_input_ids.device)\n","        poly_code_ids = poly_code_ids.unsqueeze(0).expand(batch_size, self.poly_m)\n","        poly_codes = self.poly_code_embeddings(poly_code_ids) # [bs, poly_m, dim]\n","        embs = self.dot_attention(poly_codes, ctx_out, ctx_out) # [bs, poly_m, dim]\n","\n","        # response encoder\n","        responses_input_ids = responses_input_ids.view(-1, seq_length)\n","        responses_input_masks = responses_input_masks.view(-1, seq_length)\n","        cand_emb = self.bert(responses_input_ids, responses_input_masks)[0][:,0,:] # [bs, dim]\n","        cand_emb = cand_emb.view(batch_size, res_cnt, -1) # [bs, res_cnt, dim]\n","\n","        # merge\n","        if labels is not None:\n","            # we are recycling responses for faster training\n","            # we repeat responses for batch_size times to simulate test phase\n","            # so that every context is paired with batch_size responses\n","            cand_emb = cand_emb.permute(1, 0, 2) # [1, bs, dim]\n","            cand_emb = cand_emb.expand(batch_size, batch_size, cand_emb.shape[2]) # [bs, bs, dim]\n","            ctx_emb = self.dot_attention(cand_emb, embs, embs).squeeze() # [bs, bs, dim]\n","            dot_product = (ctx_emb*cand_emb).sum(-1) # [bs, bs]\n","            mask = torch.eye(batch_size).to(context_input_ids.device) # [bs, bs]\n","            loss = F.log_softmax(dot_product, dim=-1) * mask\n","            loss = (-loss.sum(dim=1)).mean()\n","            return loss\n","        else:\n","            ctx_emb = self.dot_attention(cand_emb, embs, embs) # [bs, res_cnt, dim]\n","            dot_product = (ctx_emb*cand_emb).sum(-1)\n","            return dot_product"],"metadata":{"id":"M5C1_JRXNyIJ","executionInfo":{"status":"ok","timestamp":1682573997796,"user_tz":-540,"elapsed":1109,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from transformers import BertModel, BertConfig, BertTokenizer, BertTokenizerFast\n","from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n","\n","dataset_class, model_class, run_batch_fn_train, run_batch_fn_eval = KnowledgeSelectionDataset, AutoModelForSequenceClassification, run_batch_selection_train, run_batch_selection_eval\n","\n","eval_only = False\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.add_special_tokens(SPECIAL_TOKENS)\n","tokenizer.model_max_length = min(1024, tokenizer.model_max_length)\n","print(tokenizer.model_max_length)"],"metadata":{"id":"FJygemn-Rp1t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"Luzx7QYP2_3Q"}},{"cell_type":"code","source":["import argparse\n","import logging\n","import os\n","import random\n","import json\n","\n","from typing import Dict, Tuple\n","from argparse import Namespace\n","\n","import numpy as np\n","import torch\n","from sklearn.metrics import recall_score, precision_score, average_precision_score, classification_report, f1_score\n","\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tqdm, trange\n","from transformers import (\n","    AutoConfig,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n","    BartForConditionalGeneration,\n","    AutoModelForSequenceClassification,\n",")\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter"],"metadata":{"id":"mIwFL22q28Os","executionInfo":{"status":"ok","timestamp":1682574787836,"user_tz":-540,"elapsed":501,"user":{"displayName":"이하영","userId":"16656722516517244964"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["------------------------------------"],"metadata":{"id":"luawCJmbRfOy"}},{"cell_type":"code","source":["# deverta-v3-base - max : 1024\n","dataset_class, model_class, run_batch_fn_train, run_batch_fn_eval = KnowledgeSelectionDataset, AutoModelForSequenceClassification, run_batch_selection_train, run_batch_selection_eval\n","\n","eval_only = False\n","model_name = \"microsoft/deberta-v3-base\"\n","\n","config = AutoConfig.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.add_special_tokens(SPECIAL_TOKENS)\n","tokenizer.model_max_length = min(1024, tokenizer.model_max_length)\n","print(tokenizer.model_max_length)\n","\n","model = model_class.from_pretrained(model_name, config=config)\n","model.resize_token_embeddings(len(tokenizer))\n","model.to(device)\n","\n","output_file = 'selection_result'\n","output_dir = '/content/drive/MyDrive/dstc11-track5/output'\n","\n","train_dataset = KnowledgeSelectionDataset(tokenizer, split_type=\"train\")\n","eval_dataset = KnowledgeSelectionDataset(tokenizer, split_type=\"val\")  # main difference is during evaluation, val need to go through all snippets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMLZuzKu3NS6","executionInfo":{"status":"ok","timestamp":1680941562425,"user_tz":-540,"elapsed":183926,"user":{"displayName":"이하영","userId":"16656722516517244964"}},"outputId":"7da22fac-cf62-45d4-a208-295f7f958142"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["1024\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","tokenizing...: 100%|██████████| 28431/28431 [00:02<00:00, 11030.37it/s]\n","creating examples: 100%|██████████| 28431/28431 [02:30<00:00, 188.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["45 14768\n","[5, 9, 7, 13, 7, 3, 5, 11, 5, 5, 21, 3, 9, 5, 7, 15, 7, 15, 11, 5, 11, 3, 3, 13, 13, 5, 7, 7, 11, 15, 5, 17, 3, 11, 7, 5, 3, 5, 3, 7, 7, 11, 5, 9, 11, 3, 11, 9, 13, 7, 19, 11, 7, 7, 5, 13, 3, 5, 13, 11, 9, 15, 5, 11, 13, 11, 7, 11, 3, 15, 3, 7, 11, 7, 17, 5, 5, 5, 9, 7, 7, 9, 3, 9, 9, 7, 5, 9, 7, 9, 9, 5, 7, 5, 3, 3, 5, 5, 21, 9, 13, 19, 7, 11, 5, 9, 9, 3, 9, 7, 3, 15, 7, 5, 7, 9, 3, 15, 13, 17, 7, 11, 7, 15, 19, 15, 9, 17, 5, 15, 11, 7, 5, 11, 9, 9, 5, 7, 19, 13, 5, 15, 3, 5, 7, 15, 15, 9, 11, 9, 3, 3, 7, 7, 9, 5, 3, 11, 7, 13, 3, 7, 5, 9, 17, 7, 3, 9, 5, 7, 7, 9, 13, 13, 5, 9, 7, 5, 7, 7, 13, 7, 3, 7, 11, 5, 11, 7, 5, 7, 9, 3, 13, 17, 5, 3, 9, 9, 11, 17, 9, 3, 7, 3, 17, 7, 13, 7, 5, 5, 9, 5, 3, 5, 5, 9, 3, 3, 19, 13, 7, 7, 5, 7, 5, 9, 3, 7, 5, 11, 3, 7, 3, 9, 7, 13, 19, 5, 19, 7, 3, 11, 11, 7, 3, 7, 7, 11, 3, 9, 11, 11, 7, 5, 9, 7, 5, 3, 7, 7, 3, 13, 3, 11, 11, 9, 3, 5, 11, 7, 13, 9, 9, 3, 5, 15, 15, 11, 9, 7, 7, 7, 9, 7, 9, 7, 19, 3, 13, 11, 3, 5, 5, 13, 5, 11, 3, 15, 3, 17, 3, 5, 7, 7, 13, 3, 3, 7, 9, 17, 3, 3, 5, 7, 11, 7, 11, 9, 5, 9, 7, 11, 9, 5, 11, 7, 11, 3, 11, 7, 11, 17, 3, 7, 7, 3, 13, 5, 5, 13, 5, 7, 9, 9, 3, 9, 13, 5, 13, 9, 13, 13, 7, 3, 15, 5, 13, 5, 5, 15, 5, 3, 21, 7, 5, 5, 13, 11, 3, 3, 9, 11, 3, 3, 11, 13, 5, 5, 11, 13, 3, 13, 11, 11, 3, 3, 9, 3, 3, 5, 11, 3, 19, 5, 13, 3, 7, 15, 7, 13, 7, 7, 7, 9, 5, 15, 15, 5, 7, 5, 7, 5, 9, 11, 11, 3, 5, 9, 9, 3, 15, 13, 7, 5, 5, 3, 5, 5, 9, 17, 5, 9, 13, 5, 11, 5, 7, 13, 9, 7, 3, 7, 11, 7, 5, 7, 7, 11, 9, 7, 13, 7, 5, 3, 11, 5, 5, 5, 9, 3, 5, 5, 3, 5, 3, 5, 17, 13, 9, 7, 13, 15, 13, 11, 17, 11, 13, 3, 7, 5, 5, 5, 7, 5, 9, 13, 9, 11, 9, 3, 5, 7, 5, 7, 9, 15, 13, 9, 5, 17, 11, 13, 3, 5, 7, 7, 25, 5, 9, 27, 9, 5, 9, 9, 3, 7, 7, 3, 7, 5, 7, 11, 11, 11, 13, 13, 11, 7, 7, 15, 25, 13, 11, 13, 7, 9, 5, 9, 7, 15, 5, 5, 9, 9, 13, 5, 3, 3, 3, 5, 3, 7, 3, 11, 11, 15, 7, 7, 5, 3, 7, 5, 15, 9, 17, 7, 5, 3, 7, 3, 7, 15, 7, 3, 5, 13, 5, 9, 9, 15, 3, 17, 13, 13, 7, 3, 17, 5, 7, 11, 3, 7, 7, 7, 11, 7, 5, 3, 9, 5, 9, 9, 9, 9, 5, 11, 13, 5, 9, 9, 5, 5, 7, 13, 5, 9, 5, 11, 5, 19, 7, 9, 15, 5, 11, 7, 7, 15, 13, 7, 5, 3, 5, 7, 9, 5, 13, 11, 19, 13, 5, 13, 11, 17, 5, 11, 9, 11, 13, 5, 7, 3, 5, 13, 7, 3, 5, 7, 9, 3, 5, 17, 7, 9, 7, 5, 7, 15, 15, 3, 5, 13, 9, 5, 5, 11, 7, 7, 9, 5, 17, 5, 9, 5, 7, 15, 3, 15, 15, 5, 9, 3, 13, 9, 9, 13, 13, 17, 17, 5, 3, 5, 9, 5, 15, 5, 5, 5, 9, 7, 5, 5, 9, 5, 3, 7, 9, 3, 11, 5, 13, 17, 19, 5, 13, 3, 13, 5, 11, 5, 3, 11, 13, 5, 5, 7, 5, 11, 3, 5, 5, 7, 3, 5, 3, 13, 5, 3, 5, 5, 13, 9, 9, 13, 3, 5, 3, 11, 11, 3, 9, 9, 3, 13, 5, 5, 11, 3, 7, 9, 3, 3, 17, 15, 5, 7, 15, 13, 7, 21, 7, 5, 11, 9, 5, 15, 7, 3, 5, 9, 13, 3, 13, 13, 9, 9, 5, 5, 11, 9, 7, 9, 5, 13, 13, 11, 7, 11, 5, 7, 11, 5, 9, 11, 13, 3, 3, 13, 3, 13, 9, 17, 11, 7, 19, 3, 7, 3, 9, 5, 5, 11, 9, 7, 7, 7, 13, 5, 5, 9, 11, 7, 9, 9, 7, 9, 15, 5, 17, 17, 7, 13, 9, 5, 11, 3, 7, 11, 9, 7, 9, 7, 15, 17, 3, 13, 9, 17, 11, 15, 5, 5, 15, 7, 11, 7, 11, 3, 11, 11, 5, 11, 3, 5, 3, 5, 7, 7, 11, 7, 7, 3, 3, 11, 25, 5, 15, 5, 7, 11, 5, 5, 9, 3, 13, 11, 13, 13, 3, 15, 13, 13, 5, 5, 13, 3, 9, 15, 9, 9, 9, 7, 7, 7, 9, 11, 7, 5, 3, 9, 13, 15, 13, 5, 9, 5, 5, 13, 7, 7, 13, 7, 13, 3, 7, 7, 3, 7, 9, 3, 13, 5, 11, 9, 5, 3, 3, 15, 5, 11, 13, 9, 5, 5, 15, 11, 9, 9, 19, 7, 7, 13, 7, 5, 7, 11, 11, 7, 5, 9, 5, 5, 11, 5, 9, 3, 5, 5, 13, 3, 7, 7, 19, 9, 3, 3, 9, 9, 9, 15, 15, 11, 5, 5, 7, 9, 3, 11, 9, 13, 3, 5, 7, 11, 5, 5, 7, 7, 11, 5, 5, 3, 11, 11, 17, 7, 17, 17, 3, 5, 7, 15, 7, 11, 9, 15, 13, 11, 7, 5, 5, 19, 3, 11, 5, 9, 5, 7, 3, 7, 19, 3, 9, 11, 5, 9, 7, 5, 11, 3, 5, 9, 7, 3, 5, 11, 5, 7, 3, 5, 5, 11, 7, 5, 5, 7, 13, 5, 11, 7, 5, 13, 13, 15, 11, 17, 5, 3, 3, 13, 7, 3, 7, 13, 5, 7, 7, 7, 5, 17, 13, 9, 3, 7, 9, 13, 9, 15, 3, 9, 13, 5, 5, 9, 11, 13, 7, 5, 9, 7, 15, 5, 3, 13, 3, 5, 5, 3, 9, 3, 5, 5, 9, 5, 11, 3, 9, 15, 15, 15, 11, 7, 9, 13, 15, 7, 5, 3, 5, 9, 7, 5, 7, 7, 11, 15, 5, 7, 7, 3, 11, 5, 5, 9, 7, 5, 5, 5, 5, 13, 3, 3, 13, 3, 3, 25, 3, 5, 9, 3, 11, 13, 5, 11, 7, 5, 15, 15, 5, 17, 11, 7, 5, 3, 7, 13, 5, 5, 11, 7, 7, 5, 13, 7, 5, 11, 9, 7, 9, 15, 5, 5, 7, 5, 7, 7, 19, 5, 15, 7, 5, 7, 13, 13, 5, 3, 5, 11, 7, 9, 15, 21, 3, 5, 11, 13, 5, 9, 11, 5, 5, 13, 5, 13, 5, 13, 5, 7, 13, 5, 3, 3, 5, 9, 5, 11, 3, 7, 11, 5, 3, 13, 13, 9, 5, 9, 13, 3, 9, 5, 5, 9, 5, 3, 9, 15, 7, 5, 7, 9, 5, 5, 7, 11, 5, 11, 13, 7, 5, 7, 15, 9, 11, 15, 7, 13, 5, 5, 7, 7, 11, 11, 13, 11, 9, 13, 5, 5, 7, 5, 9, 7, 7, 13, 5, 3, 17, 7, 9, 3, 9, 3, 11, 5, 7, 3, 11, 7, 5, 9, 11, 13, 7, 7, 7, 3, 5, 13, 7, 7, 5, 7, 9, 5, 7, 9, 3, 11, 7, 7, 11, 13, 5, 3, 5, 17, 11, 13, 7, 7, 7, 5, 15, 15, 15, 13, 11, 3, 5, 7, 5, 9, 9, 13, 5, 11, 11, 5, 5, 13, 9, 7, 9, 19, 7, 3, 9, 9, 9, 5, 3, 15, 5, 3, 3, 13, 17, 5, 3, 3, 7, 5, 3, 3, 5, 3, 5, 9, 7, 3, 3, 5, 5, 3, 3, 5, 5, 13, 13, 9, 9, 15, 5, 11, 3, 5, 9, 9, 13, 9, 15, 11, 7, 11, 13, 3, 5, 11, 11, 5, 3, 3, 11, 9, 25, 7, 13, 11, 9, 3, 5, 5, 7, 5, 13, 9, 15, 13, 11, 45, 7, 5, 5, 11, 13, 9, 17, 3, 7, 7, 3, 3, 5, 7, 13, 9, 9, 3, 9, 9, 19, 5, 15, 5, 11, 5, 7, 3, 11, 7, 5, 3, 5, 13, 11, 7, 3, 3, 7, 5, 9, 7, 13, 11, 3, 15, 5, 13, 5, 15, 5, 3, 9, 5, 15, 7, 11, 7, 9, 3, 9, 9, 15, 9, 15, 3, 15, 5, 11, 9, 5, 15, 7, 13, 9, 13, 11, 13, 13, 11, 3, 11, 5, 13, 13, 3, 7, 5, 9, 13, 7, 5, 7, 3, 9, 9, 9, 5, 3, 11, 11, 5, 9, 3, 5, 9, 5, 7, 7, 5, 7, 3, 11, 15, 5, 5, 3, 11, 5, 3, 9, 13, 9, 3, 5, 3, 9, 11, 17, 9, 5, 3, 7, 5, 9, 7, 3, 5, 9, 7, 3, 7, 5, 11, 9, 13, 9, 5, 7, 17, 11, 9, 5, 13, 5, 5, 5, 13, 5, 9, 5, 9, 9, 7, 7, 5, 9, 9, 7, 9, 13, 9, 9, 23, 3, 7, 5, 9, 11, 7, 5, 5, 7, 9, 5, 13, 7, 9, 13, 7, 7, 11, 7, 5, 15, 5, 3, 11, 11, 5, 7, 5, 9, 3, 7, 13, 11, 11, 7, 3, 3, 3, 11, 7, 5, 7, 9, 3, 7, 5, 13, 5, 9, 11, 9, 15, 3, 9, 5, 13, 9, 11, 3, 9, 5, 5, 5, 3, 5, 3, 11, 3, 5, 5, 5, 7, 7, 9, 7, 11, 9, 7, 11, 5, 9, 7, 9, 3, 7, 7, 13, 9, 7, 7, 5, 9, 9, 11, 17, 13, 13, 9, 13, 3, 13, 15, 11, 7, 11, 7, 3, 11, 7, 3, 7, 3, 11, 11, 5, 7, 5, 9, 11, 11, 11, 11, 13, 3, 9, 11, 5, 17, 11, 5, 3, 7, 3, 7, 11, 9, 11, 7, 11, 5, 3, 9, 5, 9, 3, 11, 13, 9, 3, 3, 7, 3, 9, 3, 5, 11, 7, 7, 7, 5, 7, 7, 15, 3, 5, 9, 9, 13, 7, 5, 5, 17, 11, 7, 15, 5, 3, 9, 17, 7, 5, 9, 5, 7, 9, 19, 13, 3, 11, 9, 7, 5, 7, 17, 19, 5, 7, 7, 11, 5, 9, 11, 3, 11, 13, 3, 13, 13, 7, 9, 7, 3, 9, 3, 9, 3, 3, 9, 11, 19, 9, 5, 5, 3, 5, 3, 9, 5, 7, 7, 11, 7, 15, 9, 9, 15, 17, 15, 9, 21, 5, 9, 5, 7, 9, 11, 9, 5, 11, 7, 11, 7, 5, 7, 5, 3, 5, 7, 7, 5, 13, 3, 5, 11, 11, 3, 13, 11, 13, 5, 9, 13, 5, 7, 15, 5, 9, 17, 13, 11, 17, 7, 9, 7, 15, 5, 3, 7, 7, 3, 19, 3, 5, 9, 9, 7, 3, 7, 21, 5, 7, 15, 7, 13, 5, 11, 5, 11, 9, 9, 5, 3, 7, 5, 9, 11, 7, 7, 11, 7, 11, 3, 9, 9, 11, 13, 7, 5, 11, 3, 7, 5, 7, 11, 7, 7, 5, 5, 9, 9, 11, 11, 9, 7, 3, 7, 5, 9, 5, 3, 9, 17, 5, 5, 5, 3, 7, 5, 15, 11, 9, 7, 5, 11, 5, 5, 23, 13, 3, 5, 5, 9, 5, 3, 3, 3, 5, 5, 9, 5, 5, 11, 3, 13, 23, 7, 9, 5, 7, 17, 5, 5, 7, 7, 3, 9, 5, 13, 15, 9, 15, 5, 11, 7, 5, 9, 9, 11, 9, 3, 11, 9, 7, 7, 11, 7, 13, 5, 3, 13, 21, 7, 5, 11, 7, 7, 9, 3, 11, 3, 5, 13, 11, 11, 7, 5, 5, 13, 9, 5, 3, 7, 11, 11, 3, 13, 11, 13, 3, 5, 9, 13, 11, 5, 3, 3, 11, 5, 7, 3, 7, 5, 3, 5, 3, 5, 7, 5, 3, 11, 3, 5, 11, 5, 7, 7, 3, 3, 7, 13, 3, 11, 11, 5, 3, 11, 13, 7, 9, 3, 3, 9, 7, 15, 9, 5, 9, 9, 13, 9, 13, 9, 7, 3, 23, 5, 3, 7, 7, 3, 7, 13, 7, 15, 7, 11, 9, 9, 15, 19, 17, 11, 9, 5, 9, 15, 3, 9, 5, 7, 9, 9, 5, 13, 13, 7, 3, 9, 19, 7, 5, 11, 5, 13, 5, 11, 3, 5, 3, 5, 5, 7, 5, 5, 5, 9, 11, 5, 7, 11, 3, 11, 9, 21, 13, 5, 5, 5, 15, 5, 7, 13, 7, 13, 9, 7, 5, 3, 15, 3, 3, 7, 7, 13, 7, 5, 13, 9, 15, 3, 9, 7, 5, 11, 7, 9, 15, 3, 17, 13, 3, 3, 11, 15, 11, 13, 11, 7, 15, 5, 15, 9, 3, 5, 11, 7, 11, 7, 13, 5, 9, 3, 11, 7, 21, 7, 9, 3, 3, 5, 7, 13, 5, 9, 5, 19, 9, 7, 3, 7, 5, 11, 7, 7, 5, 9, 9, 9, 7, 3, 7, 7, 5, 5, 5, 5, 3, 7, 3, 9, 13, 7, 9, 3, 9, 7, 5, 5, 5, 9, 7, 3, 13, 5, 5, 9, 3, 15, 5, 13, 5, 15, 11, 5, 15, 9, 9, 9, 13, 5, 13, 17, 5, 7, 3, 11, 5, 7, 13, 3, 9, 5, 9, 7, 7, 15, 7, 9, 13, 25, 11, 7, 7, 19, 9, 5, 11, 5, 7, 13, 9, 11, 9, 3, 5, 7, 3, 5, 11, 37, 5, 3, 11, 5, 3, 5, 11, 7, 5, 9, 3, 15, 9, 3, 15, 9, 7, 3, 3, 5, 5, 15, 17, 15, 7, 11, 11, 11, 13, 5, 11, 9, 13, 11, 3, 5, 7, 11, 5, 11, 3, 3, 9, 13, 7, 11, 17, 3, 9, 17, 5, 5, 15, 3, 15, 15, 9, 7, 13, 3, 3, 15, 9, 13, 3, 9, 5, 3, 5, 7, 11, 11, 3, 5, 3, 3, 5, 11, 7, 7, 13, 7, 9, 3, 3, 11, 17, 3, 17, 7, 5, 13, 5, 15, 3, 9, 7, 7, 23, 9, 5, 21, 7, 13, 7, 13, 7, 7, 5, 13, 11, 13, 7, 5, 5, 5, 13, 7, 3, 11, 5, 3, 13, 11, 7, 15, 7, 3, 5, 9, 5, 5, 13, 9, 17, 15, 5, 7, 11, 3, 5, 5, 5, 3, 17, 7, 7, 5, 7, 7, 7, 11, 5, 9, 15, 9, 13, 7, 5, 5, 9, 11, 3, 21, 9, 3, 9, 3, 5, 3, 11, 5, 3, 7, 3, 5, 3, 5, 15, 3, 11, 11, 3, 9, 9, 13, 13, 3, 19, 7, 11, 5, 7, 9, 7, 3, 13, 11, 9, 3, 5, 15, 9, 3, 7, 9, 5, 7, 3, 13, 5, 3, 11, 5, 3, 19, 9, 3, 5, 11, 7, 3, 5, 5, 5, 15, 7, 13, 7, 5, 9, 3, 19, 5, 5, 7, 15, 3, 7, 17, 9, 19, 3, 15, 11, 9, 3, 5, 7, 5, 7, 3, 5, 7, 15, 7, 13, 5, 7, 5, 11, 3, 5, 5, 7, 5, 9, 11, 7, 3, 15, 3, 5, 11, 3, 5, 5, 11, 5, 13, 9, 9, 13, 7, 11, 3, 7, 7, 3, 7, 7, 9, 5, 9, 5, 5, 5, 5, 5, 9, 13, 5, 23, 13, 5, 7, 5, 5, 3, 9, 9, 11, 5, 7, 3, 11, 3, 11, 5, 9, 7, 3, 3, 7, 13, 7, 5, 9, 13, 13, 7, 13, 5, 7, 7, 9, 3, 7, 3, 3, 13, 9, 5, 7, 13, 11, 11, 7, 5, 17, 5, 9, 5, 9, 7, 13, 9, 7, 5, 7, 3, 13, 13, 7, 3, 5, 5, 7, 9, 11, 3, 9, 11, 5, 7, 9, 7, 13, 5, 9, 7, 3, 7, 9, 11, 9, 13, 3, 15, 19, 15, 15, 5, 5, 9, 7, 9, 5, 5, 3, 3, 13, 11, 7, 13, 11, 9, 11, 3, 7, 7, 7, 7, 5, 9, 5, 5, 5, 9, 5, 15, 3, 5, 3, 3, 7, 3, 11, 25, 17, 7, 3, 7, 7, 13, 5, 9, 5, 9, 9, 9, 7, 9, 7, 7, 7, 5, 7, 7, 13, 11, 9, 5, 3, 5, 15, 13, 13, 11, 11, 9, 11, 7, 5, 9, 7, 3, 9, 17, 9, 3, 5, 5, 7, 7, 9, 9, 7, 7, 5, 5, 5, 13, 5, 5, 9, 7, 9, 9, 5, 3, 11, 9, 9, 15, 5, 7, 7, 7, 11, 9, 9, 13, 3, 13, 7, 11, 7, 9, 7, 5, 3, 7, 7, 5, 13, 13, 7, 11, 13, 13, 9, 9, 7, 11, 9, 7, 5, 13, 19, 11, 11, 15, 11, 13, 11, 9, 11, 3, 11, 11, 11, 9, 11, 7, 5, 11, 13, 5, 5, 3, 7, 15, 3, 5, 7, 3, 17, 13, 5, 11, 11, 5, 9, 15, 5, 7, 7, 5, 7, 9, 5, 5, 5, 5, 15, 9, 9, 11, 7, 7, 7, 13, 5, 3, 9, 5, 5, 3, 7, 5, 7, 3, 3, 3, 3, 15, 5, 15, 5, 13, 7, 11, 9, 9, 3, 9, 5, 9, 5, 9, 5, 3, 15, 7, 5, 7, 5, 13, 17, 5, 5, 3, 9, 7, 5, 5, 7, 11, 3, 5, 3, 13, 11, 11, 5, 3, 17, 9, 7, 5, 11, 7, 11, 9, 11, 17, 7, 3, 5, 11, 3, 13, 15, 11, 11, 5, 5, 7, 11, 11, 3, 3, 9, 7, 7, 7, 3, 5, 3, 5, 9, 3, 7, 5, 11, 7, 15, 5, 3, 15, 11, 3, 7, 11, 11, 9, 3, 3, 11, 5, 5, 5, 15, 13, 9, 3, 17, 9, 7, 7, 7, 11, 5, 7, 5, 5, 9, 15, 7, 5, 13, 11, 7, 9, 5, 7, 7, 15, 7, 3, 17, 11, 7, 7, 3, 9, 3, 5, 13, 19, 5, 5, 5, 7, 15, 13, 5, 7, 5, 7, 5, 5, 3, 5, 15, 5, 5, 9, 7, 11, 5, 3, 15, 5, 5, 9, 5, 3, 5, 3, 11, 7, 3, 7, 11, 9, 5, 7, 3, 9, 9, 13, 7, 5, 7, 13, 21, 11, 15, 3, 7, 13, 9, 5, 9, 13, 5, 5, 3, 7, 13, 3, 9, 13, 15, 3, 7, 5, 7, 13, 5, 5, 7, 19, 11, 3, 11, 3, 5, 9, 13, 5, 3, 11, 11, 9, 15, 9, 9, 9, 5, 5, 13, 13, 13, 11, 11, 11, 3, 9, 17, 5, 3, 17, 7, 7, 11, 17, 5, 9, 5, 7, 17, 7, 9, 3, 7, 7, 7, 3, 11, 7, 9, 11, 11, 9, 11, 5, 3, 5, 17, 5, 5, 11, 3, 11, 9, 5, 7, 5, 9, 9, 7, 11, 11, 3, 13, 5, 9, 3, 3, 5, 3, 3, 11, 15, 5, 7, 3, 9, 9, 11, 7, 3, 9, 7, 7, 9, 11, 3, 5, 11, 3, 9, 11, 5, 13, 7, 13, 3, 13, 5, 11, 11, 13, 7, 7, 5, 13, 11, 7, 5, 3, 11, 9, 11, 7, 9, 9, 3, 9, 11, 3, 7, 7, 5, 7, 15, 7, 5, 11, 5, 13, 11, 15, 7, 13, 21, 15, 9, 15, 5, 3, 5, 5, 5, 7, 7, 5, 9, 13, 5, 5, 3, 7, 9, 5, 9, 11, 11, 5, 7, 5, 11, 5, 3, 3, 7, 7, 11, 13, 11, 3, 7, 7, 11, 7, 3, 11, 5, 9, 3, 3, 5, 15, 5, 3, 11, 5, 7, 11, 5, 3, 5, 5, 7, 5, 11, 11, 9, 9, 3, 5, 5, 7, 9, 7, 9, 5, 7, 13, 3, 11, 3, 11, 13, 7, 3, 11, 5, 13, 19, 7, 11, 5, 3, 5, 13, 5, 7, 3, 3, 9, 7, 15, 5, 7, 5, 17, 7, 9, 7, 13, 3, 3, 15, 5, 7, 13, 3, 15, 5, 7, 7, 3, 13, 3, 11, 13, 5, 5, 11, 7, 11, 9, 9, 5, 3, 5, 13, 11, 7, 15, 5, 13, 15, 15, 3, 7, 3, 7, 5, 13, 7, 13, 9, 11, 7, 3, 11, 13, 7, 11, 5, 9, 3, 11, 5, 13, 11, 13, 3, 15, 13, 3, 3, 9, 5, 15, 7, 15, 11, 7, 5, 5, 9, 3, 9, 9, 11, 7, 11, 3, 9, 5, 3, 11, 7, 11, 7, 3, 5, 7, 5, 5, 15, 13, 13, 3, 9, 19, 9, 3, 15, 7, 11, 3, 3, 5, 3, 7, 7, 5, 5, 3, 15, 5, 7, 5, 7, 7, 7, 13, 11, 5, 7, 11, 11, 5, 13, 3, 13, 13, 7, 13, 13, 9, 5, 3, 9, 7, 3, 7, 5, 19, 5, 7, 9, 11, 9, 9, 9, 7, 13, 3, 3, 5, 7, 5, 13, 3, 11, 9, 5, 13, 5, 9, 7, 9, 11, 5, 15, 5, 13, 5, 9, 11, 3, 7, 3, 7, 3, 5, 7, 3, 9, 15, 5, 7, 7, 5, 13, 5, 9, 9, 19, 9, 5, 5, 9, 5, 11, 17, 13, 9, 13, 5, 7, 9, 3, 5, 9, 3, 3, 7, 5, 9, 7, 5, 13, 15, 3, 9, 13, 13, 5, 3, 11, 11, 11, 5, 3, 7, 9, 7, 13, 27, 5, 7, 11, 3, 11, 3, 5, 9, 9, 3, 9, 15, 3, 13, 3, 5, 3, 5, 7, 15, 5, 3, 5, 7, 13, 5, 5, 15, 15, 11, 15, 7, 7, 15, 9, 5, 13, 9, 7, 11, 7, 5, 11, 13, 7, 13, 7, 9, 7, 5, 5, 9, 7, 7, 5, 13, 11, 9, 7, 11, 7, 9, 5, 9, 7, 5, 7, 7, 7, 5, 7, 7, 3, 5, 5, 5, 5, 9, 5, 13, 9, 7, 9, 5, 9, 9, 15, 9, 3, 3, 9, 13, 13, 3, 15, 5, 5, 5, 7, 3, 9, 9, 5, 11, 7, 7, 7, 5, 23, 17, 3, 7, 11, 11, 5, 5, 5, 3, 15, 5, 3, 3, 5, 13, 3, 7, 23, 13, 9, 7, 7, 11, 21, 21, 13, 3, 7, 7, 9, 11, 5, 5, 3, 5, 5, 13, 11, 11, 15, 5, 11, 5, 5, 7, 7, 3, 5, 5, 7, 11, 13, 19, 17, 19, 7, 13, 5, 5, 13, 9, 7, 7, 3, 11, 5, 13, 9, 13, 3, 11, 3, 7, 5, 3, 5, 15, 19, 11, 19, 9, 9, 9, 15, 11, 5, 17, 9, 5, 5, 7, 9, 5, 17, 9, 13, 13, 9, 9, 5, 7, 13, 7, 15, 5, 21, 5, 13, 3, 3, 7, 17, 3, 9, 13, 19, 7, 13, 11, 7, 17, 5, 7, 7, 11, 5, 11, 5, 5, 9, 3, 9, 13, 7, 5, 5, 13, 5, 5, 15, 15, 11, 9, 3, 13, 7, 9, 9, 11, 3, 9, 7, 5, 3, 3, 7, 5, 13, 13, 7, 9, 7, 5, 5, 9, 3, 5, 5, 15, 7, 9, 9, 19, 3, 7, 5, 11, 9, 7, 11, 5, 9, 3, 7, 7, 11, 9, 9, 11, 5, 5, 9, 3, 13, 5, 9, 15, 7, 15, 7, 11, 3, 13, 9, 3, 11, 3, 15, 7, 15, 5, 15, 3, 9, 5, 3, 7, 11, 13, 5, 3, 5, 9, 7, 7, 15, 5, 15, 11, 11, 3, 21, 7, 13, 9, 11, 9, 9, 9, 15, 3, 19, 15, 13, 9, 11, 9, 13, 9, 3, 3, 15, 7, 5, 11, 13, 9, 15, 7, 3, 3, 5, 13, 5, 11, 5, 9, 13, 7, 9, 3, 3, 7, 13, 9, 13, 5, 7, 3, 9, 19, 7, 11, 5, 9, 17, 9, 19, 13, 11, 5, 11, 11, 9, 5, 3, 5, 3, 11, 7, 11, 5, 9, 13, 5, 17, 11, 5, 5, 9, 9, 15, 5, 3, 7, 7, 9, 5, 5, 7, 5, 21, 13, 3, 5, 5, 3, 13, 7, 5, 13, 7, 15, 17, 5, 15, 5, 7, 13, 11, 7, 7, 9, 3, 9, 9, 11, 5, 3, 7, 13, 3, 15, 5, 9, 5, 3, 17, 13, 5, 5, 17, 9, 11, 5, 11, 5, 17, 3, 3, 9, 9, 11, 17, 3, 3, 7, 7, 13, 15, 9, 13, 7, 7, 9, 7, 15, 11, 7, 5, 17, 11, 3, 11, 15, 13, 7, 11, 13, 3, 11, 7, 5, 5, 7, 17, 5, 5, 5, 13, 7, 5, 11, 5, 9, 11, 3, 9, 7, 9, 5, 7, 5, 7, 3, 13, 5, 11, 13, 17, 11, 11, 7, 7, 11, 9, 5, 9, 3, 7, 3, 5, 5, 9, 9, 3, 13, 3, 3, 5, 9, 11, 13, 3, 13, 7, 11, 7, 11, 5, 3, 3, 5, 5, 23, 15, 11, 5, 3, 13, 5, 11, 5, 11, 5, 5, 15, 5, 9, 3, 5, 13, 13, 11, 9, 7, 17, 13, 3, 13, 13, 9, 5, 7, 7, 3, 15, 11, 3, 3, 9, 9, 7, 5, 13, 9, 9, 9, 5, 15, 9, 3, 5, 9, 19, 5, 13, 13, 7, 7, 5, 7, 11, 11, 5, 3, 5, 3, 3, 5, 5, 3, 7, 13, 21, 7, 7, 9, 3, 7, 9, 11, 13, 15, 13, 9, 15, 19, 3, 11, 11, 5, 11, 7, 13, 3, 7, 9, 7, 5, 13, 13, 3, 13, 9, 7, 3, 15, 11, 11, 13, 15, 9, 9, 17, 3, 5, 11, 7, 7, 13, 13, 13, 5, 7, 5, 3, 5, 3, 9, 15, 3, 21, 3, 3, 7, 7, 15, 5, 5, 9, 7, 11, 13, 7, 3, 7, 11, 11, 7, 11, 9, 11, 15, 3, 5, 3, 17, 5, 3, 7, 9, 5, 5, 7, 7, 7, 7, 13, 3, 7, 7, 3, 7, 13, 15, 5, 17, 19, 5, 7, 3, 3, 7, 5, 9, 17, 9, 9, 5, 11, 17, 3, 9, 7, 7, 13, 7, 11, 15, 3, 17, 15, 9, 5, 3, 17, 11, 3, 15, 19, 3, 5, 9, 3, 7, 15, 5, 15, 7, 5, 3, 9, 7, 7, 9, 9, 9, 13, 3, 3, 11, 3, 13, 9, 7, 13, 5, 13, 5, 9, 9, 5, 7, 9, 5, 5, 5, 7, 5, 9, 3, 9, 9, 13, 5, 5, 11, 9, 7, 11, 11, 11, 7, 15, 7, 9, 9, 7, 11, 11, 5, 7, 7, 5, 7, 9, 3, 5, 9, 5, 3, 17, 9, 7, 7, 3, 5, 11, 15, 5, 11, 7, 3, 11, 5, 3, 13, 7, 9, 5, 11, 9, 3, 3, 7, 17, 23, 11, 7, 3, 15, 9, 9, 11, 9, 11, 5, 7, 3, 3, 11, 5, 5, 13, 9, 5, 3, 11, 9, 13, 5, 15, 5, 11, 7, 9, 9, 3, 9, 11, 11, 3, 5, 3, 15, 17, 9, 3, 7, 11, 3, 13, 9, 7, 11, 3, 11, 7, 3, 15, 11, 7, 5, 7, 5, 9, 7, 9, 3, 3, 7, 3, 5, 5, 7, 5, 7, 3, 7, 15, 9, 7, 3, 9, 5, 7, 7, 5, 5, 7, 11, 5, 13, 11, 3, 3, 11, 19, 15, 3, 5, 17, 9, 23, 13, 5, 13, 3, 7, 7, 7, 15, 7, 11, 5, 17, 9, 9, 13, 5, 5, 7, 9, 7, 5, 7, 5, 5, 17, 5, 3, 11, 7, 23, 3, 5, 7, 3, 5, 7, 5, 5, 13, 7, 17, 15, 7, 15, 5, 5, 13, 11, 15, 5, 7, 5, 11, 7, 9, 7, 9, 11, 11, 11, 17, 5, 11, 9, 15, 5, 7, 25, 9, 5, 9, 13, 3, 15, 7, 5, 7, 5, 7, 11, 9, 13, 3, 9, 25, 3, 3, 13, 9, 3, 3, 11, 13, 5, 3, 3, 3, 11, 7, 11, 15, 5, 7, 11, 7, 3, 3, 5, 11, 7, 9, 5, 13, 5, 5, 7, 13, 3, 17, 7, 5, 3, 15, 13, 15, 7, 13, 7, 3, 5, 7, 5, 7, 11, 9, 11, 9, 17, 17, 11, 13, 9, 9, 13, 5, 19, 7, 17, 7, 13, 13, 9, 13, 11, 5, 5, 9, 5, 3, 3, 9, 3, 5, 7, 5, 3, 5, 3, 7, 3, 5, 13, 9, 3, 13, 13, 7, 7, 13, 11, 15, 7, 5, 5, 5, 5, 7, 7, 11, 11, 9, 5, 7, 5, 9, 7, 11, 3, 13, 5, 11, 5, 5, 19, 5, 5, 9, 3, 3, 7, 5, 5, 7, 3, 7, 17, 3, 11, 7, 9, 5, 3, 9, 5, 3, 13, 7, 5, 5, 5, 25, 3, 7, 9, 9, 11, 13, 5, 9, 19, 3, 9, 9, 9, 7, 7, 5, 23, 9, 3, 7, 13, 5, 7, 3, 5, 11, 5, 11, 3, 11, 9, 17, 9, 5, 11, 7, 11, 5, 5, 5, 3, 3, 5, 15, 11, 13, 3, 5, 9, 11, 11, 3, 5, 3, 5, 13, 5, 9, 11, 9, 5, 13, 5, 11, 9, 5, 9, 11, 9, 9, 7, 13, 11, 5, 11, 17, 9, 7, 3, 7, 5, 11, 11, 9, 11, 5, 11, 3, 11, 11, 7, 11, 5, 5, 9, 5, 5, 15, 7, 5, 7, 9, 3, 13, 3, 5, 9, 13, 11, 11, 5, 3, 9, 3, 7, 3, 3, 7, 15, 7, 5, 3, 5, 9, 7, 7, 7, 5, 3, 3, 11, 5, 5, 15, 7, 11, 7, 15, 7, 3, 5, 11, 11, 9, 7, 5, 9, 9, 5, 5, 9, 5, 7, 15, 13, 11, 19, 15, 7, 9, 9, 15, 3, 9, 7, 7, 11, 11, 11, 3, 5, 7, 15, 5, 5, 5, 13, 3, 9, 5, 3, 9, 3, 13, 7, 11, 7, 3, 7, 3, 5, 9, 5, 9, 3, 5, 7, 7, 5, 7, 7, 11, 7, 3, 9, 7, 5, 3, 7, 17, 9, 11, 7, 11, 9, 7, 11, 5, 3, 9, 11, 3, 15, 5, 7, 7, 3, 7, 13, 7, 7, 21, 7, 7, 5, 11, 13, 3, 3, 9, 9, 15, 15, 7, 15, 5, 5, 11, 5, 3, 3, 11, 3, 9, 11, 13, 9, 7, 15, 9, 11, 7, 13, 9, 15, 9, 9, 7, 7, 7, 5, 5, 9, 7, 15, 21, 7, 13, 5, 15, 9, 5, 7, 21, 5, 11, 13, 7, 15, 11, 11, 11, 9, 3, 7, 7, 3, 5, 3, 3, 9, 11, 5, 9, 3, 13, 5, 13, 7, 3, 5, 9, 5, 17, 3, 3, 9, 5, 13, 3, 5, 7, 9, 7, 7, 5, 13, 25, 5, 9, 9, 5, 3, 5, 9, 9, 7, 17, 11, 7, 3, 7, 3, 7, 3, 7, 5, 7, 11, 15, 3, 9, 7, 3, 13, 13, 5, 9, 3, 5, 3, 11, 15, 11, 15, 13, 5, 13, 11, 5, 9, 19, 5, 5, 9, 5, 7, 3, 3, 9, 3, 9, 17, 7, 7, 5, 13, 3, 3, 3, 7, 11, 7, 5, 3, 11, 7, 5, 11, 11, 11, 5, 3, 7, 5, 11, 9, 5, 5, 3, 9, 7, 9, 13, 7, 7, 7, 11, 13, 3, 11, 11, 19, 9, 3, 3, 11, 7, 9, 7, 11, 7, 7, 7, 13, 9, 5, 9, 5, 7, 7, 7, 3, 5, 7, 13, 9, 3, 7, 11, 9, 9, 7, 5, 11, 3, 7, 5, 11, 5, 15, 5, 11, 3, 7, 3, 7, 7, 9, 5, 11, 13, 15, 5, 9, 9, 7, 3, 3, 11, 19, 23, 13, 17, 7, 3, 5, 9, 3, 9, 5, 15, 3, 7, 3, 11, 5, 13, 15, 3, 9, 5, 9, 11, 13, 5, 9, 11, 11, 3, 5, 3, 7, 5, 7, 15, 7, 5, 7, 7, 9, 11, 11, 3, 13, 9, 13, 3, 7, 5, 3, 17, 3, 15, 5, 3, 3, 11, 5, 3, 5, 5, 13, 9, 9, 9, 7, 9, 9, 7, 5, 7, 15, 11, 13, 13, 9, 9, 5, 3, 3, 9, 11, 5, 13, 3, 5, 3, 13, 21, 9, 9, 5, 11, 7, 5, 5, 9, 11, 7, 5, 3, 5, 11, 5, 9, 19, 7, 5, 3, 11, 11, 5, 7, 5, 3, 3, 7, 5, 11, 5, 3, 7, 7, 5, 7, 19, 3, 11, 3, 11, 13, 3, 5, 9, 5, 5, 19, 11, 7, 5, 7, 5, 9, 5, 5, 3, 13, 17, 7, 7, 13, 9, 11, 3, 13, 11, 13, 3, 19, 19, 7, 9, 3, 9, 3, 13, 5, 13, 19, 7, 9, 11, 9, 21, 9, 7, 15, 5, 7, 11, 3, 9, 11, 5, 5, 13, 9, 9, 9, 17, 5, 15, 11, 5, 3, 11, 13, 17, 21, 11, 7, 17, 5, 5, 13, 13, 9, 5, 3, 5, 11, 7, 9, 11, 3, 9, 25, 5, 5, 3, 5, 3, 5, 5, 13, 17, 11, 3, 7, 7, 5, 3, 11, 7, 5, 5, 9, 7, 3, 9, 11, 3, 11, 11, 9, 5, 7, 3, 3, 7, 17, 17, 9, 11, 11, 13, 15, 5, 3, 7, 15, 3, 9, 11, 9, 21, 9, 7, 3, 5, 17, 13, 7, 5, 9, 3, 3, 5, 17, 7, 5, 3, 9, 13, 5, 17, 13, 5, 5, 5, 7, 5, 5, 3, 9, 7, 17, 15, 5, 7, 7, 7, 5, 9, 7, 7, 9, 9, 5, 5, 11, 15, 15, 5, 3, 13, 3, 3, 5, 5, 17, 15, 7, 15, 5, 5, 7, 3, 11, 11, 19, 13, 3, 15, 5, 5, 11, 9, 7, 3, 11, 7, 5, 3, 7, 13, 3, 3, 11, 17, 7, 19, 11, 9, 5, 7, 5, 11, 7, 9, 13, 9, 5, 3, 7, 3, 7, 13, 29, 13, 11, 13, 15, 7, 7, 11, 7, 11, 11, 15, 13, 7, 5, 9, 5, 11, 5, 11, 5, 9, 3, 3, 5, 13, 5, 9, 13, 3, 5, 5, 9, 9, 3, 5, 9, 3, 5, 5, 3, 5, 13, 5, 9, 5, 13, 7, 15, 9, 11, 7, 5, 7, 9, 7, 11, 3, 3, 5, 3, 3, 3, 5, 9, 7, 5, 11, 9, 3, 5, 9, 11, 11, 5, 15, 9, 19, 3, 15, 5, 5, 13, 5, 3, 13, 5, 3, 7, 5, 9, 3, 3, 21, 15, 5, 3, 3, 9, 7, 5, 9, 5, 5, 11, 11, 7, 9, 11, 9, 11, 5, 5, 13, 11, 11, 7, 5, 11, 13, 7, 7, 5, 9, 7, 13, 9, 13, 11, 9, 3, 15, 9, 5, 5, 9, 9, 3, 9, 21, 5, 13, 7, 5, 3, 3, 23, 17, 15, 5, 11, 15, 13, 3, 11, 7, 11, 5, 3, 5, 13, 11, 9, 3, 9, 23, 9, 5, 13, 11, 5, 13, 11, 13, 5, 5, 5, 5, 11, 9, 11, 5, 5, 13, 9, 5, 3, 11, 5, 9, 5, 13, 7, 9, 13, 19, 15, 3, 5, 11, 11, 5, 5, 11, 17, 7, 11, 11, 9, 7, 3, 5, 13, 15, 9, 3, 5, 11, 9, 11, 5, 5, 11, 9, 9, 15, 11, 11, 3, 7, 15, 7, 9, 3, 13, 9, 13, 5, 7, 3, 3, 7, 19, 9, 7, 5, 15, 3, 11, 5, 7, 5, 5, 13, 5, 7, 7, 3, 5, 3, 11, 11, 11, 7, 11, 7, 3, 5, 7, 11, 15, 7, 9, 5, 5, 5, 9, 3, 7, 5, 13, 7, 13, 11, 7, 5, 7, 13, 7, 5, 9, 9, 9, 7, 11, 11, 7, 11, 15, 5, 5, 3, 7, 7, 5, 5, 5, 7, 9, 13, 7, 7, 15, 9, 9, 11, 7, 7, 3, 13, 5, 7, 7, 13, 11, 5, 7, 3, 11, 11, 15, 3, 7, 5, 7, 11, 11, 11, 9, 13, 11, 3, 5, 5, 15, 13, 3, 25, 9, 3, 13, 9, 3, 5, 5, 9, 7, 17, 13, 11, 7, 13, 3, 13, 11, 5, 9, 13, 3, 5, 15, 11, 7, 11, 9, 5, 21, 5, 9, 15, 3, 5, 3, 9, 15, 9, 11, 15, 13, 5, 15, 13, 3, 5, 7, 15, 3, 19, 13, 11, 9, 11, 5, 7, 9, 11, 9, 11, 9, 15, 11, 25, 7, 3, 3, 13, 5, 13, 11, 19, 11, 7, 21, 13, 13, 17, 5, 7, 7, 3, 5, 11, 3, 9, 9, 5, 5, 5, 5, 17, 11, 15, 9, 11, 17, 5, 15, 11, 9, 9, 7, 13, 13, 5, 7, 13, 7, 9, 13, 11, 11, 3, 5, 13, 19, 9, 3, 7, 5, 7, 11, 13, 23, 15, 7, 5, 11, 9, 17, 7, 7, 7, 11, 15, 15, 5, 9, 11, 5, 9, 7, 9, 3, 9, 7, 5, 11, 5, 5, 5, 7, 5, 13, 9, 9, 15, 5, 9, 11, 7, 11, 11, 15, 3, 7, 5, 7, 9, 15, 5, 9, 9, 13, 11, 5, 9, 9, 13, 5, 11, 9, 5, 9, 3, 11, 7, 7, 15, 3, 5, 15, 3, 3, 11, 11, 3, 15, 5, 7, 5, 13, 9, 9, 5, 9, 5, 11, 5, 5, 3, 9, 13, 11, 7, 5, 7, 5, 3, 7, 7, 9, 7, 5, 5, 15, 9, 9, 3, 13, 3, 5, 11, 5, 9, 3, 13, 11, 5, 7, 17, 9, 3, 3, 11, 17, 7, 7, 9, 5, 5, 15, 9, 11, 17, 5, 5, 3, 9, 3, 9, 7, 9, 13, 9, 3, 9, 9, 11, 15, 11, 19, 15, 7, 7, 3, 3, 9, 5, 3, 9, 11, 7, 3, 5, 7, 7, 3, 3, 5, 7, 7, 9, 7, 7, 3, 5, 13, 9, 11, 13, 11, 3, 3, 3, 9, 11, 13, 9, 11, 3, 7, 23, 11, 3, 5, 17, 9, 13, 3, 15, 3, 5, 5, 3, 5, 11, 5, 3, 11, 9, 11, 3, 3, 11, 5, 17, 7, 7, 7, 9, 5, 7, 11, 11, 3, 11, 7, 5, 15, 7, 9, 11, 7, 5, 3, 3, 17, 7, 3, 7, 7, 5, 3, 15, 23, 11, 9, 5, 9, 9, 5, 13, 21, 15, 17, 13, 7, 13, 13, 17, 11, 9, 15, 5, 7, 5, 5, 5, 11, 15, 7, 11, 5, 9, 13, 11, 5, 5, 13, 9, 11, 7, 7, 5, 17, 11, 9, 3, 5, 3, 3, 3, 11, 9, 9, 3, 11, 15, 3, 11, 5, 5, 11, 11, 3, 5, 5, 5, 3, 3, 7, 3, 5, 11, 3, 9, 7, 9, 5, 9, 5, 3, 3, 3, 3, 21, 9, 15, 13, 5, 5, 5, 7, 5, 9, 11, 5, 11, 13, 3, 5, 5, 11, 5, 9, 5, 5, 3, 7, 5, 5, 7, 5, 3, 5, 17, 7, 5, 5, 11, 5, 11, 9, 11, 5, 11, 11, 9, 5, 3, 17, 9, 5, 7, 13, 13, 13, 7, 5, 9, 3, 3, 11, 11, 7, 3, 5, 17, 11, 7, 9, 9, 5, 11, 3, 7, 5, 13, 5, 3, 3, 3, 11, 9, 13, 15, 3, 15, 5, 3, 11, 11, 3, 9, 11, 3, 13, 9, 5, 13, 7, 3, 3, 3, 13, 3, 7, 5, 17, 9, 5, 7, 7, 7, 5, 3, 7, 15, 9, 15, 7, 9, 19, 11, 3, 17, 5, 15, 13, 5, 13, 9, 5, 11, 3, 15, 5, 15, 15, 5, 11, 7, 11, 3, 5, 13, 7, 3, 5, 3, 5, 9, 3, 3, 7, 9, 3, 13, 11, 7, 3, 5, 3, 3, 7, 7, 15, 11, 11, 17, 3, 7, 9, 15, 9, 9, 5, 7, 5, 15, 3, 9, 11, 3, 9, 5, 13, 3, 5, 3, 17, 9, 11, 5, 11, 7, 11, 3, 7, 7, 11, 5, 5, 9, 7, 7, 7, 7, 3, 7, 5, 7, 15, 5, 3, 3, 5, 3, 13, 3, 11, 5, 3, 5, 7, 5, 5, 13, 5, 11, 7, 11, 5, 11, 5, 3, 5, 5, 11, 7, 7, 9, 3, 15, 11, 5, 23, 3, 9, 15, 3, 11, 19, 5, 13, 5, 13, 9, 17, 9, 9, 9, 17, 3, 9, 9, 5, 7, 7, 3, 7, 13, 9, 11, 9, 7, 5, 9, 9, 7, 11, 5, 5, 7, 7, 7, 11, 7, 7, 5, 19, 5, 5, 5, 3, 3, 13, 7, 5, 5, 11, 5, 5, 9, 13, 5, 11, 13, 13, 5, 9, 5, 11, 7, 7, 5, 7, 7, 9, 5, 9, 5, 3, 5, 7, 15, 5, 3, 13, 11, 3, 7, 3, 9, 3, 11, 11, 3, 17, 9, 9, 5, 11, 5, 11, 7, 9, 5, 9, 13, 7, 3, 5, 9, 9, 7, 5, 3, 3, 3, 7, 5, 17, 17, 9, 11, 7, 3, 9, 11, 5, 11, 5, 11, 11, 7, 5, 9, 11, 9, 9, 3, 5, 7, 7, 3, 5, 9, 7, 5, 11, 9, 7, 3, 5, 3, 5, 19, 13, 7, 7, 5, 3, 7, 7, 11, 5, 5, 17, 7, 3, 15, 3, 5, 9, 17, 15, 9, 3, 15, 5, 7, 3, 9, 5, 5, 5, 17, 9, 7, 3, 3, 9, 7, 5, 3, 17, 11, 11, 5, 3, 11, 3, 13, 3, 11, 5, 13, 5, 11, 11, 5, 13, 9, 13, 15, 9, 23, 3, 3, 5, 19, 9, 13, 9, 5, 7, 5, 5, 3, 7, 11, 5, 5, 9, 7, 3, 7, 5, 5, 9, 9, 3, 13, 13, 5, 7, 13, 11, 7, 11, 9, 5, 7, 7, 11, 17, 11, 5, 15, 3, 9, 5, 9, 3, 11, 7, 9, 3, 5, 5, 5, 5, 11, 7, 7, 11, 23, 9, 3, 5, 3, 11, 5, 23, 9, 15, 7, 3, 3, 15, 3, 11, 13, 9, 5, 11, 5, 7, 3, 15, 9, 11, 7, 3, 3, 7, 3, 3, 7, 11, 7, 11, 3, 7, 7, 9, 3, 3, 5, 3, 9, 5, 13, 7, 5, 3, 5, 7, 11, 5, 9, 11, 5, 3, 9, 5, 7, 9, 7, 3, 9, 7, 5, 5, 7, 3, 3, 3, 13, 11, 11, 11, 9, 11, 7, 13, 9, 13, 7, 5, 11, 3, 7, 3, 11, 15, 3, 13, 9, 11, 13, 7, 13, 3, 7, 5, 11, 3, 13, 5, 17, 11, 5, 5, 5, 7, 9, 5, 5, 3, 15, 3, 9, 11, 13, 13, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 7, 5, 5, 9, 9, 19, 11, 9, 5, 5, 5, 5, 15, 11, 7, 13, 7, 9, 7, 9, 9, 15, 11, 3, 9, 15, 7, 3, 3, 3, 9, 3, 15, 3, 9, 3, 17, 9, 11, 11, 5, 13, 11, 3, 3, 11, 5, 5, 15, 5, 5, 3, 7, 3, 15, 7, 5, 5, 9, 5, 5, 7, 3, 13, 7, 3, 13, 5, 9, 5, 13, 11, 11, 5, 9, 9, 19, 7, 9, 9, 13, 15, 9, 11, 7, 7, 15, 11, 9, 17, 7, 5, 3, 21, 11, 7, 3, 7, 17, 3, 5, 13, 13, 15, 7, 5, 9, 7, 5, 3, 3, 5, 7, 7, 11, 5, 3, 9, 7, 7, 5, 9, 17, 13, 5, 3, 11, 3, 7, 15, 9, 3, 13, 9, 5, 3, 13, 11, 3, 7, 3, 17, 9, 11, 5, 7, 3, 7, 7, 5, 3, 5, 9, 7, 3, 9, 11, 5, 13, 7, 7, 3, 3, 3, 9, 13, 5, 9, 9, 17, 9, 13, 5, 9, 11, 13, 5, 11, 9, 5, 3, 5, 7, 11, 11, 13, 9, 13, 9, 9, 5, 5, 11, 15, 9, 5, 11, 5, 7, 9, 9, 3, 5, 5, 15, 11, 3, 3, 13, 11, 15, 5, 13, 9, 7, 15, 5, 7, 11, 9, 7, 13, 11, 3, 11, 9, 3, 17, 7, 9, 3, 3, 11, 3, 19, 5, 13, 5, 7, 5, 7, 13, 7, 5, 13, 13, 7, 3, 11, 3, 13, 13, 9, 15, 17, 9, 13, 5, 9, 3, 13, 11, 5, 9, 13, 5, 7, 3, 9, 13, 9, 11, 13, 11, 5, 13, 11, 15, 15, 5, 19, 7, 5, 17, 11, 19, 7, 13, 9, 7, 3, 19, 11, 9, 7, 9, 5, 13, 9, 11, 13, 3, 7, 5, 3, 9, 9, 17, 11, 5, 5, 7, 15, 17, 5, 3, 5, 11, 13, 7, 5, 5, 5, 7, 3, 3, 15, 13, 5, 11, 7, 11, 9, 7, 5, 11, 5, 3, 13, 9, 15, 7, 11, 5, 7, 11, 15, 5, 13, 7, 5, 3, 7, 13, 3, 19, 11, 7, 13, 11, 17, 13, 7, 7, 11, 5, 15, 5, 7, 9, 9, 11, 5, 13, 7, 5, 7, 5, 13, 13, 9, 3, 3, 11, 9, 9, 7, 9, 5, 17, 13, 9, 3, 13, 15, 3, 5, 3, 5, 9, 9, 5, 3, 5, 5, 7, 7, 3, 7, 5, 5, 9, 9, 3, 5, 5, 5, 11, 5, 15, 3, 7, 11, 5, 17, 11, 11, 13, 13, 3, 5, 7, 11, 3, 7, 5, 17, 5, 7, 5, 3, 9, 3, 7, 3, 19, 13, 3, 13, 3, 3, 5, 5, 7, 13, 3, 3, 3, 3, 9, 5, 13, 7, 3, 3, 7, 13, 13, 5, 13, 17, 15, 15, 7, 7, 5, 3, 9, 11, 11, 13, 7, 13, 5, 5, 9, 11, 13, 13, 11, 13, 9, 7, 13, 11, 7, 11, 5, 5, 9, 5, 15, 5, 5, 5, 7, 13, 3, 11, 7, 13, 5, 3, 9, 15, 11, 9, 5, 9, 5, 13, 7, 13, 3, 7, 11, 9, 13, 9, 11, 11, 13, 9, 7, 9, 9, 13, 9, 3, 3, 13, 3, 9, 3, 7, 9, 9, 7, 5, 5, 7, 5, 7, 7, 7, 9, 3, 9, 3, 7, 3, 11, 3, 5, 3, 9, 3, 5, 9, 13, 3, 13, 3, 7, 17, 5, 11, 13, 11, 11, 11, 21, 7, 9, 5, 7, 3, 9, 9, 5, 7, 9, 11, 5, 11, 9, 11, 13, 5, 3, 5, 17, 3, 11, 3, 13, 15, 15, 9, 3, 3, 7, 11, 15, 13, 5, 5, 5, 15, 11, 11, 11, 9, 13, 7, 11, 5, 5, 9, 9, 13, 9, 5, 5, 11, 9, 7, 15, 3, 5, 17, 9, 11, 11, 5, 15, 9, 9, 7, 11, 7, 7, 3, 17, 7, 11, 5, 17, 3, 7, 5, 3, 13, 9, 3, 5, 13, 3, 9, 5, 13, 11, 5, 11, 3, 15, 5, 11, 5, 5, 3, 7, 7, 17, 7, 13, 9, 7, 3, 7, 9, 9, 7, 13, 3, 5, 13, 11, 13, 3, 15, 3, 7, 9, 7, 19, 3, 9, 5, 9, 7, 9, 7, 3, 9, 13, 3, 5, 5, 9, 9, 13, 5, 3, 9, 5, 7, 5, 9, 11, 3, 7, 17, 7, 11, 5, 11, 11, 3, 15, 11, 9, 7, 13, 5, 5, 3, 13, 11, 15, 3, 7, 5, 11, 13, 13, 3, 13, 11, 3, 3, 11, 7, 7, 7, 9, 3, 15, 15, 5, 3, 17, 17, 3, 9, 7, 21, 7, 11, 9, 5, 7, 11, 5, 17, 3, 13, 3, 5, 7, 9, 17, 9, 9, 11, 13, 5, 7, 9, 9, 11, 19, 13, 5, 9, 9, 11, 3, 5, 5, 11, 5, 9, 9, 11, 3, 15, 15, 3, 11, 5, 13, 11, 13, 9, 3, 7, 7, 17, 5, 9, 3, 3, 13, 5, 13, 11, 7, 3, 7, 5, 13, 9, 9, 5, 7, 5, 9, 11, 11, 5, 15, 9, 5, 5, 3, 11, 5, 7, 9, 11, 9, 9, 5, 5, 7, 5, 7, 11, 7, 7, 9, 5, 11, 7, 17, 9, 11, 15, 9, 5, 9, 3, 13, 5, 7, 5, 9, 7, 13, 13, 7, 11, 11, 5, 11, 13, 11, 7, 7, 5, 17, 11, 11, 9, 9, 5, 5, 3, 11, 5, 9, 7, 17, 5, 13, 3, 3, 9, 3, 11, 13, 5, 11, 3, 5, 3, 3, 3, 9, 3, 15, 7, 11, 5, 7, 9, 9, 13, 15, 13, 5, 7, 15, 7, 9, 5, 5, 11, 13, 9, 3, 13, 9, 7, 3, 7, 7, 3, 5, 5, 5, 9, 11, 3, 13, 5, 7, 5, 7, 11, 3, 11, 5, 7, 3, 3, 9, 3, 3, 11, 9, 11, 15, 5, 9, 11, 11, 9, 7, 3, 5, 7, 13, 9, 5, 9, 13, 7, 5, 3, 5, 3, 7, 9, 7, 9, 5, 13, 19, 9, 17, 7, 15, 3, 3, 3, 5, 3, 7, 3, 5, 5, 7, 7, 3, 9, 17, 13, 5, 7, 3, 5, 15, 7, 3, 5, 11, 5, 11, 9, 5, 9, 5, 19, 5, 5, 5, 7, 3, 7, 11, 5, 3, 7, 11, 15, 11, 11, 11, 3, 7, 9, 3, 13, 11, 3, 11, 15, 17, 11, 13, 7, 3, 13, 7, 13, 13, 11, 7, 5, 3, 3, 17, 13, 5, 3, 3, 5, 5, 5, 5, 11, 11, 11, 11, 9, 3, 5, 11, 7, 3, 11, 9, 9, 9, 3, 3, 13, 5, 5, 5, 5, 5, 11, 13, 13, 19, 5, 5, 5, 5, 3, 7, 9, 9, 5, 7, 11, 15, 3, 3, 9, 3, 5, 7, 11, 7, 13, 19, 9, 9, 9, 7, 7, 5, 15, 5, 11, 3, 9, 15, 15, 5, 9, 3, 5, 9, 5, 3, 9, 5, 5, 9, 11, 15, 5, 5, 3, 11, 11, 15, 7, 7, 13, 5, 9, 5, 9, 7, 7, 15, 11, 7, 9, 9, 9, 11, 11, 11, 9, 5, 7, 11, 11, 13, 15, 11, 5, 5, 11, 9, 7, 5, 15, 15, 7, 3, 7, 13, 11, 7, 9, 11, 3, 5, 5, 19, 15, 3, 5, 19, 11, 7, 9, 9, 5, 13, 9, 5, 3, 5, 5, 17, 13, 5, 3, 5, 11, 7, 5, 5, 9, 11, 3, 5, 11, 5, 7, 15, 9, 9, 11, 5, 11, 9, 15, 5, 13, 15, 9, 19, 9, 7, 9, 15, 19, 9, 3, 5, 7, 9, 11, 9, 7, 13, 9, 7, 3, 5, 5, 13, 13, 11, 3, 9, 5, 3, 5, 5, 3, 13, 9, 17, 3, 11, 5, 5, 5, 9, 3, 13, 5, 9, 7, 3, 7, 15, 13, 13, 11, 13, 9, 5, 5, 7, 3, 9, 5, 7, 9, 9, 7, 7, 13, 9, 13, 5, 11, 11, 9, 11, 19, 7, 7, 7, 7, 5, 5, 11, 3, 3, 25, 9, 13, 5, 9, 5, 5, 11, 7, 9, 3, 5, 5, 5, 3, 7, 13, 3, 5, 5, 13, 13, 3, 13, 7, 5, 13, 15, 7, 13, 3, 9, 9, 11, 37, 9, 13, 5, 17, 5, 7, 5, 17, 11, 7, 5, 5, 9, 7, 5, 9, 7, 3, 15, 5, 3, 3, 11, 9, 13, 9, 11, 13, 13, 9, 7, 9, 15, 5, 3, 3, 3, 13, 7, 7, 9, 3, 3, 13, 5, 7, 13, 3, 3, 5, 7, 13, 11, 5, 7, 15, 7, 5, 3, 13, 3, 7, 7, 5, 7, 7, 3, 15, 5, 7, 7, 5, 5, 7, 11, 9, 9, 9, 11, 9, 9, 3, 7, 3, 5, 9, 7, 11, 17, 11, 9, 9, 3, 5, 11, 11, 3, 17, 3, 15, 17, 5, 7, 7, 7, 13, 7, 15, 17, 9, 3, 5, 7, 9, 11, 9, 3, 5, 13, 3, 7, 7, 11, 15, 5, 7, 17, 7, 9, 7, 11, 3, 7, 5, 3, 19, 19, 21, 3, 7, 5, 5, 15, 13, 5, 7, 7, 9, 7, 13, 9, 11, 19, 5, 3, 13, 13, 3, 7, 11, 11, 5, 9, 7, 5, 9, 11, 5, 9, 11, 9, 17, 3, 13, 11, 21, 9, 3, 7, 9, 9, 11, 3, 5, 11, 5, 5, 7, 3, 9, 5, 3, 7, 5, 9, 9, 15, 5, 3, 5, 7, 5, 15, 5, 5, 7, 5, 9, 3, 9, 9, 13, 7, 5, 7, 13, 9, 7, 9, 13, 7, 13, 7, 21, 5, 13, 15, 7, 3, 5, 7, 3, 5, 3, 9, 3, 13, 13, 11, 5, 11, 5, 7, 7, 5, 7, 11, 17, 9, 3, 11, 9, 7, 5, 15, 5, 7, 13, 7, 15, 5, 3, 9, 13, 11, 15, 13, 9, 15, 13, 3, 13, 3, 9, 5, 11, 3, 3, 7, 5, 3, 7, 3, 7, 3, 9, 3, 9, 3, 13, 3, 7, 15, 3, 15, 11, 3, 13, 5, 7, 3, 5, 11, 9, 5, 9, 5, 7, 3, 5, 11, 9, 5, 5, 5, 5, 11, 9, 7, 7, 11, 3, 11, 15, 7, 5, 11, 3, 5, 13, 13, 9, 13, 3, 9, 3, 15, 3, 7, 7, 17, 15, 5, 3, 3, 7, 5, 11, 13, 7, 13, 9, 11, 3, 13, 5, 9, 3, 9, 11, 7, 3, 3, 11, 5, 15, 7, 13, 13, 5, 5, 3, 5, 7, 7, 19, 9, 3, 5, 5, 3, 11, 5, 11, 5, 11, 9, 3, 3, 9, 3, 9, 13, 11, 7, 3, 9, 9, 17, 9, 9, 9, 15, 11, 3, 13, 15, 9, 11, 13, 9, 13, 11, 3, 9, 5, 3, 13, 9, 9, 5, 9, 3, 9, 5, 5, 15, 9, 3, 3, 7, 9, 5, 7, 7, 15, 9, 13, 3, 11, 7, 7, 5, 7, 11, 11, 5, 3, 7, 3, 5, 11, 11, 5, 7, 3, 3, 3, 17, 11, 9, 3, 5, 9, 7, 5, 7, 9, 5, 5, 11, 9, 9, 5, 9, 5, 13, 7, 3, 5, 9, 15, 9, 15, 3, 3, 5, 9, 5, 7, 13, 11, 3, 7, 17, 9, 13, 17, 11, 7, 7, 7, 15, 11, 11, 11, 17, 11, 3, 9, 13, 9, 11, 7, 11, 13, 13, 7, 5, 5, 3, 7, 11, 11, 5, 5, 7, 11, 9, 3, 15, 9, 5, 7, 3, 9, 9, 5, 17, 13, 13, 5, 7, 5, 9, 5, 3, 3, 13, 7, 9, 19, 9, 5, 11, 5, 3, 13, 7, 5, 9, 15, 3, 11, 5, 13, 9, 7, 3, 5, 17, 9, 3, 5, 13, 9, 11, 5, 11, 5, 5, 11, 5, 11, 5, 9, 21, 7, 7, 13, 3, 11, 13, 11, 9, 7, 19, 3, 21, 9, 11, 11, 9, 11, 9, 3, 7, 5, 13, 11, 15, 3, 13, 9, 5, 9, 9, 7, 9, 5, 13, 7, 11, 9, 9, 9, 5, 9, 15, 13, 3, 13, 13, 5, 7, 5, 9, 5, 7, 9, 15, 13, 11, 7, 5, 23, 5, 5, 3, 7, 5, 9, 7, 15, 3, 9, 7, 11, 7, 5, 3, 15, 15, 3, 7, 5, 9, 17, 7, 9, 7, 11, 5, 9, 7, 7, 7, 5, 3, 15, 5, 13, 5, 5, 5, 5, 3, 3, 7, 7, 5, 3, 5, 13, 5, 11, 3, 13, 5, 9, 17, 3, 11, 7, 11, 7, 3, 7, 5, 7, 11, 19, 5, 15, 7, 5, 3, 9, 7, 7, 9, 3, 5, 7, 3, 9, 3, 7, 11, 11, 7, 15, 5, 5, 9, 9, 7, 9, 5, 7, 7, 9, 15, 5, 17, 7, 13, 13, 7, 5, 11, 5, 11, 5, 11, 7, 5, 11, 17, 13, 13, 5, 11, 13, 13, 9, 7, 15, 9, 7, 5, 5, 5, 3, 7, 13, 9, 3, 11, 13, 15, 15, 5, 13, 5, 3, 5, 9, 3, 3, 11, 7, 3, 9, 5, 5, 9, 9, 5, 5, 13, 13, 9, 9, 3, 11, 5, 15, 13, 3, 7, 15, 5, 15, 3, 5, 7, 3, 9, 3, 9, 7, 11, 21, 7, 7, 9, 9, 7, 17, 3, 11, 3, 9, 9, 13, 9, 13, 5, 5, 9, 5, 15, 15, 11, 3, 11, 7, 17, 7, 7, 9, 13, 7, 3, 13, 3, 7, 5, 5, 13, 7, 7, 3, 11, 13, 11, 9, 11, 7, 13, 7, 7, 7, 5, 5, 3, 11, 3, 5, 7, 9, 9, 3, 5, 3, 3, 11, 9, 3, 9, 9, 9, 5, 7, 13, 5, 19, 9, 15, 17, 3, 23, 11, 5, 5, 13, 13, 13, 11, 13, 11, 9, 15, 9, 15, 5, 15, 3, 5, 3, 7, 5, 7, 7, 3, 5, 9, 17, 3, 13, 9, 5, 5, 7, 5, 9, 7, 5, 9, 13, 5, 5, 11, 11, 11, 3, 3, 7, 7, 7, 9, 13, 3, 5, 9, 7, 5, 5, 13, 15, 3, 7, 5, 3, 7, 5, 7, 11, 7, 9, 7, 9, 17, 7, 9, 5, 19, 7, 9, 7, 11, 11, 5, 13, 5, 13, 3, 9, 5, 17, 7, 5, 9, 3, 5, 9, 15, 11, 9, 11, 5, 5, 15, 9, 5, 11, 5, 3, 3, 13, 5, 17, 11, 5, 7, 3, 17, 7, 13, 7, 11, 5, 13, 15, 5, 7, 5, 3, 5, 7, 13, 9, 11, 9, 7, 9, 5, 3, 15, 5, 13, 5, 3, 13, 7, 13, 3, 13, 19, 9, 5, 3, 9, 11, 11, 5, 7, 3, 9, 13, 7, 7, 3, 5, 7, 15, 9, 3, 5, 3, 3, 19, 5, 7, 9, 3, 9, 13, 3, 11, 9, 3, 7, 13, 9, 7, 5, 13, 17, 13, 5, 5, 7, 11, 7, 3, 23, 9, 3, 9, 9, 9, 11, 7, 5, 7, 7, 3, 7, 21, 13, 7, 9, 5, 5, 11, 15, 11, 7, 7, 3, 15, 9, 7, 9, 5, 9, 9, 19, 5, 7, 5, 7, 5, 13, 5, 5, 17, 9, 7, 3, 15, 7, 13, 9, 15, 17, 11, 9, 13, 17, 9, 5, 13, 3, 5, 7, 5, 9, 15, 11, 3, 9, 9, 7, 9, 9, 3, 3, 3, 11, 7, 5, 7, 19, 3, 9, 7, 11, 9, 11, 5, 13, 5, 5, 11, 3, 7, 5, 13, 11, 9, 3, 5, 13, 11, 7, 7, 5, 3, 9, 5, 15, 5, 9, 9, 11, 3, 7, 7, 7, 11, 13, 5, 7, 13, 3, 19, 5, 5, 13, 9, 17, 5, 9, 9, 3, 13, 17, 17, 9, 9, 7, 3, 11, 15, 11, 5, 7, 11, 7, 7, 13, 9, 13, 5, 5, 7, 5, 7, 13, 5, 5, 13, 7, 3, 9, 7, 5, 13, 13, 5, 7, 5, 3, 9, 7, 11, 11, 3, 5, 7, 13, 5, 17, 5, 15, 15, 15, 7, 3, 7, 7, 9, 7, 19, 9, 11, 5, 5, 3, 9, 3, 3, 5, 5, 5, 5, 11, 7, 9, 7, 9, 3, 13, 11, 7, 5, 13, 3, 7, 7, 5, 15, 31, 7, 5, 11, 5, 3, 13, 15, 7, 13, 5, 9, 11, 9, 11, 13, 3, 13, 13, 7, 11, 9, 7, 11, 5, 5, 9, 5, 11, 9, 9, 9, 9, 13, 7, 7, 7, 11, 9, 5, 17, 5, 11, 9, 9, 3, 11, 3, 5, 3, 3, 11, 3, 5, 13, 7, 5, 5, 5, 17, 15, 15, 7, 11, 11, 3, 11, 5, 9, 11, 7, 5, 3, 5, 15, 13, 7, 5, 13, 3, 7, 5, 5, 5, 3, 3, 15, 11, 13, 7, 5, 5, 7, 3, 7, 11, 5, 11, 17, 11, 11, 13, 13, 11, 23, 7, 5, 3, 11, 7, 13, 3, 15, 11, 7, 3, 9, 3, 7, 11, 3, 13, 5, 3, 3, 7, 5, 15, 13, 3, 9, 11, 9, 15, 5, 9, 9, 15, 11, 5, 9, 5, 5, 7, 5, 5, 5, 11, 7, 11, 17, 13, 5, 7, 5, 3, 13, 7, 3, 5, 11, 5, 5, 5, 7, 7, 5, 5, 5, 11, 9, 37, 3, 9, 9, 11, 3, 9, 11, 9, 7, 3, 9, 5, 11, 5, 5, 11, 9, 7, 13, 7, 13, 5, 5, 3, 11, 9, 3, 9, 9, 7, 9, 3, 3, 19, 11, 11, 9, 5, 15, 11, 3, 13, 23, 3, 13, 7, 5, 5, 5, 3, 3, 5, 15, 13, 5, 5, 11, 3, 11, 11, 15, 7, 3, 13, 3, 7, 3, 11, 13, 5, 9, 11, 11, 11, 7, 9, 5, 3, 7, 3, 9, 3, 13, 5, 15, 13, 5, 9, 7, 15, 11, 3, 5, 11, 7, 7, 7, 7, 5, 13, 17, 7, 9, 3, 7, 9, 9, 13, 5, 17, 9, 7, 5, 17, 13, 19, 3, 5, 19, 7, 5, 7, 13, 5, 13, 5, 7, 3, 3, 9, 5, 5, 7, 5, 3, 5, 13, 7, 7, 11, 9, 9, 9, 9, 5, 15, 5, 5, 17, 5, 11, 11, 7, 9, 17, 7, 13, 11, 5, 7, 17, 3, 7, 3, 7, 3, 11, 7, 9, 11, 7, 3, 7, 5, 5, 7, 11, 7, 3, 13, 3, 5, 13, 11, 5, 5, 5, 5, 7, 7, 9, 3, 7, 7, 5, 11, 7, 15, 11, 7, 7, 9, 19, 5, 3, 11, 7, 21, 7, 3, 5, 3, 9, 5, 15, 3, 9, 7, 5, 5, 3, 5, 7, 15, 7, 7, 9, 3, 15, 9, 11, 9, 7, 11, 13, 9, 11, 5, 9, 11, 5, 13, 13, 5, 11, 3, 15, 13, 11, 11, 15, 11, 15, 5, 9, 9, 3, 5, 9, 5, 5, 17, 7, 9, 5, 11, 3, 5, 3, 9, 3, 7, 7, 7, 9, 5, 5, 3, 3, 13, 5, 3, 9, 7, 9, 9, 5, 7, 7, 9, 15, 17, 5, 9, 11, 7, 9, 3, 7, 5, 5, 9, 11, 3, 9, 7, 11, 9, 7, 9, 11, 5, 5, 7, 7, 9, 11, 7, 3, 5, 9, 9, 9, 5, 7, 7, 11, 11, 15, 7, 11, 3, 5, 13, 7, 7, 7, 7, 7, 15, 9, 7, 9, 15, 11, 5, 3, 11, 7, 9, 5, 9, 13, 7, 15, 9, 17, 3, 13, 7, 15, 13, 9, 13, 7, 7, 7, 9, 7, 17, 5, 7, 5, 5, 13, 3, 9, 3, 7, 5, 5, 13, 11, 5, 7, 5, 15, 7, 7, 9, 11, 5, 5, 7, 9, 7, 7, 5, 5, 13, 9, 5, 5, 13, 11, 7, 7, 15, 15, 15, 11, 7, 11, 7, 3, 5, 13, 5, 13, 11, 11, 13, 9, 3, 11, 9, 9, 3, 7, 11, 9, 5, 3, 7, 11, 9, 9, 5, 3, 7, 7, 7, 15, 7, 9, 13, 13, 5, 15, 13, 5, 9, 19, 15, 15, 5, 3, 11, 5, 7, 7, 9, 5, 11, 9, 7, 9, 11, 9, 11, 3, 3, 7, 7, 3, 3, 17, 5, 15, 3, 13, 5, 3, 7, 15, 11, 21, 5, 11, 15, 5, 13, 19, 9, 9, 3, 11, 5, 5, 9, 5, 5, 9, 5, 5, 9, 9, 17, 3, 9, 15, 3, 19, 15, 3, 15, 17, 17, 13, 3, 7, 9, 3, 5, 5, 9, 5, 5, 3, 9, 7, 15, 5, 9, 7, 7, 7, 9, 3, 9, 21, 15, 15, 5, 3, 5, 7, 5, 7, 5, 15, 11, 5, 15, 7, 5, 17, 19, 7, 9, 5, 17, 5, 7, 9, 5, 9, 7, 5, 13, 7, 5, 7, 13, 9, 9, 15, 3, 15, 9, 17, 5, 11, 5, 3, 5, 9, 13, 11, 17, 3, 9, 7, 3, 3, 17, 7, 3, 11, 9, 15, 9, 3, 5, 3, 5, 17, 9, 11, 3, 5, 11, 3, 11, 7, 3, 11, 11, 5, 17, 7, 9, 13, 7, 5, 11, 11, 5, 7, 21, 11, 7, 5, 9, 3, 9, 5, 3, 5, 13, 3, 19, 11, 5, 7, 3, 11, 5, 7, 3, 11, 7, 9, 5, 11, 13, 9, 5, 3, 13, 9, 3, 13, 5, 11, 3, 21, 5, 11, 21, 7, 11, 9, 5, 9, 7, 5, 13, 9, 9, 5, 3, 15, 3, 9, 3, 13, 7, 5, 5, 13, 11, 5, 5, 17, 3, 3, 15, 5, 5, 5, 3, 11, 9, 13, 5, 15, 5, 3, 13, 11, 9, 3, 19, 5, 5, 9, 13, 5, 3, 11, 15, 3, 9, 11, 11, 15, 7, 5, 13, 5, 5, 9, 5, 5, 3, 9, 5, 5, 11, 23, 3, 11, 15, 7, 15, 3, 3, 5, 7, 3, 11, 7, 7, 11, 3, 5, 11, 3, 5, 7, 11, 5, 3, 5, 7, 7, 17, 5, 13, 3, 5, 11, 13, 3, 15, 23, 3, 11, 11, 9, 3, 13, 13, 13, 11, 7, 9, 11, 11, 13, 5, 9, 13, 3, 13, 11, 7, 5, 7, 3, 7, 11, 3, 5, 11, 17, 7, 9, 11, 3, 5, 17, 9, 15, 7, 9, 3, 5, 5, 13, 7, 7, 11, 13, 9, 5, 3, 9, 7, 9, 7, 5, 11, 9, 7, 3, 9, 9, 5, 5, 7, 5, 11, 5, 5, 11, 7, 7, 7, 3, 15, 7, 7, 5, 9, 5, 3, 7, 3, 3, 5, 7, 11, 11, 9, 13, 11, 19, 7, 17, 11, 19, 5, 3, 3, 3, 15, 3, 3, 5, 5, 3, 7, 9, 9, 3, 9, 5, 5, 5, 5, 17, 3, 13, 3, 13, 9, 5, 3, 5, 37, 9, 7, 7, 9, 9, 3, 7, 3, 7, 9, 3, 19, 3, 5, 9, 3, 9, 15, 7, 11, 3, 9, 9, 9, 9, 15, 13, 13, 5, 9, 7, 5, 13, 5, 5, 5, 5, 7, 17, 9, 3, 3, 9, 5, 3, 13, 5, 11, 5, 13, 11, 5, 7, 11, 5, 3, 13, 7, 3, 7, 5, 5, 9, 17, 13, 9, 19, 5, 11, 9, 7, 3, 3, 9, 9, 5, 11, 9, 13, 3, 7, 11, 5, 7, 11, 3, 13, 11, 17, 3, 7, 9, 7, 9, 11, 9, 5, 5, 11, 3, 9, 3, 3, 5, 9, 13, 27, 7, 9, 7, 5, 3, 11, 7, 9, 3, 15, 5, 5, 5, 3, 3, 3, 11, 15, 5, 3, 11, 9, 5, 5, 9, 5, 3, 7, 11, 11, 7, 3, 11, 5, 11, 19, 7, 7, 13, 11, 11, 5, 3, 11, 5, 11, 5, 7, 5, 13, 5, 5, 7, 7, 5, 5, 11, 5, 5, 11, 3, 5, 3, 7, 17, 5, 3, 5, 3, 7, 21, 5, 9, 7, 3, 9, 11, 7, 13, 11, 9, 3, 9, 9, 7, 7, 9, 11, 7, 13, 5, 13, 7, 7, 3, 11, 13, 5, 11, 5, 7, 21, 9, 13, 7, 17, 7, 7, 13, 3, 15, 5, 5, 11, 7, 7, 3, 5, 3, 7, 7, 7, 7, 7, 9, 13, 5, 3, 5, 13, 11, 13, 3, 3, 5, 11, 15, 5, 9, 11, 7, 9, 7, 11, 9, 9, 3, 3, 13, 15, 13, 7, 11, 7, 7, 7, 5, 7, 9, 11, 17, 9, 7, 7, 9, 9, 13, 3, 13, 5, 11, 5, 5, 3, 5, 3, 7, 7, 17, 3, 5, 5, 5, 9, 5, 11, 9, 11, 5, 5, 13, 5, 9, 9, 7, 5, 9, 11, 7, 5, 3, 9, 9, 5, 5, 5, 3, 17, 13, 13, 9, 9, 5, 3, 11, 11, 11, 7, 7, 3, 11, 9, 5, 5, 13, 11, 3, 9, 3, 5, 9, 9, 5, 5, 5, 5, 9, 13, 5, 5, 7, 13, 9, 3, 11, 13, 3, 15, 15, 5, 17, 3, 11, 7, 3, 7, 15, 11, 5, 5, 9, 15, 5, 13, 13, 5, 7, 7, 5, 5, 9, 19, 5, 11, 11, 13, 7, 7, 5, 5, 7, 7, 5, 3, 5, 7, 5, 9, 7, 11, 3, 5, 5, 11, 11, 3, 3, 15, 7, 5, 13, 9, 17, 3, 9, 11, 5, 7, 3, 11, 15, 5, 5, 9, 7, 13, 3, 7, 9, 11, 11, 7, 7, 5, 9, 11, 7, 13, 3, 3, 5, 5, 9, 3, 5, 5, 3, 13, 15, 3, 5, 5, 3, 9, 5, 9, 13, 3, 3, 7, 5, 13, 3, 5, 5, 7, 7, 13, 7, 9, 13, 5, 13, 11, 13, 7, 7, 5, 7, 9, 7, 7, 13, 11, 5, 13, 7, 11, 5, 11, 3, 9, 3, 7, 5, 11, 9, 9, 7, 7, 15, 9, 5, 9, 5, 5, 9, 9, 7, 5, 11, 11, 11, 17, 11, 3, 7, 9, 3, 7, 7, 9, 11, 7, 5, 9, 7, 11, 3, 9, 5, 5, 9, 9, 17, 11, 7, 13, 13, 7, 7, 11, 9, 11, 5, 7, 9, 11, 5, 3, 9, 13, 11, 9, 3, 5, 3, 7, 9, 5, 9, 7, 3, 3, 13, 13, 7, 13, 9, 3, 7, 3, 5, 7, 5, 5, 3, 17, 7, 7, 3, 11, 5, 5, 15, 5, 13, 17, 5, 3, 7, 7, 5, 11, 3, 13, 5, 7, 3, 3, 17, 9, 17, 5, 7, 11, 9, 13, 3, 5, 5, 3, 13, 13, 7, 11, 5, 15, 7, 7, 5, 13, 9, 13, 3, 5, 5, 17, 7, 5, 7, 7, 7, 7, 5, 5, 7, 9, 5, 5, 3, 13, 7, 9, 13, 7, 19, 11, 7, 3, 7, 11, 17, 7, 13, 9, 7, 5, 5, 3, 9, 9, 5, 9, 9, 7, 13, 3, 7, 7, 5, 9, 7, 7, 9, 17, 11, 9, 7, 11, 7, 3, 11, 11, 7, 17, 3, 3, 7, 15, 7, 11, 5, 3, 9, 9, 13, 5, 5, 13, 3, 11, 11, 3, 15, 3, 15, 9, 3, 7, 5, 5, 3, 15, 5, 5, 11, 5, 17, 17, 9, 11, 11, 9, 5, 11, 5, 9, 5, 5, 5, 5, 5, 11, 9, 7, 9, 7, 9, 5, 3, 5, 5, 13, 9, 17, 11, 9, 7, 7, 5, 19, 13, 7, 9, 5, 17, 11, 19, 13, 11, 5, 13, 9, 5, 11, 3, 9, 13, 7, 7, 5, 19, 11, 3, 11, 5, 7, 3, 5, 5, 7, 11, 9, 9, 11, 3, 25, 7, 9, 7, 7, 11, 11, 17, 5, 15, 11, 7, 9, 13, 7, 11, 11, 17, 9, 15, 13, 5, 13, 11, 13, 11, 13, 5, 11, 5, 5, 5, 3, 7, 5, 11, 7, 15, 9, 5, 5, 11, 13, 9, 5, 5, 11, 3, 11, 5, 15, 7, 7, 5, 7, 5, 9, 5, 3, 5, 13, 17, 17, 3, 7, 15, 9, 5, 7, 11, 15, 3, 9, 11, 5, 3, 11, 9, 5, 7, 11, 5, 7, 11, 19, 11, 5, 13, 3, 11, 13, 11, 5, 9, 5, 5, 3, 9, 13, 5, 5, 13, 13, 7, 15, 3, 9, 9, 11, 5, 5, 11, 7, 9, 7, 9, 7, 5, 7, 13, 5, 15, 11, 11, 9, 3, 3, 5, 11, 11, 3, 9, 3, 3, 3, 11, 11, 9, 27, 9, 5, 9, 9, 9, 7, 19, 9, 5, 5, 3, 13, 7, 9, 17, 17, 7, 5, 15, 5, 5, 7, 7, 9, 9, 9, 5, 7, 9, 7, 3, 9, 15, 13, 11, 11, 3, 11, 5, 3, 15, 3, 7, 13, 13, 11, 3, 9, 9, 7, 15, 5, 5, 9, 15, 3, 9, 17, 9, 9, 7, 5, 11, 15, 15, 13, 15, 17, 5, 13, 9, 15, 11, 9, 9, 3, 7, 5, 11, 5, 3, 19, 11, 5, 7, 7, 7, 5, 3, 11, 7, 7, 9, 11, 15, 15, 7, 7, 5, 11, 15, 13, 7, 7, 17, 9, 11, 13, 15, 5, 13, 3, 5, 15, 3, 11, 3, 9, 7, 5, 5, 3, 13, 5, 17, 11, 9, 13, 13, 3, 5, 5, 5, 13, 9, 3, 3, 7, 5, 15, 3, 11, 11, 11, 7, 3, 3, 11, 7, 11, 7, 5, 3, 3, 9, 19, 9, 3, 9, 9, 3, 11, 7, 13, 7, 11, 11, 7, 9, 7, 7, 5, 5, 3, 5, 13, 13, 13, 11, 7, 5, 7, 11, 9, 9, 5, 15, 9, 9, 3, 11, 5, 7, 11, 7, 3, 11, 9, 7, 11, 13, 3, 5, 11, 15, 21, 9, 11, 11, 13, 13, 7, 9, 3, 7, 11, 11, 9, 7, 7, 11, 3, 5, 9, 7, 9, 5, 7, 3, 13, 13, 3, 13, 5, 11, 15, 13, 11, 11, 9, 7, 9, 11, 17, 5, 7, 5, 3, 11, 7, 9, 7, 5, 3, 3, 3, 5, 21, 11, 5, 9, 5, 9, 5, 5, 7, 3, 3, 5, 11, 9, 3, 7, 3, 13, 13, 5, 17, 9, 7, 15, 15, 11, 5, 13, 3, 11, 7, 9, 7, 5, 3, 17, 17, 9, 5, 15, 9, 5, 7, 9, 7, 5, 9, 7, 9, 3, 9, 7, 5, 9, 3, 7, 7, 3, 15, 3, 9, 7, 7, 13, 11, 11, 5, 5, 9, 5, 7, 5, 9, 5, 13, 11, 5, 5, 3, 3, 3, 7, 3, 9, 7, 15, 9, 5, 11, 19, 7, 21, 13, 7, 13, 5, 7, 15, 13, 9, 9, 5, 5, 9, 5, 5, 19, 7, 9, 5, 3, 3, 11, 11, 5, 3, 13, 3, 7, 3, 13, 7, 3, 5, 3, 11, 3, 9, 7, 7, 9, 5, 7, 13, 11, 3, 7, 5, 11, 11, 7, 11, 7, 5, 5, 3, 13, 7, 7, 3, 11, 5, 5, 9, 9, 9, 3, 5, 15, 9, 15, 5, 9, 7, 7, 3, 15, 7, 11, 11, 7, 9, 11, 5, 15, 5, 11, 7, 13, 11, 9, 5, 13, 7, 9, 15, 11, 5, 13, 9, 13, 5, 5, 11, 13, 3, 3, 15, 5, 13, 5, 21, 5, 5, 5, 5, 7, 5, 13, 7, 5, 5, 7, 9, 13, 11, 3, 5, 9, 13, 3, 5, 11, 13, 5, 7, 7, 3, 3, 7, 5, 11, 7, 11, 13, 5, 11, 5, 7, 3, 3, 13, 7, 15, 5, 5, 5, 7, 13, 5, 7, 3, 15, 3, 11, 3, 11, 11, 5, 15, 13, 5, 7, 7, 3, 3, 7, 5, 9, 13, 11, 17, 15, 17, 11, 5, 3, 5, 5, 5, 9, 7, 13, 13, 17, 9, 5, 5, 13, 7, 3, 13, 5, 15, 5, 7, 15, 9, 7, 11, 7, 5, 5, 9, 7, 15, 7, 7, 15, 9, 11, 5, 3, 11, 7, 3, 7, 5, 7, 5, 3, 5, 9, 15, 5, 5, 5, 9, 15, 7, 7, 15, 11, 3, 9, 9, 5, 7, 11, 5, 11, 11, 5, 11, 5, 5, 7, 11, 3, 7, 9, 9, 7, 9, 3, 11, 7, 19, 5, 15, 5, 3, 5, 5, 7, 13, 9, 5, 13, 13, 3, 3, 3, 9, 3, 7, 15, 3, 5, 15, 11, 13, 11, 17, 3, 5, 17, 3, 7, 5, 11, 5, 17, 7, 11, 7, 11, 15, 7, 9, 3, 11, 17, 11, 9, 9, 11, 7, 7, 9, 15, 11, 9, 5, 3, 13, 17, 7, 5, 5, 9, 5, 7, 5, 3, 5, 7, 7, 9, 9, 9, 5, 11, 11, 7, 13, 7, 11, 5, 9, 19, 11, 5, 13, 9, 7, 5, 11, 11, 11, 3, 11, 9, 9, 7, 15, 3, 7, 5, 3, 5, 5, 5, 15, 9, 15, 3, 3, 9, 13, 13, 17, 7, 13, 15, 9, 5, 5, 5, 17, 5, 13, 3, 5, 9, 3, 17, 15, 11, 3, 3, 3, 7, 5, 13, 3, 13, 9, 9, 9, 9, 9, 3, 7, 7, 9, 7, 3, 9, 5, 7, 7, 3, 3, 11, 5, 5, 13, 9, 7, 9, 5, 11, 5, 13, 7, 5, 15, 3, 11, 3, 5, 13, 9, 9, 5, 3, 5, 13, 13, 15, 21, 7, 9, 5, 21, 3, 3, 7, 11, 7, 11, 9, 7, 13, 7, 15, 5, 13, 23, 15, 11, 3, 3, 11, 9, 11, 3, 5, 13, 9, 7, 9, 3, 15, 3, 5, 5, 5, 13, 7, 9, 25, 11, 11, 3, 9, 17, 5, 9, 13, 9, 19, 5, 9, 5, 9, 7, 9, 13, 9, 15, 9, 9, 5, 5, 3, 5, 5, 7, 9, 5, 19, 9, 9, 3, 15, 5, 3, 9, 11, 11, 7, 17, 7, 7, 3, 15, 3, 7, 9, 11, 5, 15, 7, 11, 11, 3, 9, 5, 7, 7, 3, 5, 13, 9, 11, 11, 3, 9, 5, 11, 13, 5, 11, 3, 3, 9, 5, 5, 7, 15, 3, 5, 17, 9, 13, 3, 3, 11, 5, 5, 9, 11, 9, 9, 7, 7, 9, 5, 11, 5, 7, 5, 5, 7, 5, 7, 9, 3, 15, 9, 3, 7, 5, 5, 21, 13, 3, 17, 5, 3, 9, 5, 7, 9, 19, 3, 13, 5, 11, 13, 7, 5, 11, 7, 7, 3, 9, 5, 11, 9, 3, 3, 11, 17, 11, 7, 11, 11, 7, 7, 11, 7, 11, 7, 3, 13, 17, 7, 5, 7, 17, 3, 11, 15, 11, 11, 13, 5, 7, 3, 17, 13, 15, 3, 3, 15, 3, 7, 9, 11, 3, 19, 7, 9, 13, 13, 3, 3, 3, 7, 21, 5, 7, 17, 3, 5, 7, 11, 5, 5, 3, 7, 11, 11, 5, 9, 9, 9, 9, 5, 3, 13, 7, 5, 7, 11, 7, 3, 5, 9, 17, 3, 9, 17, 5, 13, 3, 13, 9, 3, 11, 11, 9, 11, 7, 3, 3, 7, 7, 9, 5, 5, 7, 3, 7, 13, 11, 5, 9, 9, 5, 7, 7, 5, 5, 5, 9, 13, 13, 5, 15, 9, 9, 5, 9, 9, 5, 7, 7, 15, 5, 9, 13, 7, 9, 17, 3, 5, 3, 13, 11, 5, 11, 9, 5, 5, 5, 5, 7, 7, 5, 3, 11, 5, 3, 15, 11, 11, 7, 17, 9, 3, 9, 13, 13, 7, 11, 9, 9, 9, 11, 7, 13, 13, 11, 7, 11, 5, 5, 5, 11, 9, 5, 13, 3, 7, 13, 3, 7, 5, 15, 3, 5, 7, 9, 11, 13, 3, 9, 5, 5, 7, 17, 3, 11, 11, 13, 7, 13, 13, 13, 7, 9, 5, 11, 11, 3, 25, 5, 11, 5, 7, 11, 3, 15, 11, 9, 7, 5, 9, 11, 3, 7, 9, 3, 9, 5, 7, 3, 7, 9, 5, 7, 7, 5, 7, 3, 9, 9, 15, 5, 5, 7, 15, 7, 13, 9, 11, 13, 13, 5, 9, 13, 11, 3, 15, 7, 5, 5, 15, 15, 7, 5, 11, 11, 9, 3, 9, 11, 5, 5, 5, 7, 9, 5, 9, 7, 9, 13, 5, 11, 5, 9, 11, 7, 3, 17, 13, 5, 7, 9, 11, 7, 5, 13, 11, 5, 11, 11, 5, 7, 9, 11, 3, 11, 7, 5, 7, 5, 5, 11, 7, 9, 5, 13, 5, 5, 25, 5, 7, 7, 9, 11, 17, 9, 3, 15, 13, 3, 9, 5, 3, 5, 5, 5, 7, 7, 5, 17, 17, 5, 7, 5, 3, 3, 9, 7, 11, 5, 5, 11, 9, 31, 3, 11, 9, 5, 9, 17, 21, 7, 9, 5, 9, 13, 7, 13, 5, 3, 7, 3, 3, 11, 3, 13, 5, 5, 13, 11, 5, 13, 5, 7, 9, 5, 9, 5, 5, 9, 13, 9, 9, 3, 5, 3, 9, 11, 5, 13, 13, 15, 9, 3, 9, 9, 7, 17, 3, 13, 5, 11, 7, 7, 3, 13, 11, 19, 7, 9, 5, 5, 7, 5, 13, 9, 5, 3, 7, 5, 15, 5, 5, 9, 13, 3, 11, 3, 15, 15, 11, 3, 13, 3, 3, 3, 5, 7, 9, 9, 9, 21, 7, 5, 7, 17, 7, 11, 9, 7, 5, 9, 7, 3, 5, 11, 9, 11, 9, 9, 11, 15, 7, 3, 11, 7, 5, 9, 5, 9, 11, 13, 11, 5, 3, 7, 5, 5, 9, 7, 17, 5, 11, 5, 7, 3, 7, 11, 21, 5, 7, 9, 5, 7, 9, 5, 7, 11, 15, 9, 5, 9, 7, 3, 5, 5, 7, 5, 9, 7, 5, 11, 9, 11, 23, 3, 11, 11, 7, 3, 7, 9, 11, 9, 9, 7, 11, 3, 5, 15, 11, 3, 7, 7, 13, 3, 3, 11, 9, 15, 7, 11, 15, 19, 9, 7, 3, 9, 9, 19, 13, 7, 13, 3, 3, 15, 7, 7, 15, 7, 5, 11, 9, 13, 15, 7, 7, 7, 5, 9, 3, 5, 3, 5, 13, 3, 15, 11, 5, 11, 13, 5, 5, 9, 11, 7, 11, 11, 5, 13, 3, 11, 13, 3, 5, 9, 11, 9, 9, 11, 13, 3, 9, 11, 9, 7, 3, 9, 7, 3, 19, 13, 7, 7, 5, 11, 3, 3, 5, 9, 5, 5, 3, 3, 11, 3, 3, 17, 7, 3, 7, 13, 5, 21, 11, 7, 11, 9, 5, 7, 3, 3, 11, 21, 5, 13, 19, 13, 5, 11, 5, 7, 5, 11, 3, 5, 9, 9, 11, 9, 7, 9, 11, 9, 7, 3, 3, 15, 7, 7, 19, 13, 9, 7, 13, 7, 13, 9, 5, 7, 5, 5, 9, 7, 5, 5, 7, 3, 3, 5, 17, 5, 7, 11, 5, 15, 9, 9, 11, 5, 5, 7, 15, 15, 7, 7, 5, 3, 13, 5, 9, 13, 3, 5, 11, 5, 3, 11, 9, 5, 7, 9, 5, 9, 11, 7, 3, 3, 13, 9, 15, 5, 9, 13, 13, 11, 7, 11, 11, 9, 7, 5, 11, 3, 11, 13, 9, 7, 11, 5, 9, 5, 3, 5, 15, 17, 3, 19, 9, 13, 7, 3, 3, 13, 9, 5, 11, 15, 5, 5, 11, 3, 11, 5, 13, 9, 3, 7, 9, 3, 9, 3, 9, 7, 7, 5, 5, 7, 5, 7, 11, 5, 9, 11, 7, 7, 3, 9, 19, 7, 3, 7, 11, 3, 3, 7, 11, 5, 9, 21, 7, 11, 11, 3, 3, 7, 19, 3, 9, 15, 11, 13, 7, 13, 17, 7, 5, 3, 7, 3, 7, 9, 9, 3, 15, 3, 5, 3, 3, 5, 13, 11, 17, 5, 15, 13, 11, 5, 5, 7, 7, 7, 11, 5, 3, 5, 5, 13, 9, 21, 9, 5, 9, 7, 5, 15, 3, 7, 9, 3, 13, 9, 15, 9, 11, 7, 11, 5, 9, 11, 21, 5, 5, 3, 5, 9, 9, 9, 5, 15, 9, 9, 15, 21, 9, 9, 13, 5, 11, 13, 7, 5, 5, 11, 13, 11, 13, 11, 13, 9, 13, 11, 9, 5, 13, 11, 5, 5, 3, 15, 3, 5, 9, 13, 7, 9, 7, 11, 17, 11, 15, 7, 3, 3, 11, 9, 9, 7, 5, 5, 9, 3, 17, 9, 5, 7, 7, 13, 11, 3, 15, 5, 9, 11, 7, 5, 11, 7, 5, 5, 7, 11, 5, 7, 7, 9, 5, 17, 5, 11, 3, 11, 5, 13, 3, 5, 7, 5, 5, 9, 27, 3, 5, 15, 5, 5, 5, 5, 7, 9, 9, 5, 23, 15, 5, 11, 9, 11, 7, 11, 3, 5, 3, 3, 15, 15, 5, 7, 9, 5, 11, 9, 7, 7, 13, 5, 11, 3, 5, 11, 13, 7, 13, 3, 11, 11, 7, 13, 3, 3, 11, 5, 3, 3, 7, 5, 5, 13, 3, 13, 5, 15, 11, 3, 11, 3, 7, 9, 9, 19, 15, 3, 9, 7, 7, 9, 11, 11, 3, 11, 7, 7, 9, 15, 13, 15, 3, 5, 11, 11, 9, 5, 3, 7, 7, 11, 11, 7, 7, 7, 3, 11, 5, 15, 13, 11, 5, 7, 5, 3, 7, 15, 9, 3, 7, 3, 9, 5, 5, 11, 11, 13, 9, 19, 3, 9, 9, 17, 5, 11, 3, 5, 5, 7, 5, 13, 5, 3, 13, 17, 13, 3, 9, 13, 11, 7, 9, 7, 5, 11, 9, 7, 5, 5, 5, 3, 5, 9, 9, 15, 7, 7, 7, 3, 5, 9, 7, 15, 5, 5, 3, 7, 3, 11, 3, 9, 13, 7, 15, 9, 5, 5, 7, 11, 13, 5, 5, 5, 11, 7, 7, 13, 3, 5, 7, 9, 5, 7, 7, 13, 7, 3, 7, 11, 5, 17, 7, 9, 7, 11, 5, 5, 5, 11, 9, 9, 7, 9, 13, 13, 5, 11, 7, 5, 9, 7, 5, 13, 5, 5, 11, 13, 3, 9, 5, 9, 13, 11, 9, 3, 9, 3, 11, 3, 5, 3, 15, 13, 15, 17, 3, 13, 7, 5, 3, 15, 3, 5, 7, 3, 9, 7, 5, 9, 9, 9, 11, 7, 5, 9, 7, 13, 3, 5, 3, 5, 3, 11, 21, 17, 9, 7, 15, 13, 5, 3, 3, 9, 13, 19, 5, 3, 3, 11, 5, 5, 5, 3, 17, 13, 5, 5, 15, 3, 5, 5, 5, 9, 7, 3, 9, 13, 9, 9, 13, 15, 13, 5, 3, 11, 13, 5, 15, 19, 15, 7, 11, 15, 9, 11, 7, 9, 25, 3, 7, 3, 3, 5, 9, 7, 9, 9, 15, 7, 7, 13, 13, 11, 5, 3, 5, 15, 17, 11, 3, 7, 5, 11, 3, 17, 11, 3, 3, 5, 5, 21, 5, 5, 5, 13, 3, 9, 17, 3, 3, 9, 9, 11, 5, 9, 11, 13, 7, 5, 3, 9, 7, 5, 9, 11, 11, 3, 13, 3, 13, 9, 3, 13, 5, 5, 7, 5, 3, 3, 11, 13, 5, 11, 7, 11, 5, 5, 9, 9, 9, 5, 5, 7, 11, 13, 3, 5, 7, 3, 7, 3, 3, 7, 5, 7, 15, 3, 3, 11, 3, 9, 15, 5, 3, 3, 11, 11, 9, 17, 9, 15, 5, 17, 5, 13, 9, 9, 3, 3, 19, 11, 5, 7, 5, 3, 9, 9, 15, 3, 13, 3, 13, 5, 11, 13, 13, 13, 13, 3, 13, 13, 5, 5, 7, 3, 3, 5, 11, 5, 17, 15, 7, 11, 3, 5, 3, 19, 21, 9, 5, 9, 9, 11, 3, 9, 7, 3, 5, 7, 9, 9, 5, 9, 3, 17, 9, 11, 5, 7, 7, 11, 7, 3, 9, 7, 3, 7, 11, 9, 11, 3, 5, 5, 11, 11, 7, 13, 11, 15, 9, 13, 17, 5, 7, 11, 3, 17, 11, 5, 13, 11, 9, 11, 7, 13, 7, 11, 13, 11, 17, 3, 15, 5, 11, 3, 7, 5, 13, 3, 3, 5, 15, 5, 9, 13, 7, 3, 11, 3, 15, 13, 11, 13, 13, 5, 7, 9, 11, 15, 5, 5, 13, 11, 15, 3, 13, 15, 9, 11, 5, 7, 9, 3, 11, 11, 5, 3, 11, 13, 9, 7, 3, 7, 9, 7, 5, 3, 3, 3, 5, 11, 7, 13, 15, 5, 5, 9, 5, 5, 13, 7, 13, 11, 5, 9, 11, 13, 3, 15, 3, 7, 5, 5, 11, 5, 9, 5, 9, 7, 7, 3, 5, 3, 11, 9, 9, 9, 3, 7, 3, 5, 9, 15, 13, 7, 11, 5, 11, 13, 5, 7, 5, 11, 9, 9, 3, 3, 3, 15, 3, 17, 7, 7, 3, 5, 7, 9, 7, 7, 3, 7, 9, 9, 11, 5, 3, 11, 9, 9, 5, 5, 3, 13, 7, 11, 17, 5, 3, 13, 7, 17, 5, 17, 5, 9, 9, 9, 5, 3, 3, 11, 7, 7, 3, 7, 13, 3, 5, 13, 9, 5, 5, 9, 15, 13, 3, 5, 9, 15, 11, 15, 7, 11, 13, 11, 3, 9, 9, 3, 5, 13, 3, 5, 7, 9, 7, 3, 5, 13, 9, 5, 7, 17, 9, 9, 7, 9, 13, 11, 5, 13, 5, 5, 3, 11, 11, 5, 5, 13, 15, 11, 7, 13, 11, 5, 7, 9, 5, 5, 15, 9, 5, 3, 17, 13, 5, 7, 5, 9, 13, 5, 17, 13, 5, 11, 13, 11, 19, 15, 7, 3, 9, 11, 9, 5, 7, 15, 9, 11, 3, 9, 11, 5, 19, 5, 3, 5, 11, 3, 11, 5, 3, 5, 11, 11, 7, 5, 11, 3, 11, 5, 9, 7, 5, 5, 3, 9, 7, 7, 11, 9, 3, 11, 5, 13, 5, 7, 11, 3, 3, 7, 5, 7, 5, 9, 11, 9, 9, 11, 11, 25, 5, 13, 13, 13, 3, 5, 7, 5, 5, 3, 11, 7, 5, 7, 17, 5, 9, 9, 5, 15, 17, 11, 13, 7, 7, 11, 7, 17, 11, 13, 13, 3, 21, 13, 3, 13, 11, 3, 5, 5, 11, 13, 7, 3, 13, 15, 11, 5, 3, 9, 11, 15, 5, 9, 7, 9, 9, 5, 9, 7, 11, 3, 9, 5, 9, 11, 3, 19, 5, 5, 5, 3, 5, 5, 11, 9, 7, 9, 13, 17, 5, 11, 13, 9, 5, 9, 7, 13, 5, 11, 17, 3]\n","21 14768\n","[5, 9, 7, 12, 7, 3, 5, 11, 5, 5, 13, 3, 9, 5, 7, 15, 7, 15, 11, 5, 11, 3, 3, 13, 13, 5, 7, 7, 11, 15, 5, 16, 3, 11, 7, 5, 3, 5, 3, 7, 7, 11, 5, 9, 11, 3, 11, 9, 13, 7, 16, 11, 7, 7, 5, 13, 3, 5, 13, 11, 9, 15, 5, 11, 13, 11, 7, 11, 3, 15, 3, 7, 11, 7, 15, 5, 5, 5, 9, 7, 7, 9, 3, 9, 9, 7, 5, 9, 7, 9, 9, 5, 7, 5, 3, 3, 5, 5, 14, 9, 13, 14, 7, 11, 5, 9, 9, 3, 9, 7, 3, 15, 7, 5, 7, 9, 3, 15, 13, 15, 7, 11, 7, 12, 16, 15, 9, 17, 5, 15, 11, 7, 5, 11, 9, 9, 5, 7, 14, 13, 5, 15, 3, 5, 7, 14, 15, 9, 11, 9, 3, 3, 7, 7, 9, 5, 3, 11, 7, 13, 3, 7, 5, 9, 15, 7, 3, 9, 5, 7, 7, 9, 13, 13, 5, 9, 7, 5, 7, 7, 13, 7, 3, 7, 11, 5, 11, 7, 5, 7, 9, 3, 13, 17, 5, 3, 9, 9, 11, 16, 9, 3, 7, 3, 17, 7, 13, 7, 5, 5, 9, 5, 3, 5, 5, 9, 3, 3, 13, 13, 7, 7, 5, 7, 5, 9, 3, 7, 5, 11, 3, 7, 3, 9, 7, 13, 16, 5, 11, 7, 3, 11, 11, 7, 3, 7, 7, 11, 3, 9, 11, 11, 7, 5, 9, 7, 5, 3, 7, 7, 3, 13, 3, 11, 11, 9, 3, 5, 11, 7, 13, 9, 9, 3, 5, 13, 12, 11, 9, 7, 7, 7, 9, 7, 9, 7, 16, 3, 13, 11, 3, 5, 5, 13, 5, 11, 3, 14, 3, 16, 3, 5, 7, 7, 13, 3, 3, 7, 9, 17, 3, 3, 5, 7, 11, 7, 11, 9, 5, 9, 7, 11, 9, 5, 11, 7, 11, 3, 11, 7, 11, 14, 3, 7, 7, 3, 13, 5, 5, 13, 5, 7, 9, 9, 3, 9, 13, 5, 13, 9, 13, 13, 7, 3, 15, 5, 13, 5, 5, 15, 5, 3, 17, 7, 5, 5, 13, 11, 3, 3, 9, 11, 3, 3, 11, 13, 5, 5, 11, 13, 3, 13, 11, 11, 3, 3, 9, 3, 3, 5, 11, 3, 16, 5, 13, 3, 7, 15, 7, 13, 7, 7, 7, 9, 5, 15, 11, 5, 7, 5, 7, 5, 9, 11, 11, 3, 5, 9, 9, 3, 15, 13, 7, 5, 5, 3, 5, 5, 9, 16, 5, 9, 13, 5, 11, 5, 7, 12, 9, 7, 3, 7, 11, 7, 5, 7, 7, 11, 9, 7, 13, 7, 5, 3, 11, 5, 5, 5, 9, 3, 5, 5, 3, 5, 3, 5, 12, 13, 9, 7, 13, 12, 13, 11, 12, 11, 13, 3, 7, 5, 5, 5, 7, 5, 9, 13, 9, 11, 9, 3, 5, 7, 5, 7, 9, 13, 13, 9, 5, 17, 11, 13, 3, 5, 7, 7, 16, 5, 9, 11, 9, 5, 9, 9, 3, 7, 7, 3, 7, 5, 7, 11, 11, 11, 13, 13, 11, 7, 7, 15, 13, 13, 11, 13, 7, 9, 5, 9, 7, 15, 5, 5, 9, 9, 13, 5, 3, 3, 3, 5, 3, 7, 3, 11, 11, 15, 7, 7, 5, 3, 7, 5, 15, 9, 16, 7, 5, 3, 7, 3, 7, 15, 7, 3, 5, 13, 5, 9, 9, 15, 3, 17, 13, 13, 7, 3, 12, 5, 7, 11, 3, 7, 7, 7, 11, 7, 5, 3, 9, 5, 9, 9, 9, 9, 5, 11, 13, 5, 9, 9, 5, 5, 7, 13, 5, 9, 5, 11, 5, 16, 7, 9, 13, 5, 11, 7, 7, 15, 13, 7, 5, 3, 5, 7, 9, 5, 13, 11, 16, 13, 5, 13, 11, 12, 5, 11, 9, 11, 13, 5, 7, 3, 5, 13, 7, 3, 5, 7, 9, 3, 5, 16, 7, 9, 7, 5, 7, 15, 15, 3, 5, 13, 9, 5, 5, 11, 7, 7, 9, 5, 12, 5, 9, 5, 7, 15, 3, 15, 14, 5, 9, 3, 13, 9, 9, 13, 13, 17, 17, 5, 3, 5, 9, 5, 14, 5, 5, 5, 9, 7, 5, 5, 9, 5, 3, 7, 9, 3, 11, 5, 13, 16, 16, 5, 13, 3, 13, 5, 11, 5, 3, 11, 13, 5, 5, 7, 5, 11, 3, 5, 5, 7, 3, 5, 3, 13, 5, 3, 5, 5, 13, 9, 9, 12, 3, 5, 3, 11, 11, 3, 9, 9, 3, 13, 5, 5, 11, 3, 7, 9, 3, 3, 16, 15, 5, 7, 14, 13, 7, 15, 7, 5, 11, 9, 5, 15, 7, 3, 5, 9, 13, 3, 13, 13, 9, 9, 5, 5, 11, 9, 7, 9, 5, 10, 12, 11, 7, 11, 5, 7, 11, 5, 9, 11, 13, 3, 3, 13, 3, 13, 9, 17, 11, 7, 12, 3, 7, 3, 9, 5, 5, 11, 9, 7, 7, 7, 13, 5, 5, 9, 11, 7, 9, 9, 7, 9, 13, 5, 17, 17, 7, 13, 9, 5, 11, 3, 7, 11, 9, 7, 9, 7, 15, 15, 3, 13, 9, 15, 11, 15, 5, 5, 14, 7, 11, 7, 11, 3, 11, 11, 5, 11, 3, 5, 3, 5, 7, 7, 11, 7, 7, 3, 3, 11, 17, 5, 14, 5, 7, 11, 5, 5, 9, 3, 13, 11, 13, 13, 3, 15, 13, 13, 5, 5, 13, 3, 9, 15, 9, 9, 9, 7, 7, 7, 9, 11, 7, 5, 3, 9, 13, 14, 13, 5, 9, 5, 5, 13, 7, 7, 13, 7, 13, 3, 7, 7, 3, 7, 9, 3, 13, 5, 11, 9, 5, 3, 3, 14, 5, 11, 13, 9, 5, 5, 15, 11, 9, 9, 15, 7, 7, 13, 7, 5, 7, 11, 11, 7, 5, 9, 5, 5, 11, 5, 9, 3, 5, 5, 13, 3, 7, 7, 14, 9, 3, 3, 9, 9, 9, 15, 15, 11, 5, 5, 7, 9, 3, 11, 9, 13, 3, 5, 7, 11, 5, 5, 7, 7, 11, 5, 5, 3, 11, 11, 15, 7, 17, 13, 3, 5, 7, 13, 7, 11, 9, 15, 13, 11, 7, 5, 5, 16, 3, 11, 5, 9, 5, 7, 3, 7, 16, 3, 9, 11, 5, 9, 7, 5, 11, 3, 5, 9, 7, 3, 5, 11, 5, 7, 3, 5, 5, 11, 7, 5, 5, 7, 13, 5, 11, 7, 5, 11, 13, 15, 11, 16, 5, 3, 3, 13, 7, 3, 7, 13, 5, 7, 7, 7, 5, 17, 13, 9, 3, 7, 9, 13, 9, 15, 3, 9, 11, 5, 5, 9, 11, 13, 7, 5, 9, 7, 15, 5, 3, 13, 3, 5, 5, 3, 9, 3, 5, 5, 9, 5, 11, 3, 9, 15, 15, 14, 11, 7, 9, 13, 15, 7, 5, 3, 5, 9, 7, 5, 7, 7, 11, 14, 5, 7, 7, 3, 11, 5, 5, 9, 7, 5, 5, 5, 5, 13, 3, 3, 13, 3, 3, 20, 3, 5, 9, 3, 11, 13, 5, 11, 7, 5, 15, 15, 5, 17, 11, 7, 5, 3, 7, 13, 5, 5, 11, 7, 7, 5, 13, 7, 5, 11, 9, 7, 9, 15, 5, 5, 7, 5, 7, 7, 14, 5, 14, 7, 5, 7, 13, 13, 5, 3, 5, 11, 7, 9, 14, 16, 3, 5, 11, 13, 5, 9, 11, 5, 5, 13, 5, 13, 5, 13, 5, 7, 13, 5, 3, 3, 5, 9, 5, 11, 3, 7, 11, 5, 3, 13, 13, 9, 5, 9, 11, 3, 9, 5, 5, 9, 5, 3, 9, 15, 7, 5, 7, 9, 5, 5, 7, 11, 5, 11, 13, 7, 5, 7, 15, 9, 11, 15, 7, 13, 5, 5, 7, 7, 11, 11, 13, 11, 9, 13, 5, 5, 7, 5, 9, 7, 7, 13, 5, 3, 13, 7, 9, 3, 9, 3, 11, 5, 7, 3, 11, 7, 5, 9, 11, 13, 7, 7, 7, 3, 5, 13, 7, 7, 5, 7, 9, 5, 7, 9, 3, 11, 7, 7, 11, 13, 5, 3, 5, 16, 11, 13, 7, 7, 7, 5, 13, 12, 15, 13, 11, 3, 5, 7, 5, 9, 9, 13, 5, 11, 11, 5, 5, 13, 9, 7, 9, 18, 7, 3, 9, 9, 9, 5, 3, 15, 5, 3, 3, 13, 17, 5, 3, 3, 7, 5, 3, 3, 5, 3, 5, 9, 7, 3, 3, 5, 5, 3, 3, 5, 5, 13, 13, 9, 9, 12, 5, 11, 3, 5, 9, 9, 13, 9, 15, 11, 7, 11, 13, 3, 5, 11, 11, 5, 3, 3, 11, 9, 13, 7, 13, 11, 9, 3, 5, 5, 7, 5, 13, 9, 15, 13, 11, 11, 7, 5, 5, 11, 13, 9, 14, 3, 7, 7, 3, 3, 5, 7, 10, 9, 9, 3, 9, 9, 16, 5, 14, 5, 11, 5, 7, 3, 11, 7, 5, 3, 5, 13, 11, 7, 3, 3, 7, 5, 9, 7, 13, 11, 3, 14, 5, 13, 5, 15, 5, 3, 9, 5, 15, 7, 11, 7, 9, 3, 9, 9, 15, 9, 15, 3, 15, 5, 11, 9, 5, 15, 7, 13, 9, 13, 11, 13, 13, 11, 3, 11, 5, 13, 13, 3, 7, 5, 9, 13, 7, 5, 7, 3, 9, 9, 9, 5, 3, 11, 11, 5, 9, 3, 5, 9, 5, 7, 7, 5, 7, 3, 11, 15, 5, 5, 3, 11, 5, 3, 9, 13, 9, 3, 5, 3, 9, 11, 14, 9, 5, 3, 7, 5, 9, 7, 3, 5, 9, 7, 3, 7, 5, 11, 9, 13, 9, 5, 7, 17, 11, 9, 5, 13, 5, 5, 5, 13, 5, 9, 5, 9, 9, 7, 7, 5, 9, 9, 7, 9, 13, 9, 9, 13, 3, 7, 5, 9, 11, 7, 5, 5, 7, 9, 5, 13, 7, 9, 13, 7, 7, 11, 7, 5, 13, 5, 3, 11, 11, 5, 7, 5, 9, 3, 7, 13, 11, 11, 7, 3, 3, 3, 11, 7, 5, 7, 9, 3, 7, 5, 13, 5, 9, 11, 9, 14, 3, 9, 5, 13, 9, 11, 3, 9, 5, 5, 5, 3, 5, 3, 11, 3, 5, 5, 5, 7, 7, 9, 7, 11, 9, 7, 11, 5, 9, 7, 9, 3, 7, 7, 13, 9, 7, 7, 5, 9, 9, 11, 16, 13, 13, 9, 13, 3, 13, 15, 11, 7, 11, 7, 3, 11, 7, 3, 7, 3, 11, 11, 5, 7, 5, 9, 11, 11, 11, 11, 13, 3, 9, 11, 5, 17, 11, 5, 3, 7, 3, 7, 11, 9, 11, 7, 11, 5, 3, 9, 5, 9, 3, 11, 13, 9, 3, 3, 7, 3, 9, 3, 5, 11, 7, 7, 7, 5, 7, 7, 11, 3, 5, 9, 9, 13, 7, 5, 5, 14, 11, 7, 13, 5, 3, 9, 14, 7, 5, 9, 5, 7, 9, 17, 13, 3, 11, 9, 7, 5, 7, 17, 13, 5, 7, 7, 11, 5, 9, 11, 3, 11, 13, 3, 13, 13, 7, 9, 7, 3, 9, 3, 9, 3, 3, 9, 11, 17, 9, 5, 5, 3, 5, 3, 9, 5, 7, 7, 11, 7, 15, 9, 9, 15, 15, 15, 9, 16, 5, 9, 5, 7, 9, 11, 9, 5, 11, 7, 11, 7, 5, 7, 5, 3, 5, 7, 7, 5, 13, 3, 5, 11, 11, 3, 13, 11, 13, 5, 9, 13, 5, 7, 14, 5, 9, 17, 12, 11, 17, 7, 9, 7, 10, 5, 3, 7, 7, 3, 16, 3, 5, 9, 9, 7, 3, 7, 16, 5, 7, 15, 7, 13, 5, 11, 5, 11, 9, 9, 5, 3, 7, 5, 9, 11, 7, 7, 11, 7, 11, 3, 9, 9, 11, 13, 7, 5, 11, 3, 7, 5, 7, 11, 7, 7, 5, 5, 9, 9, 11, 11, 9, 7, 3, 7, 5, 9, 5, 3, 9, 16, 5, 5, 5, 3, 7, 5, 15, 11, 9, 7, 5, 11, 5, 5, 16, 13, 3, 5, 5, 9, 5, 3, 3, 3, 5, 5, 9, 5, 5, 11, 3, 13, 18, 7, 9, 5, 7, 12, 5, 5, 7, 7, 3, 9, 5, 13, 12, 9, 15, 5, 11, 7, 5, 9, 9, 11, 9, 3, 11, 9, 7, 7, 11, 7, 12, 5, 3, 13, 15, 7, 5, 11, 7, 7, 9, 3, 11, 3, 5, 13, 11, 11, 7, 5, 5, 13, 9, 5, 3, 7, 11, 11, 3, 13, 11, 13, 3, 5, 9, 13, 11, 5, 3, 3, 11, 5, 7, 3, 7, 5, 3, 5, 3, 5, 7, 5, 3, 11, 3, 5, 11, 5, 7, 7, 3, 3, 7, 13, 3, 11, 11, 5, 3, 11, 13, 7, 9, 3, 3, 9, 7, 15, 9, 5, 9, 9, 13, 9, 13, 9, 7, 3, 17, 5, 3, 7, 7, 3, 7, 13, 7, 15, 7, 11, 9, 9, 15, 17, 16, 11, 9, 5, 9, 15, 3, 9, 5, 7, 9, 9, 5, 13, 13, 7, 3, 9, 13, 7, 5, 11, 5, 13, 5, 11, 3, 5, 3, 5, 5, 7, 5, 5, 5, 9, 11, 5, 7, 11, 3, 11, 9, 19, 13, 5, 5, 5, 14, 5, 7, 13, 7, 13, 9, 7, 5, 3, 15, 3, 3, 7, 7, 13, 7, 5, 13, 9, 15, 3, 9, 7, 5, 11, 7, 9, 15, 3, 14, 13, 3, 3, 11, 15, 11, 13, 11, 7, 15, 5, 15, 9, 3, 5, 11, 7, 11, 7, 13, 5, 9, 3, 11, 7, 13, 7, 9, 3, 3, 5, 7, 13, 5, 9, 5, 17, 9, 7, 3, 7, 5, 11, 7, 7, 5, 9, 9, 9, 7, 3, 7, 7, 5, 5, 5, 5, 3, 7, 3, 9, 13, 7, 9, 3, 9, 7, 5, 5, 5, 9, 7, 3, 13, 5, 5, 9, 3, 14, 5, 12, 5, 15, 11, 5, 15, 9, 9, 9, 13, 5, 13, 17, 5, 7, 3, 11, 5, 7, 13, 3, 9, 5, 9, 7, 7, 15, 7, 9, 13, 18, 11, 7, 7, 15, 9, 5, 11, 5, 7, 13, 9, 11, 9, 3, 5, 7, 3, 5, 11, 13, 5, 3, 11, 5, 3, 5, 11, 7, 5, 9, 3, 15, 9, 3, 15, 9, 7, 3, 3, 5, 5, 15, 16, 14, 7, 11, 11, 11, 13, 5, 11, 9, 13, 11, 3, 5, 7, 11, 5, 11, 3, 3, 9, 13, 7, 11, 12, 3, 9, 16, 5, 5, 15, 3, 15, 12, 9, 7, 13, 3, 3, 15, 9, 13, 3, 9, 5, 3, 5, 7, 11, 11, 3, 5, 3, 3, 5, 11, 7, 7, 13, 7, 9, 3, 3, 11, 17, 3, 15, 7, 5, 13, 5, 13, 3, 9, 7, 7, 17, 9, 5, 13, 7, 13, 7, 11, 7, 7, 5, 13, 11, 13, 7, 5, 5, 5, 13, 7, 3, 11, 5, 3, 13, 11, 7, 15, 7, 3, 5, 9, 5, 5, 13, 9, 14, 14, 5, 7, 11, 3, 5, 5, 5, 3, 15, 7, 7, 5, 7, 7, 7, 11, 5, 9, 14, 9, 13, 7, 5, 5, 9, 11, 3, 18, 9, 3, 9, 3, 5, 3, 11, 5, 3, 7, 3, 5, 3, 5, 15, 3, 11, 11, 3, 9, 9, 13, 13, 3, 14, 7, 11, 5, 7, 9, 7, 3, 13, 11, 9, 3, 5, 15, 9, 3, 7, 9, 5, 7, 3, 12, 5, 3, 11, 5, 3, 16, 9, 3, 5, 11, 7, 3, 5, 5, 5, 14, 7, 13, 7, 5, 9, 3, 13, 5, 5, 7, 15, 3, 7, 15, 9, 18, 3, 15, 11, 9, 3, 5, 7, 5, 7, 3, 5, 7, 15, 7, 13, 5, 7, 5, 11, 3, 5, 5, 7, 5, 9, 11, 7, 3, 12, 3, 5, 11, 3, 5, 5, 11, 5, 13, 9, 9, 13, 7, 11, 3, 7, 7, 3, 7, 7, 9, 5, 9, 5, 5, 5, 5, 5, 9, 13, 5, 21, 12, 5, 7, 5, 5, 3, 9, 9, 11, 5, 7, 3, 11, 3, 11, 5, 9, 7, 3, 3, 7, 13, 7, 5, 9, 13, 13, 7, 13, 5, 7, 7, 9, 3, 7, 3, 3, 13, 9, 5, 7, 13, 11, 11, 7, 5, 12, 5, 9, 5, 9, 7, 13, 9, 7, 5, 7, 3, 13, 13, 7, 3, 5, 5, 7, 9, 11, 3, 9, 11, 5, 7, 9, 7, 13, 5, 9, 7, 3, 7, 9, 11, 9, 13, 3, 14, 19, 13, 14, 5, 5, 9, 7, 9, 5, 5, 3, 3, 13, 11, 7, 13, 11, 9, 11, 3, 7, 7, 7, 7, 5, 9, 5, 5, 5, 9, 5, 15, 3, 5, 3, 3, 7, 3, 11, 13, 14, 7, 3, 7, 7, 13, 5, 9, 5, 9, 9, 9, 7, 9, 7, 7, 7, 5, 7, 7, 13, 11, 9, 5, 3, 5, 15, 13, 10, 11, 11, 9, 11, 7, 5, 9, 7, 3, 9, 17, 9, 3, 5, 5, 7, 7, 9, 9, 7, 7, 5, 5, 5, 13, 5, 5, 9, 7, 9, 9, 5, 3, 11, 9, 9, 14, 5, 7, 7, 7, 11, 9, 9, 13, 3, 13, 7, 11, 7, 9, 7, 5, 3, 7, 7, 5, 13, 13, 7, 11, 13, 13, 9, 9, 7, 11, 9, 7, 5, 13, 16, 11, 11, 12, 11, 13, 11, 9, 11, 3, 11, 11, 11, 9, 11, 7, 5, 11, 13, 5, 5, 3, 7, 15, 3, 5, 7, 3, 17, 13, 5, 11, 11, 5, 9, 15, 5, 7, 7, 5, 7, 9, 5, 5, 5, 5, 14, 9, 9, 11, 7, 7, 7, 13, 5, 3, 9, 5, 5, 3, 7, 5, 7, 3, 3, 3, 3, 14, 5, 15, 5, 13, 7, 11, 9, 9, 3, 9, 5, 9, 5, 9, 5, 3, 15, 7, 5, 7, 5, 13, 12, 5, 5, 3, 9, 7, 5, 5, 7, 11, 3, 5, 3, 13, 11, 11, 5, 3, 16, 9, 7, 5, 11, 7, 11, 9, 11, 14, 7, 3, 5, 11, 3, 13, 15, 11, 11, 5, 5, 7, 11, 11, 3, 3, 9, 7, 7, 7, 3, 5, 3, 5, 9, 3, 7, 5, 11, 7, 15, 5, 3, 14, 11, 3, 7, 11, 11, 9, 3, 3, 11, 5, 5, 5, 15, 12, 9, 3, 14, 9, 7, 7, 7, 11, 5, 7, 5, 5, 9, 15, 7, 5, 13, 11, 7, 9, 5, 7, 7, 15, 7, 3, 11, 11, 7, 7, 3, 9, 3, 5, 13, 14, 5, 5, 5, 7, 15, 13, 5, 7, 5, 7, 5, 5, 3, 5, 15, 5, 5, 9, 7, 11, 5, 3, 15, 5, 5, 9, 5, 3, 5, 3, 11, 7, 3, 7, 11, 9, 5, 7, 3, 9, 9, 13, 7, 5, 7, 13, 14, 11, 14, 3, 7, 13, 9, 5, 9, 13, 5, 5, 3, 7, 13, 3, 9, 13, 15, 3, 7, 5, 7, 13, 5, 5, 7, 16, 11, 3, 11, 3, 5, 9, 13, 5, 3, 11, 11, 9, 15, 9, 9, 9, 5, 5, 13, 13, 13, 11, 11, 11, 3, 9, 13, 5, 3, 17, 7, 7, 11, 16, 5, 9, 5, 7, 14, 7, 9, 3, 7, 7, 7, 3, 11, 7, 9, 11, 11, 9, 11, 5, 3, 5, 15, 5, 5, 11, 3, 11, 9, 5, 7, 5, 9, 9, 7, 11, 11, 3, 13, 5, 9, 3, 3, 5, 3, 3, 11, 13, 5, 7, 3, 9, 9, 11, 7, 3, 9, 7, 7, 9, 11, 3, 5, 11, 3, 9, 11, 5, 13, 7, 13, 3, 13, 5, 11, 11, 13, 7, 7, 5, 12, 11, 7, 5, 3, 11, 9, 11, 7, 9, 9, 3, 9, 11, 3, 7, 7, 5, 7, 15, 7, 5, 11, 5, 13, 11, 15, 7, 13, 21, 13, 9, 15, 5, 3, 5, 5, 5, 7, 7, 5, 9, 13, 5, 5, 3, 7, 9, 5, 9, 11, 11, 5, 7, 5, 11, 5, 3, 3, 7, 7, 11, 13, 11, 3, 7, 7, 11, 7, 3, 11, 5, 9, 3, 3, 5, 15, 5, 3, 11, 5, 7, 11, 5, 3, 5, 5, 7, 5, 11, 11, 9, 9, 3, 5, 5, 7, 9, 7, 9, 5, 7, 13, 3, 11, 3, 11, 13, 7, 3, 11, 5, 13, 14, 7, 11, 5, 3, 5, 13, 5, 7, 3, 3, 9, 7, 15, 5, 7, 5, 16, 7, 9, 7, 13, 3, 3, 15, 5, 7, 13, 3, 12, 5, 7, 7, 3, 13, 3, 11, 13, 5, 5, 11, 7, 11, 9, 9, 5, 3, 5, 13, 11, 7, 15, 5, 13, 15, 15, 3, 7, 3, 7, 5, 13, 7, 13, 9, 11, 7, 3, 11, 13, 7, 11, 5, 9, 3, 11, 5, 13, 11, 13, 3, 14, 13, 3, 3, 9, 5, 15, 7, 15, 11, 7, 5, 5, 9, 3, 9, 9, 11, 7, 11, 3, 9, 5, 3, 11, 7, 11, 7, 3, 5, 7, 5, 5, 15, 13, 13, 3, 9, 13, 9, 3, 15, 7, 11, 3, 3, 5, 3, 7, 7, 5, 5, 3, 14, 5, 7, 5, 7, 7, 7, 13, 11, 5, 7, 11, 11, 5, 13, 3, 13, 13, 7, 13, 13, 9, 5, 3, 9, 7, 3, 7, 5, 15, 5, 7, 9, 11, 9, 9, 9, 7, 13, 3, 3, 5, 7, 5, 13, 3, 11, 9, 5, 13, 5, 9, 7, 9, 11, 5, 14, 5, 13, 5, 9, 11, 3, 7, 3, 7, 3, 5, 7, 3, 9, 15, 5, 7, 7, 5, 13, 5, 9, 9, 11, 9, 5, 5, 9, 5, 11, 17, 13, 9, 13, 5, 7, 9, 3, 5, 9, 3, 3, 7, 5, 9, 7, 5, 13, 15, 3, 9, 12, 13, 5, 3, 11, 11, 11, 5, 3, 7, 9, 7, 13, 13, 5, 7, 11, 3, 11, 3, 5, 9, 9, 3, 9, 15, 3, 13, 3, 5, 3, 5, 7, 15, 5, 3, 5, 7, 13, 5, 5, 15, 15, 11, 15, 7, 7, 15, 9, 5, 13, 9, 7, 11, 7, 5, 11, 13, 7, 13, 7, 9, 7, 5, 5, 9, 7, 7, 5, 13, 11, 9, 7, 11, 7, 9, 5, 9, 7, 5, 7, 7, 7, 5, 7, 7, 3, 5, 5, 5, 5, 9, 5, 13, 9, 7, 9, 5, 9, 9, 13, 9, 3, 3, 9, 13, 13, 3, 15, 5, 5, 5, 7, 3, 9, 9, 5, 11, 7, 7, 7, 5, 13, 14, 3, 7, 11, 11, 5, 5, 5, 3, 15, 5, 3, 3, 5, 13, 3, 7, 17, 13, 9, 7, 7, 11, 14, 16, 13, 3, 7, 7, 9, 11, 5, 5, 3, 5, 5, 13, 11, 11, 15, 5, 11, 5, 5, 7, 7, 3, 5, 5, 7, 11, 13, 18, 13, 16, 7, 13, 5, 5, 12, 9, 7, 7, 3, 11, 5, 13, 9, 13, 3, 11, 3, 7, 5, 3, 5, 15, 15, 11, 14, 9, 9, 9, 14, 11, 5, 17, 9, 5, 5, 7, 9, 5, 17, 9, 13, 13, 9, 9, 5, 7, 13, 7, 11, 5, 14, 5, 13, 3, 3, 7, 17, 3, 9, 13, 11, 7, 13, 11, 7, 16, 5, 7, 7, 11, 5, 11, 5, 5, 9, 3, 9, 13, 7, 5, 5, 12, 5, 5, 15, 15, 11, 9, 3, 13, 7, 9, 9, 11, 3, 9, 7, 5, 3, 3, 7, 5, 13, 13, 7, 9, 7, 5, 5, 9, 3, 5, 5, 15, 7, 9, 9, 18, 3, 7, 5, 11, 9, 7, 11, 5, 9, 3, 7, 7, 11, 9, 9, 11, 5, 5, 9, 3, 13, 5, 9, 15, 7, 15, 7, 11, 3, 13, 9, 3, 11, 3, 15, 7, 15, 5, 15, 3, 9, 5, 3, 7, 11, 13, 5, 3, 5, 9, 7, 7, 12, 5, 14, 11, 11, 3, 17, 7, 13, 9, 11, 9, 9, 9, 15, 3, 18, 15, 13, 9, 11, 9, 13, 9, 3, 3, 13, 7, 5, 11, 13, 9, 15, 7, 3, 3, 5, 13, 5, 11, 5, 9, 13, 7, 9, 3, 3, 7, 13, 9, 13, 5, 7, 3, 9, 14, 7, 11, 5, 9, 17, 9, 16, 13, 11, 5, 11, 11, 9, 5, 3, 5, 3, 11, 7, 11, 5, 9, 13, 5, 15, 11, 5, 5, 9, 9, 15, 5, 3, 7, 7, 9, 5, 5, 7, 5, 18, 13, 3, 5, 5, 3, 13, 7, 5, 13, 7, 15, 16, 5, 13, 5, 7, 13, 11, 7, 7, 9, 3, 9, 9, 11, 5, 3, 7, 13, 3, 15, 5, 9, 5, 3, 17, 13, 5, 5, 12, 9, 11, 5, 11, 5, 14, 3, 3, 9, 9, 11, 17, 3, 3, 7, 7, 13, 15, 9, 13, 7, 7, 9, 7, 15, 11, 7, 5, 15, 11, 3, 11, 15, 13, 7, 11, 13, 3, 11, 7, 5, 5, 7, 13, 5, 5, 5, 13, 7, 5, 11, 5, 9, 11, 3, 9, 7, 9, 5, 7, 5, 7, 3, 13, 5, 11, 13, 14, 11, 11, 7, 7, 11, 9, 5, 9, 3, 7, 3, 5, 5, 9, 9, 3, 13, 3, 3, 5, 9, 11, 13, 3, 13, 7, 11, 7, 11, 5, 3, 3, 5, 5, 14, 14, 10, 5, 3, 13, 5, 11, 5, 11, 5, 5, 15, 5, 9, 3, 5, 13, 13, 11, 9, 7, 17, 13, 3, 13, 13, 9, 5, 7, 7, 3, 15, 11, 3, 3, 9, 9, 7, 5, 13, 9, 9, 9, 5, 15, 9, 3, 5, 9, 16, 5, 10, 13, 7, 7, 5, 7, 11, 11, 5, 3, 5, 3, 3, 5, 5, 3, 7, 13, 18, 7, 7, 9, 3, 7, 9, 11, 13, 14, 13, 9, 15, 14, 3, 11, 11, 5, 11, 7, 13, 3, 7, 9, 7, 5, 13, 13, 3, 13, 9, 7, 3, 15, 11, 11, 13, 14, 9, 9, 17, 3, 5, 11, 7, 7, 13, 13, 13, 5, 7, 5, 3, 5, 3, 9, 15, 3, 15, 3, 3, 7, 7, 15, 5, 5, 9, 7, 11, 13, 7, 3, 7, 11, 11, 7, 11, 9, 11, 15, 3, 5, 3, 15, 5, 3, 7, 9, 5, 5, 7, 7, 7, 7, 13, 3, 7, 7, 3, 7, 13, 15, 5, 16, 12, 5, 7, 3, 3, 7, 5, 9, 17, 9, 9, 5, 11, 17, 3, 9, 7, 7, 13, 7, 11, 15, 3, 15, 15, 9, 5, 3, 14, 11, 3, 12, 14, 3, 5, 9, 3, 7, 15, 5, 15, 7, 5, 3, 9, 7, 7, 9, 9, 9, 13, 3, 3, 11, 3, 13, 9, 7, 13, 5, 13, 5, 9, 9, 5, 7, 9, 5, 5, 5, 7, 5, 9, 3, 9, 9, 13, 5, 5, 11, 9, 7, 11, 11, 11, 7, 15, 7, 9, 9, 7, 11, 11, 5, 7, 7, 5, 7, 9, 3, 5, 9, 5, 3, 16, 9, 7, 7, 3, 5, 11, 15, 5, 11, 7, 3, 11, 5, 3, 13, 7, 9, 5, 11, 9, 3, 3, 7, 16, 14, 11, 7, 3, 12, 9, 9, 11, 9, 11, 5, 7, 3, 3, 11, 5, 5, 13, 9, 5, 3, 11, 9, 12, 5, 15, 5, 11, 7, 9, 9, 3, 9, 11, 11, 3, 5, 3, 15, 15, 9, 3, 7, 11, 3, 13, 9, 7, 11, 3, 11, 7, 3, 15, 11, 7, 5, 7, 5, 9, 7, 9, 3, 3, 7, 3, 5, 5, 7, 5, 7, 3, 7, 15, 9, 7, 3, 9, 5, 7, 7, 5, 5, 7, 11, 5, 13, 11, 3, 3, 11, 15, 15, 3, 5, 17, 9, 15, 13, 5, 13, 3, 7, 7, 7, 15, 7, 11, 5, 14, 9, 9, 13, 5, 5, 7, 9, 7, 5, 7, 5, 5, 17, 5, 3, 11, 7, 17, 3, 5, 7, 3, 5, 7, 5, 5, 13, 7, 17, 15, 7, 14, 5, 5, 13, 11, 15, 5, 7, 5, 11, 7, 9, 7, 9, 11, 11, 11, 16, 5, 11, 9, 15, 5, 7, 16, 9, 5, 9, 12, 3, 15, 7, 5, 7, 5, 7, 11, 9, 13, 3, 9, 15, 3, 3, 13, 9, 3, 3, 11, 13, 5, 3, 3, 3, 11, 7, 11, 15, 5, 7, 11, 7, 3, 3, 5, 11, 7, 9, 5, 13, 5, 5, 7, 13, 3, 14, 7, 5, 3, 13, 13, 15, 7, 13, 7, 3, 5, 7, 5, 7, 11, 9, 11, 9, 13, 13, 11, 13, 9, 9, 13, 5, 15, 7, 17, 7, 13, 13, 9, 13, 11, 5, 5, 9, 5, 3, 3, 9, 3, 5, 7, 5, 3, 5, 3, 7, 3, 5, 13, 9, 3, 13, 13, 7, 7, 13, 11, 15, 7, 5, 5, 5, 5, 7, 7, 11, 11, 9, 5, 7, 5, 9, 7, 11, 3, 13, 5, 11, 5, 5, 18, 5, 5, 9, 3, 3, 7, 5, 5, 7, 3, 7, 14, 3, 11, 7, 9, 5, 3, 9, 5, 3, 13, 7, 5, 5, 5, 15, 3, 7, 9, 9, 11, 12, 5, 9, 16, 3, 9, 9, 9, 7, 7, 5, 17, 9, 3, 7, 13, 5, 7, 3, 5, 11, 5, 11, 3, 11, 9, 17, 9, 5, 11, 7, 11, 5, 5, 5, 3, 3, 5, 15, 11, 13, 3, 5, 9, 11, 11, 3, 5, 3, 5, 13, 5, 9, 11, 9, 5, 13, 5, 11, 9, 5, 9, 11, 9, 9, 7, 13, 11, 5, 11, 14, 9, 7, 3, 7, 5, 11, 11, 9, 11, 5, 11, 3, 11, 11, 7, 11, 5, 5, 9, 5, 5, 15, 7, 5, 7, 9, 3, 13, 3, 5, 9, 13, 11, 11, 5, 3, 9, 3, 7, 3, 3, 7, 15, 7, 5, 3, 5, 9, 7, 7, 7, 5, 3, 3, 11, 5, 5, 15, 7, 11, 7, 15, 7, 3, 5, 11, 11, 9, 7, 5, 9, 9, 5, 5, 9, 5, 7, 15, 13, 11, 15, 15, 7, 9, 9, 14, 3, 9, 7, 7, 11, 11, 11, 3, 5, 7, 15, 5, 5, 5, 13, 3, 9, 5, 3, 9, 3, 13, 7, 11, 7, 3, 7, 3, 5, 9, 5, 9, 3, 5, 7, 7, 5, 7, 7, 11, 7, 3, 9, 7, 5, 3, 7, 14, 9, 11, 7, 11, 9, 7, 11, 5, 3, 9, 11, 3, 11, 5, 7, 7, 3, 7, 13, 7, 7, 16, 7, 7, 5, 11, 13, 3, 3, 9, 9, 15, 14, 7, 15, 5, 5, 11, 5, 3, 3, 11, 3, 9, 11, 13, 9, 7, 14, 9, 11, 7, 13, 9, 15, 9, 9, 7, 7, 7, 5, 5, 9, 7, 13, 18, 7, 13, 5, 13, 9, 5, 7, 16, 5, 11, 13, 7, 15, 11, 11, 11, 9, 3, 7, 7, 3, 5, 3, 3, 9, 11, 5, 9, 3, 13, 5, 13, 7, 3, 5, 9, 5, 15, 3, 3, 9, 5, 13, 3, 5, 7, 9, 7, 7, 5, 13, 20, 5, 9, 9, 5, 3, 5, 9, 9, 7, 13, 11, 7, 3, 7, 3, 7, 3, 7, 5, 7, 11, 14, 3, 9, 7, 3, 13, 13, 5, 9, 3, 5, 3, 11, 15, 11, 12, 13, 5, 13, 11, 5, 9, 16, 5, 5, 9, 5, 7, 3, 3, 9, 3, 9, 15, 7, 7, 5, 13, 3, 3, 3, 7, 11, 7, 5, 3, 11, 7, 5, 11, 11, 11, 5, 3, 7, 5, 11, 9, 5, 5, 3, 9, 7, 9, 13, 7, 7, 7, 11, 13, 3, 11, 11, 16, 9, 3, 3, 11, 7, 9, 7, 11, 7, 7, 7, 13, 9, 5, 9, 5, 7, 7, 7, 3, 5, 7, 13, 9, 3, 7, 11, 9, 9, 7, 5, 11, 3, 7, 5, 11, 5, 15, 5, 11, 3, 7, 3, 7, 7, 9, 5, 11, 13, 15, 5, 9, 9, 7, 3, 3, 11, 16, 16, 13, 13, 7, 3, 5, 9, 3, 9, 5, 12, 3, 7, 3, 11, 5, 12, 14, 3, 9, 5, 9, 11, 13, 5, 9, 11, 11, 3, 5, 3, 7, 5, 7, 15, 7, 5, 7, 7, 9, 11, 11, 3, 13, 9, 13, 3, 7, 5, 3, 17, 3, 14, 5, 3, 3, 11, 5, 3, 5, 5, 13, 9, 9, 9, 7, 9, 9, 7, 5, 7, 15, 11, 13, 13, 9, 9, 5, 3, 3, 9, 11, 5, 13, 3, 5, 3, 13, 16, 9, 9, 5, 11, 7, 5, 5, 9, 11, 7, 5, 3, 5, 11, 5, 9, 16, 7, 5, 3, 11, 11, 5, 7, 5, 3, 3, 7, 5, 11, 5, 3, 7, 7, 5, 7, 16, 3, 11, 3, 11, 13, 3, 5, 9, 5, 5, 15, 11, 7, 5, 7, 5, 9, 5, 5, 3, 13, 13, 7, 7, 13, 9, 11, 3, 13, 11, 13, 3, 14, 15, 7, 9, 3, 9, 3, 13, 5, 13, 18, 7, 9, 11, 9, 16, 9, 7, 11, 5, 7, 11, 3, 9, 11, 5, 5, 13, 9, 9, 9, 17, 5, 13, 11, 5, 3, 11, 13, 16, 17, 11, 7, 16, 5, 5, 13, 13, 9, 5, 3, 5, 11, 7, 9, 11, 3, 9, 15, 5, 5, 3, 5, 3, 5, 5, 13, 17, 11, 3, 7, 7, 5, 3, 11, 7, 5, 5, 9, 7, 3, 9, 11, 3, 11, 11, 9, 5, 7, 3, 3, 7, 17, 17, 9, 11, 11, 13, 12, 5, 3, 7, 15, 3, 9, 11, 9, 14, 9, 7, 3, 5, 17, 13, 7, 5, 9, 3, 3, 5, 16, 7, 5, 3, 9, 13, 5, 14, 13, 5, 5, 5, 7, 5, 5, 3, 9, 7, 15, 15, 5, 7, 7, 7, 5, 9, 7, 7, 9, 9, 5, 5, 11, 15, 15, 5, 3, 13, 3, 3, 5, 5, 16, 15, 7, 15, 5, 5, 7, 3, 11, 11, 18, 13, 3, 15, 5, 5, 11, 9, 7, 3, 11, 7, 5, 3, 7, 13, 3, 3, 11, 14, 7, 16, 11, 9, 5, 7, 5, 11, 7, 9, 12, 9, 5, 3, 7, 3, 7, 13, 17, 13, 11, 13, 15, 7, 7, 11, 7, 11, 11, 15, 13, 7, 5, 9, 5, 11, 5, 11, 5, 9, 3, 3, 5, 13, 5, 9, 13, 3, 5, 5, 9, 9, 3, 5, 9, 3, 5, 5, 3, 5, 13, 5, 9, 5, 13, 7, 15, 9, 11, 7, 5, 7, 9, 7, 11, 3, 3, 5, 3, 3, 3, 5, 9, 7, 5, 11, 9, 3, 5, 9, 11, 11, 5, 15, 9, 15, 3, 15, 5, 5, 13, 5, 3, 13, 5, 3, 7, 5, 9, 3, 3, 14, 14, 5, 3, 3, 9, 7, 5, 9, 5, 5, 11, 11, 7, 9, 11, 9, 11, 5, 5, 13, 11, 11, 7, 5, 11, 13, 7, 7, 5, 9, 7, 13, 9, 13, 11, 9, 3, 15, 9, 5, 5, 9, 9, 3, 9, 14, 5, 12, 7, 5, 3, 3, 13, 17, 15, 5, 11, 15, 13, 3, 11, 7, 11, 5, 3, 5, 13, 11, 9, 3, 9, 18, 9, 5, 13, 11, 5, 13, 11, 13, 5, 5, 5, 5, 11, 9, 11, 5, 5, 13, 9, 5, 3, 11, 5, 9, 5, 13, 7, 9, 13, 17, 15, 3, 5, 11, 11, 5, 5, 11, 17, 7, 11, 11, 9, 7, 3, 5, 13, 15, 9, 3, 5, 11, 9, 11, 5, 5, 11, 9, 9, 15, 11, 11, 3, 7, 14, 7, 9, 3, 13, 9, 13, 5, 7, 3, 3, 7, 19, 9, 7, 5, 15, 3, 11, 5, 7, 5, 5, 13, 5, 7, 7, 3, 5, 3, 11, 11, 11, 7, 11, 7, 3, 5, 7, 11, 15, 7, 9, 5, 5, 5, 9, 3, 7, 5, 13, 7, 13, 11, 7, 5, 7, 13, 7, 5, 9, 9, 9, 7, 11, 11, 7, 11, 14, 5, 5, 3, 7, 7, 5, 5, 5, 7, 9, 13, 7, 7, 15, 9, 9, 11, 7, 7, 3, 13, 5, 7, 7, 13, 11, 5, 7, 3, 11, 11, 15, 3, 7, 5, 7, 11, 11, 11, 9, 13, 11, 3, 5, 5, 15, 13, 3, 12, 9, 3, 13, 9, 3, 5, 5, 9, 7, 16, 13, 11, 7, 13, 3, 13, 11, 5, 9, 13, 3, 5, 13, 11, 7, 11, 9, 5, 15, 5, 9, 14, 3, 5, 3, 9, 15, 9, 11, 14, 13, 5, 15, 13, 3, 5, 7, 14, 3, 12, 13, 11, 9, 11, 5, 7, 9, 11, 9, 11, 9, 15, 11, 12, 7, 3, 3, 13, 5, 13, 11, 14, 11, 7, 15, 13, 13, 17, 5, 7, 7, 3, 5, 11, 3, 9, 9, 5, 5, 5, 5, 14, 11, 15, 9, 11, 17, 5, 15, 11, 9, 9, 7, 13, 13, 5, 7, 13, 7, 9, 13, 11, 11, 3, 5, 13, 15, 9, 3, 7, 5, 7, 11, 13, 17, 13, 7, 5, 11, 9, 15, 7, 7, 7, 11, 15, 15, 5, 9, 11, 5, 9, 7, 9, 3, 9, 7, 5, 11, 5, 5, 5, 7, 5, 13, 9, 9, 14, 5, 9, 11, 7, 11, 11, 15, 3, 7, 5, 7, 9, 15, 5, 9, 9, 13, 11, 5, 9, 9, 13, 5, 11, 9, 5, 9, 3, 11, 7, 7, 15, 3, 5, 15, 3, 3, 11, 11, 3, 15, 5, 7, 5, 13, 9, 9, 5, 9, 5, 11, 5, 5, 3, 9, 13, 11, 7, 5, 7, 5, 3, 7, 7, 9, 7, 5, 5, 15, 9, 9, 3, 13, 3, 5, 11, 5, 9, 3, 13, 11, 5, 7, 16, 9, 3, 3, 11, 15, 7, 7, 9, 5, 5, 15, 9, 11, 17, 5, 5, 3, 9, 3, 9, 7, 9, 13, 9, 3, 9, 9, 11, 12, 11, 14, 15, 7, 7, 3, 3, 9, 5, 3, 9, 11, 7, 3, 5, 7, 7, 3, 3, 5, 7, 7, 9, 7, 7, 3, 5, 10, 9, 11, 13, 11, 3, 3, 3, 9, 11, 13, 9, 11, 3, 7, 16, 11, 3, 5, 16, 9, 13, 3, 15, 3, 5, 5, 3, 5, 11, 5, 3, 11, 9, 11, 3, 3, 11, 5, 17, 7, 7, 7, 9, 5, 7, 11, 11, 3, 11, 7, 5, 15, 7, 9, 11, 7, 5, 3, 3, 15, 7, 3, 7, 7, 5, 3, 15, 17, 11, 9, 5, 9, 9, 5, 12, 19, 15, 14, 13, 7, 13, 13, 17, 11, 9, 15, 5, 7, 5, 5, 5, 11, 15, 7, 11, 5, 9, 13, 11, 5, 5, 13, 9, 11, 7, 7, 5, 17, 11, 9, 3, 5, 3, 3, 3, 11, 9, 9, 3, 11, 13, 3, 11, 5, 5, 11, 11, 3, 5, 5, 5, 3, 3, 7, 3, 5, 11, 3, 9, 7, 9, 5, 9, 5, 3, 3, 3, 3, 13, 9, 15, 13, 5, 5, 5, 7, 5, 9, 11, 5, 11, 13, 3, 5, 5, 11, 5, 9, 5, 5, 3, 7, 5, 5, 7, 5, 3, 5, 14, 7, 5, 5, 11, 5, 11, 9, 11, 5, 11, 11, 9, 5, 3, 16, 9, 5, 7, 13, 13, 13, 7, 5, 9, 3, 3, 11, 11, 7, 3, 5, 12, 11, 7, 9, 9, 5, 11, 3, 7, 5, 13, 5, 3, 3, 3, 11, 9, 13, 15, 3, 15, 5, 3, 11, 11, 3, 9, 11, 3, 13, 9, 5, 13, 7, 3, 3, 3, 13, 3, 7, 5, 17, 9, 5, 7, 7, 7, 5, 3, 7, 13, 9, 14, 7, 9, 18, 11, 3, 17, 5, 15, 13, 5, 13, 9, 5, 11, 3, 15, 5, 15, 15, 5, 11, 7, 11, 3, 5, 13, 7, 3, 5, 3, 5, 9, 3, 3, 7, 9, 3, 13, 11, 7, 3, 5, 3, 3, 7, 7, 13, 11, 11, 17, 3, 7, 9, 14, 9, 9, 5, 7, 5, 15, 3, 9, 11, 3, 9, 5, 13, 3, 5, 3, 16, 9, 11, 5, 11, 7, 11, 3, 7, 7, 11, 5, 5, 9, 7, 7, 7, 7, 3, 7, 5, 7, 15, 5, 3, 3, 5, 3, 13, 3, 11, 5, 3, 5, 7, 5, 5, 13, 5, 11, 7, 11, 5, 11, 5, 3, 5, 5, 11, 7, 7, 9, 3, 15, 11, 5, 16, 3, 9, 15, 3, 11, 16, 5, 13, 5, 13, 9, 17, 9, 9, 9, 17, 3, 9, 9, 5, 7, 7, 3, 7, 13, 9, 11, 9, 7, 5, 9, 9, 7, 11, 5, 5, 7, 7, 7, 11, 7, 7, 5, 15, 5, 5, 5, 3, 3, 13, 7, 5, 5, 11, 5, 5, 9, 13, 5, 11, 11, 13, 5, 9, 5, 11, 7, 7, 5, 7, 7, 9, 5, 9, 5, 3, 5, 7, 15, 5, 3, 13, 11, 3, 7, 3, 9, 3, 11, 11, 3, 16, 9, 9, 5, 11, 5, 11, 7, 9, 5, 9, 12, 7, 3, 5, 9, 9, 7, 5, 3, 3, 3, 7, 5, 17, 12, 9, 11, 7, 3, 9, 11, 5, 11, 5, 11, 11, 7, 5, 9, 11, 9, 9, 3, 5, 7, 7, 3, 5, 9, 7, 5, 11, 9, 7, 3, 5, 3, 5, 14, 13, 7, 7, 5, 3, 7, 7, 11, 5, 5, 17, 7, 3, 15, 3, 5, 9, 17, 13, 9, 3, 15, 5, 7, 3, 9, 5, 5, 5, 15, 9, 7, 3, 3, 9, 7, 5, 3, 17, 11, 11, 5, 3, 11, 3, 13, 3, 11, 5, 13, 5, 11, 11, 5, 13, 9, 13, 15, 9, 13, 3, 3, 5, 12, 9, 13, 9, 5, 7, 5, 5, 3, 7, 11, 5, 5, 9, 7, 3, 7, 5, 5, 9, 9, 3, 13, 13, 5, 7, 13, 11, 7, 11, 9, 5, 7, 7, 11, 16, 11, 5, 14, 3, 9, 5, 9, 3, 11, 7, 9, 3, 5, 5, 5, 5, 11, 7, 7, 11, 17, 9, 3, 5, 3, 11, 5, 16, 9, 15, 7, 3, 3, 15, 3, 11, 13, 9, 5, 11, 5, 7, 3, 15, 9, 11, 7, 3, 3, 7, 3, 3, 7, 11, 7, 11, 3, 7, 7, 9, 3, 3, 5, 3, 9, 5, 13, 7, 5, 3, 5, 7, 11, 5, 9, 11, 5, 3, 9, 5, 7, 9, 7, 3, 9, 7, 5, 5, 7, 3, 3, 3, 13, 11, 11, 11, 9, 11, 7, 13, 9, 13, 7, 5, 11, 3, 7, 3, 11, 15, 3, 13, 9, 11, 13, 7, 13, 3, 7, 5, 11, 3, 12, 5, 14, 11, 5, 5, 5, 7, 9, 5, 5, 3, 15, 3, 9, 11, 12, 13, 5, 5, 5, 3, 5, 3, 7, 5, 7, 7, 7, 5, 5, 9, 9, 18, 11, 9, 5, 5, 5, 5, 14, 11, 7, 13, 7, 9, 7, 9, 9, 14, 11, 3, 9, 14, 7, 3, 3, 3, 9, 3, 14, 3, 9, 3, 17, 9, 11, 11, 5, 13, 11, 3, 3, 11, 5, 5, 15, 5, 5, 3, 7, 3, 15, 7, 5, 5, 9, 5, 5, 7, 3, 13, 7, 3, 13, 5, 9, 5, 13, 11, 11, 5, 9, 9, 15, 7, 9, 9, 13, 14, 9, 11, 7, 7, 15, 11, 9, 17, 7, 5, 3, 16, 11, 7, 3, 7, 15, 3, 5, 13, 13, 15, 7, 5, 9, 7, 5, 3, 3, 5, 7, 7, 11, 5, 3, 9, 7, 7, 5, 9, 17, 13, 5, 3, 11, 3, 7, 15, 9, 3, 13, 9, 5, 3, 13, 11, 3, 7, 3, 16, 9, 11, 5, 7, 3, 7, 7, 5, 3, 5, 9, 7, 3, 9, 11, 5, 13, 7, 7, 3, 3, 3, 9, 13, 5, 9, 9, 17, 9, 13, 5, 9, 11, 13, 5, 11, 9, 5, 3, 5, 7, 11, 11, 13, 9, 13, 9, 9, 5, 5, 11, 15, 9, 5, 11, 5, 7, 9, 9, 3, 5, 5, 14, 11, 3, 3, 13, 11, 14, 5, 12, 9, 7, 12, 5, 7, 11, 9, 7, 10, 11, 3, 11, 9, 3, 16, 7, 9, 3, 3, 11, 3, 16, 5, 13, 5, 7, 5, 7, 13, 7, 5, 13, 13, 7, 3, 11, 3, 13, 13, 9, 15, 16, 9, 13, 5, 9, 3, 12, 11, 5, 9, 13, 5, 7, 3, 9, 13, 9, 11, 13, 11, 5, 13, 11, 13, 15, 5, 16, 7, 5, 17, 11, 16, 7, 13, 9, 7, 3, 18, 11, 9, 7, 9, 5, 13, 9, 11, 13, 3, 7, 5, 3, 9, 9, 14, 11, 5, 5, 7, 15, 14, 5, 3, 5, 11, 13, 7, 5, 5, 5, 7, 3, 3, 15, 13, 5, 11, 7, 11, 9, 7, 5, 11, 5, 3, 13, 9, 13, 7, 11, 5, 7, 11, 15, 5, 12, 7, 5, 3, 7, 13, 3, 15, 11, 7, 13, 11, 16, 13, 7, 7, 11, 5, 15, 5, 7, 9, 9, 11, 5, 13, 7, 5, 7, 5, 13, 13, 9, 3, 3, 11, 9, 9, 7, 9, 5, 16, 13, 9, 3, 13, 14, 3, 5, 3, 5, 9, 9, 5, 3, 5, 5, 7, 7, 3, 7, 5, 5, 9, 9, 3, 5, 5, 5, 11, 5, 14, 3, 7, 11, 5, 16, 11, 11, 13, 13, 3, 5, 7, 11, 3, 7, 5, 17, 5, 7, 5, 3, 9, 3, 7, 3, 19, 13, 3, 13, 3, 3, 5, 5, 7, 13, 3, 3, 3, 3, 9, 5, 13, 7, 3, 3, 7, 13, 13, 5, 13, 17, 13, 15, 7, 7, 5, 3, 9, 11, 11, 13, 7, 12, 5, 5, 9, 11, 13, 13, 11, 13, 9, 7, 13, 11, 7, 11, 5, 5, 9, 5, 15, 5, 5, 5, 7, 13, 3, 11, 7, 13, 5, 3, 9, 15, 11, 9, 5, 9, 5, 13, 7, 13, 3, 7, 11, 9, 13, 9, 11, 11, 13, 9, 7, 9, 9, 13, 9, 3, 3, 13, 3, 9, 3, 7, 9, 9, 7, 5, 5, 7, 5, 7, 7, 7, 9, 3, 9, 3, 7, 3, 11, 3, 5, 3, 9, 3, 5, 9, 13, 3, 13, 3, 7, 11, 5, 11, 13, 11, 11, 11, 15, 7, 9, 5, 7, 3, 9, 9, 5, 7, 9, 11, 5, 11, 9, 11, 13, 5, 3, 5, 17, 3, 11, 3, 13, 15, 15, 9, 3, 3, 7, 11, 15, 13, 5, 5, 5, 13, 11, 11, 11, 9, 13, 7, 11, 5, 5, 9, 9, 13, 9, 5, 5, 11, 9, 7, 14, 3, 5, 12, 9, 11, 11, 5, 15, 9, 9, 7, 11, 7, 7, 3, 17, 7, 11, 5, 17, 3, 7, 5, 3, 13, 9, 3, 5, 13, 3, 9, 5, 13, 11, 5, 11, 3, 15, 5, 11, 5, 5, 3, 7, 7, 16, 7, 13, 9, 7, 3, 7, 9, 9, 7, 13, 3, 5, 13, 11, 13, 3, 12, 3, 7, 9, 7, 15, 3, 9, 5, 9, 7, 9, 7, 3, 9, 13, 3, 5, 5, 9, 9, 13, 5, 3, 9, 5, 7, 5, 9, 11, 3, 7, 13, 7, 11, 5, 11, 11, 3, 15, 11, 9, 7, 13, 5, 5, 3, 13, 11, 15, 3, 7, 5, 11, 13, 13, 3, 13, 11, 3, 3, 11, 7, 7, 7, 9, 3, 15, 15, 5, 3, 16, 16, 3, 9, 7, 13, 7, 11, 9, 5, 7, 11, 5, 12, 3, 13, 3, 5, 7, 9, 16, 9, 9, 11, 13, 5, 7, 9, 9, 11, 14, 13, 5, 9, 9, 11, 3, 5, 5, 11, 5, 9, 9, 11, 3, 15, 15, 3, 11, 5, 13, 11, 11, 9, 3, 7, 7, 17, 5, 9, 3, 3, 13, 5, 13, 11, 7, 3, 7, 5, 13, 9, 9, 5, 7, 5, 9, 11, 11, 5, 14, 9, 5, 5, 3, 11, 5, 7, 9, 11, 9, 9, 5, 5, 7, 5, 7, 11, 7, 7, 9, 5, 11, 7, 16, 9, 11, 14, 9, 5, 9, 3, 13, 5, 7, 5, 9, 7, 13, 13, 7, 11, 11, 5, 11, 13, 11, 7, 7, 5, 16, 11, 11, 9, 9, 5, 5, 3, 11, 5, 9, 7, 17, 5, 13, 3, 3, 9, 3, 11, 13, 5, 11, 3, 5, 3, 3, 3, 9, 3, 14, 7, 11, 5, 7, 9, 9, 13, 14, 13, 5, 7, 15, 7, 9, 5, 5, 11, 13, 9, 3, 13, 9, 7, 3, 7, 7, 3, 5, 5, 5, 9, 11, 3, 13, 5, 7, 5, 7, 11, 3, 11, 5, 7, 3, 3, 9, 3, 3, 11, 9, 11, 13, 5, 9, 11, 11, 9, 7, 3, 5, 7, 13, 9, 5, 9, 13, 7, 5, 3, 5, 3, 7, 9, 7, 9, 5, 13, 13, 9, 14, 7, 15, 3, 3, 3, 5, 3, 7, 3, 5, 5, 7, 7, 3, 9, 15, 13, 5, 7, 3, 5, 15, 7, 3, 5, 11, 5, 11, 9, 5, 9, 5, 14, 5, 5, 5, 7, 3, 7, 11, 5, 3, 7, 11, 14, 11, 11, 11, 3, 7, 9, 3, 13, 11, 3, 11, 15, 17, 11, 13, 7, 3, 13, 7, 13, 13, 11, 7, 5, 3, 3, 17, 13, 5, 3, 3, 5, 5, 5, 5, 11, 11, 11, 11, 9, 3, 5, 11, 7, 3, 11, 9, 9, 9, 3, 3, 13, 5, 5, 5, 5, 5, 11, 13, 13, 16, 5, 5, 5, 5, 3, 7, 9, 9, 5, 7, 11, 15, 3, 3, 9, 3, 5, 7, 11, 7, 13, 19, 9, 9, 9, 7, 7, 5, 13, 5, 11, 3, 9, 15, 15, 5, 9, 3, 5, 9, 5, 3, 9, 5, 5, 9, 11, 13, 5, 5, 3, 11, 11, 15, 7, 7, 13, 5, 9, 5, 9, 7, 7, 14, 11, 7, 9, 9, 9, 11, 11, 11, 9, 5, 7, 11, 11, 13, 13, 11, 5, 5, 11, 9, 7, 5, 12, 15, 7, 3, 7, 13, 11, 7, 9, 11, 3, 5, 5, 15, 15, 3, 5, 15, 11, 7, 9, 9, 5, 13, 9, 5, 3, 5, 5, 12, 13, 5, 3, 5, 11, 7, 5, 5, 9, 11, 3, 5, 11, 5, 7, 14, 9, 9, 11, 5, 11, 9, 15, 5, 13, 15, 9, 17, 9, 7, 9, 15, 14, 9, 3, 5, 7, 9, 11, 9, 7, 13, 9, 7, 3, 5, 5, 12, 13, 11, 3, 9, 5, 3, 5, 5, 3, 13, 9, 17, 3, 11, 5, 5, 5, 9, 3, 13, 5, 9, 7, 3, 7, 15, 13, 13, 11, 13, 9, 5, 5, 7, 3, 9, 5, 7, 9, 9, 7, 7, 13, 9, 13, 5, 11, 11, 9, 11, 17, 7, 7, 7, 7, 5, 5, 11, 3, 3, 12, 9, 13, 5, 9, 5, 5, 11, 7, 9, 3, 5, 5, 5, 3, 7, 13, 3, 5, 5, 13, 13, 3, 13, 7, 5, 13, 15, 7, 13, 3, 9, 9, 11, 13, 9, 13, 5, 12, 5, 7, 5, 17, 11, 7, 5, 5, 9, 7, 5, 9, 7, 3, 15, 5, 3, 3, 11, 9, 13, 9, 11, 13, 13, 9, 7, 9, 15, 5, 3, 3, 3, 13, 7, 7, 9, 3, 3, 11, 5, 7, 13, 3, 3, 5, 7, 13, 11, 5, 7, 15, 7, 5, 3, 13, 3, 7, 7, 5, 7, 7, 3, 15, 5, 7, 7, 5, 5, 7, 11, 9, 9, 9, 11, 9, 9, 3, 7, 3, 5, 9, 7, 11, 17, 11, 9, 9, 3, 5, 11, 11, 3, 11, 3, 15, 15, 5, 7, 7, 7, 13, 7, 15, 17, 9, 3, 5, 7, 9, 11, 9, 3, 5, 13, 3, 7, 7, 11, 11, 5, 7, 17, 7, 9, 7, 11, 3, 7, 5, 3, 11, 13, 16, 3, 7, 5, 5, 15, 13, 5, 7, 7, 9, 7, 13, 9, 11, 14, 5, 3, 13, 13, 3, 7, 11, 11, 5, 9, 7, 5, 9, 11, 5, 9, 11, 9, 17, 3, 13, 11, 19, 9, 3, 7, 9, 9, 11, 3, 5, 11, 5, 5, 7, 3, 9, 5, 3, 7, 5, 9, 9, 14, 5, 3, 5, 7, 5, 15, 5, 5, 7, 5, 9, 3, 9, 9, 12, 7, 5, 7, 11, 9, 7, 9, 13, 7, 13, 7, 18, 5, 13, 15, 7, 3, 5, 7, 3, 5, 3, 9, 3, 13, 13, 11, 5, 11, 5, 7, 7, 5, 7, 11, 15, 9, 3, 11, 9, 7, 5, 13, 5, 7, 13, 7, 15, 5, 3, 9, 13, 11, 14, 13, 9, 14, 13, 3, 13, 3, 9, 5, 11, 3, 3, 7, 5, 3, 7, 3, 7, 3, 9, 3, 9, 3, 13, 3, 7, 15, 3, 15, 11, 3, 13, 5, 7, 3, 5, 11, 9, 5, 9, 5, 7, 3, 5, 11, 9, 5, 5, 5, 5, 11, 9, 7, 7, 11, 3, 11, 12, 7, 5, 11, 3, 5, 13, 13, 9, 13, 3, 9, 3, 15, 3, 7, 7, 15, 15, 5, 3, 3, 7, 5, 11, 13, 7, 13, 9, 11, 3, 13, 5, 9, 3, 9, 11, 7, 3, 3, 11, 5, 12, 7, 13, 13, 5, 5, 3, 5, 7, 7, 11, 9, 3, 5, 5, 3, 11, 5, 11, 5, 11, 9, 3, 3, 9, 3, 9, 13, 11, 7, 3, 9, 9, 17, 9, 9, 9, 15, 11, 3, 13, 15, 9, 11, 13, 9, 13, 11, 3, 9, 5, 3, 13, 9, 9, 5, 9, 3, 9, 5, 5, 14, 9, 3, 3, 7, 9, 5, 7, 7, 15, 9, 13, 3, 11, 7, 7, 5, 7, 11, 11, 5, 3, 7, 3, 5, 11, 11, 5, 7, 3, 3, 3, 17, 11, 9, 3, 5, 9, 7, 5, 7, 9, 5, 5, 11, 9, 9, 5, 9, 5, 13, 7, 3, 5, 9, 15, 9, 15, 3, 3, 5, 9, 5, 7, 13, 11, 3, 7, 17, 9, 12, 13, 11, 7, 7, 7, 14, 11, 11, 11, 16, 11, 3, 9, 13, 9, 11, 7, 11, 13, 13, 7, 5, 5, 3, 7, 11, 11, 5, 5, 7, 11, 9, 3, 15, 9, 5, 7, 3, 9, 9, 5, 14, 13, 13, 5, 7, 5, 9, 5, 3, 3, 13, 7, 9, 14, 9, 5, 11, 5, 3, 12, 7, 5, 9, 15, 3, 11, 5, 13, 9, 7, 3, 5, 17, 9, 3, 5, 13, 9, 11, 5, 11, 5, 5, 11, 5, 11, 5, 9, 13, 7, 7, 13, 3, 11, 13, 11, 9, 7, 14, 3, 14, 9, 11, 11, 9, 11, 9, 3, 7, 5, 13, 11, 15, 3, 13, 9, 5, 9, 9, 7, 9, 5, 13, 7, 11, 9, 9, 9, 5, 9, 14, 13, 3, 13, 13, 5, 7, 5, 9, 5, 7, 9, 15, 13, 11, 7, 5, 16, 5, 5, 3, 7, 5, 9, 7, 14, 3, 9, 7, 11, 7, 5, 3, 15, 15, 3, 7, 5, 9, 16, 7, 9, 7, 11, 5, 9, 7, 7, 7, 5, 3, 15, 5, 13, 5, 5, 5, 5, 3, 3, 7, 7, 5, 3, 5, 13, 5, 11, 3, 10, 5, 9, 16, 3, 11, 7, 11, 7, 3, 7, 5, 7, 11, 11, 5, 15, 7, 5, 3, 9, 7, 7, 9, 3, 5, 7, 3, 9, 3, 7, 11, 11, 7, 14, 5, 5, 9, 9, 7, 9, 5, 7, 7, 9, 15, 5, 16, 7, 13, 13, 7, 5, 11, 5, 11, 5, 11, 7, 5, 11, 14, 13, 13, 5, 11, 13, 13, 9, 7, 12, 9, 7, 5, 5, 5, 3, 7, 13, 9, 3, 11, 13, 15, 14, 5, 13, 5, 3, 5, 9, 3, 3, 11, 7, 3, 9, 5, 5, 9, 9, 5, 5, 13, 13, 9, 9, 3, 11, 5, 15, 12, 3, 7, 13, 5, 15, 3, 5, 7, 3, 9, 3, 9, 7, 11, 14, 7, 7, 9, 9, 7, 17, 3, 11, 3, 9, 9, 11, 9, 13, 5, 5, 9, 5, 15, 12, 11, 3, 11, 7, 16, 7, 7, 9, 13, 7, 3, 13, 3, 7, 5, 5, 11, 7, 7, 3, 11, 12, 11, 9, 11, 7, 13, 7, 7, 7, 5, 5, 3, 11, 3, 5, 7, 9, 9, 3, 5, 3, 3, 11, 9, 3, 9, 9, 9, 5, 7, 13, 5, 17, 9, 14, 16, 3, 13, 11, 5, 5, 13, 13, 13, 11, 13, 11, 9, 15, 9, 15, 5, 14, 3, 5, 3, 7, 5, 7, 7, 3, 5, 9, 13, 3, 13, 9, 5, 5, 7, 5, 9, 7, 5, 9, 13, 5, 5, 11, 11, 11, 3, 3, 7, 7, 7, 9, 13, 3, 5, 9, 7, 5, 5, 13, 15, 3, 7, 5, 3, 7, 5, 7, 11, 7, 9, 7, 9, 12, 7, 9, 5, 16, 7, 9, 7, 11, 11, 5, 13, 5, 13, 3, 9, 5, 16, 7, 5, 9, 3, 5, 9, 13, 11, 9, 11, 5, 5, 15, 9, 5, 11, 5, 3, 3, 13, 5, 17, 11, 5, 7, 3, 17, 7, 13, 7, 11, 5, 13, 15, 5, 7, 5, 3, 5, 7, 13, 9, 11, 9, 7, 9, 5, 3, 15, 5, 13, 5, 3, 13, 7, 13, 3, 13, 16, 9, 5, 3, 9, 11, 11, 5, 7, 3, 9, 13, 7, 7, 3, 5, 7, 15, 9, 3, 5, 3, 3, 13, 5, 7, 9, 3, 9, 13, 3, 11, 9, 3, 7, 13, 9, 7, 5, 13, 13, 13, 5, 5, 7, 11, 7, 3, 14, 9, 3, 9, 9, 9, 11, 7, 5, 7, 7, 3, 7, 14, 13, 7, 9, 5, 5, 11, 15, 11, 7, 7, 3, 15, 9, 7, 9, 5, 9, 9, 14, 5, 7, 5, 7, 5, 13, 5, 5, 12, 9, 7, 3, 15, 7, 13, 9, 15, 16, 11, 9, 13, 17, 9, 5, 13, 3, 5, 7, 5, 9, 15, 11, 3, 9, 9, 7, 9, 9, 3, 3, 3, 11, 7, 5, 7, 17, 3, 9, 7, 11, 9, 11, 5, 13, 5, 5, 11, 3, 7, 5, 13, 11, 9, 3, 5, 13, 11, 7, 7, 5, 3, 9, 5, 15, 5, 9, 9, 11, 3, 7, 7, 7, 11, 13, 5, 7, 13, 3, 15, 5, 5, 13, 9, 17, 5, 9, 9, 3, 13, 16, 12, 9, 9, 7, 3, 11, 15, 11, 5, 7, 11, 7, 7, 13, 9, 13, 5, 5, 7, 5, 7, 13, 5, 5, 13, 7, 3, 9, 7, 5, 13, 13, 5, 7, 5, 3, 9, 7, 11, 11, 3, 5, 7, 13, 5, 12, 5, 14, 15, 15, 7, 3, 7, 7, 9, 7, 14, 9, 11, 5, 5, 3, 9, 3, 3, 5, 5, 5, 5, 11, 7, 9, 7, 9, 3, 13, 11, 7, 5, 13, 3, 7, 7, 5, 15, 17, 7, 5, 11, 5, 3, 13, 15, 7, 13, 5, 9, 11, 9, 11, 13, 3, 13, 13, 7, 11, 9, 7, 11, 5, 5, 9, 5, 11, 9, 9, 9, 9, 13, 7, 7, 7, 11, 9, 5, 17, 5, 11, 9, 9, 3, 11, 3, 5, 3, 3, 11, 3, 5, 13, 7, 5, 5, 5, 12, 14, 15, 7, 11, 11, 3, 11, 5, 9, 11, 7, 5, 3, 5, 15, 13, 7, 5, 13, 3, 7, 5, 5, 5, 3, 3, 15, 11, 13, 7, 5, 5, 7, 3, 7, 11, 5, 11, 14, 11, 11, 13, 13, 11, 13, 7, 5, 3, 11, 7, 13, 3, 15, 11, 7, 3, 9, 3, 7, 11, 3, 13, 5, 3, 3, 7, 5, 15, 13, 3, 9, 11, 9, 13, 5, 9, 9, 13, 11, 5, 9, 5, 5, 7, 5, 5, 5, 11, 7, 11, 13, 13, 5, 7, 5, 3, 13, 7, 3, 5, 11, 5, 5, 5, 7, 7, 5, 5, 5, 11, 9, 13, 3, 9, 9, 11, 3, 9, 11, 9, 7, 3, 9, 5, 11, 5, 5, 11, 9, 7, 13, 7, 13, 5, 5, 3, 11, 9, 3, 9, 9, 7, 9, 3, 3, 17, 11, 11, 9, 5, 12, 11, 3, 13, 14, 3, 13, 7, 5, 5, 5, 3, 3, 5, 15, 13, 5, 5, 11, 3, 11, 11, 14, 7, 3, 13, 3, 7, 3, 11, 13, 5, 9, 11, 11, 11, 7, 9, 5, 3, 7, 3, 9, 3, 13, 5, 15, 13, 5, 9, 7, 13, 11, 3, 5, 11, 7, 7, 7, 7, 5, 13, 11, 7, 9, 3, 7, 9, 9, 12, 5, 14, 9, 7, 5, 17, 13, 14, 3, 5, 18, 7, 5, 7, 13, 5, 13, 5, 7, 3, 3, 9, 5, 5, 7, 5, 3, 5, 13, 7, 7, 11, 9, 9, 9, 9, 5, 11, 5, 5, 15, 5, 11, 11, 7, 9, 13, 7, 13, 11, 5, 7, 17, 3, 7, 3, 7, 3, 11, 7, 9, 11, 7, 3, 7, 5, 5, 7, 11, 7, 3, 13, 3, 5, 13, 11, 5, 5, 5, 5, 7, 7, 9, 3, 7, 7, 5, 11, 7, 15, 11, 7, 7, 9, 19, 5, 3, 11, 7, 17, 7, 3, 5, 3, 9, 5, 15, 3, 9, 7, 5, 5, 3, 5, 7, 15, 7, 7, 9, 3, 15, 9, 11, 9, 7, 11, 13, 9, 11, 5, 9, 11, 5, 13, 13, 5, 11, 3, 15, 13, 11, 11, 13, 11, 15, 5, 9, 9, 3, 5, 9, 5, 5, 14, 7, 9, 5, 11, 3, 5, 3, 9, 3, 7, 7, 7, 9, 5, 5, 3, 3, 13, 5, 3, 9, 7, 9, 9, 5, 7, 7, 9, 15, 17, 5, 9, 11, 7, 9, 3, 7, 5, 5, 9, 11, 3, 9, 7, 11, 9, 7, 9, 11, 5, 5, 7, 7, 9, 11, 7, 3, 5, 9, 9, 9, 5, 7, 7, 11, 11, 15, 7, 11, 3, 5, 13, 7, 7, 7, 7, 7, 13, 9, 7, 9, 12, 11, 5, 3, 11, 7, 9, 5, 9, 13, 7, 14, 9, 17, 3, 12, 7, 13, 13, 9, 13, 7, 7, 7, 9, 7, 17, 5, 7, 5, 5, 13, 3, 9, 3, 7, 5, 5, 13, 11, 5, 7, 5, 15, 7, 7, 9, 11, 5, 5, 7, 9, 7, 7, 5, 5, 13, 9, 5, 5, 13, 11, 7, 7, 14, 15, 12, 11, 7, 11, 7, 3, 5, 13, 5, 13, 11, 11, 13, 9, 3, 11, 9, 9, 3, 7, 11, 9, 5, 3, 7, 11, 9, 9, 5, 3, 7, 7, 7, 14, 7, 9, 13, 13, 5, 15, 13, 5, 9, 15, 15, 15, 5, 3, 11, 5, 7, 7, 9, 5, 11, 9, 7, 9, 11, 9, 11, 3, 3, 7, 7, 3, 3, 17, 5, 14, 3, 13, 5, 3, 7, 15, 11, 15, 5, 11, 14, 5, 13, 17, 9, 9, 3, 11, 5, 5, 9, 5, 5, 9, 5, 5, 9, 9, 14, 3, 9, 15, 3, 15, 15, 3, 15, 16, 12, 13, 3, 7, 9, 3, 5, 5, 9, 5, 5, 3, 9, 7, 14, 5, 9, 7, 7, 7, 9, 3, 9, 14, 15, 15, 5, 3, 5, 7, 5, 7, 5, 13, 11, 5, 15, 7, 5, 12, 12, 7, 9, 5, 16, 5, 7, 9, 5, 9, 7, 5, 13, 7, 5, 7, 13, 9, 9, 15, 3, 14, 9, 17, 5, 11, 5, 3, 5, 9, 13, 11, 16, 3, 9, 7, 3, 3, 16, 7, 3, 11, 9, 14, 9, 3, 5, 3, 5, 15, 9, 11, 3, 5, 11, 3, 11, 7, 3, 11, 11, 5, 16, 7, 9, 13, 7, 5, 11, 11, 5, 7, 14, 11, 7, 5, 9, 3, 9, 5, 3, 5, 13, 3, 15, 11, 5, 7, 3, 11, 5, 7, 3, 11, 7, 9, 5, 11, 13, 9, 5, 3, 13, 9, 3, 13, 5, 11, 3, 16, 5, 11, 16, 7, 11, 9, 5, 9, 7, 5, 13, 9, 9, 5, 3, 14, 3, 9, 3, 13, 7, 5, 5, 13, 11, 5, 5, 14, 3, 3, 12, 5, 5, 5, 3, 11, 9, 13, 5, 14, 5, 3, 13, 11, 9, 3, 15, 5, 5, 9, 13, 5, 3, 11, 15, 3, 9, 11, 11, 15, 7, 5, 13, 5, 5, 9, 5, 5, 3, 9, 5, 5, 11, 13, 3, 11, 15, 7, 15, 3, 3, 5, 7, 3, 11, 7, 7, 11, 3, 5, 11, 3, 5, 7, 11, 5, 3, 5, 7, 7, 16, 5, 13, 3, 5, 11, 13, 3, 14, 16, 3, 11, 11, 9, 3, 13, 13, 13, 11, 7, 9, 11, 11, 13, 5, 9, 13, 3, 13, 11, 7, 5, 7, 3, 7, 11, 3, 5, 11, 12, 7, 9, 11, 3, 5, 16, 9, 15, 7, 9, 3, 5, 5, 13, 7, 7, 11, 13, 9, 5, 3, 9, 7, 9, 7, 5, 11, 9, 7, 3, 9, 9, 5, 5, 7, 5, 11, 5, 5, 11, 7, 7, 7, 3, 15, 7, 7, 5, 9, 5, 3, 7, 3, 3, 5, 7, 11, 11, 9, 13, 11, 18, 7, 17, 11, 14, 5, 3, 3, 3, 14, 3, 3, 5, 5, 3, 7, 9, 9, 3, 9, 5, 5, 5, 5, 16, 3, 13, 3, 12, 9, 5, 3, 5, 13, 9, 7, 7, 9, 9, 3, 7, 3, 7, 9, 3, 19, 3, 5, 9, 3, 9, 15, 7, 11, 3, 9, 9, 9, 9, 15, 13, 13, 5, 9, 7, 5, 13, 5, 5, 5, 5, 7, 17, 9, 3, 3, 9, 5, 3, 13, 5, 11, 5, 13, 11, 5, 7, 11, 5, 3, 13, 7, 3, 7, 5, 5, 9, 17, 13, 9, 18, 5, 11, 9, 7, 3, 3, 9, 9, 5, 11, 9, 13, 3, 7, 11, 5, 7, 11, 3, 13, 11, 16, 3, 7, 9, 7, 9, 11, 9, 5, 5, 11, 3, 9, 3, 3, 5, 9, 13, 17, 7, 9, 7, 5, 3, 11, 7, 9, 3, 14, 5, 5, 5, 3, 3, 3, 11, 15, 5, 3, 11, 9, 5, 5, 9, 5, 3, 7, 11, 11, 7, 3, 11, 5, 11, 16, 7, 7, 13, 11, 11, 5, 3, 11, 5, 11, 5, 7, 5, 13, 5, 5, 7, 7, 5, 5, 11, 5, 5, 11, 3, 5, 3, 7, 16, 5, 3, 5, 3, 7, 17, 5, 9, 7, 3, 9, 11, 7, 13, 11, 9, 3, 9, 9, 7, 7, 9, 11, 7, 13, 5, 13, 7, 7, 3, 11, 13, 5, 11, 5, 7, 17, 9, 13, 7, 17, 7, 7, 13, 3, 15, 5, 5, 11, 7, 7, 3, 5, 3, 7, 7, 7, 7, 7, 9, 13, 5, 3, 5, 13, 11, 13, 3, 3, 5, 11, 13, 5, 9, 11, 7, 9, 7, 11, 9, 9, 3, 3, 13, 15, 13, 7, 11, 7, 7, 7, 5, 7, 9, 11, 16, 9, 7, 7, 9, 9, 13, 3, 13, 5, 11, 5, 5, 3, 5, 3, 7, 7, 16, 3, 5, 5, 5, 9, 5, 11, 9, 11, 5, 5, 13, 5, 9, 9, 7, 5, 9, 11, 7, 5, 3, 9, 9, 5, 5, 5, 3, 13, 13, 13, 9, 9, 5, 3, 11, 11, 11, 7, 7, 3, 11, 9, 5, 5, 13, 11, 3, 9, 3, 5, 9, 9, 5, 5, 5, 5, 9, 13, 5, 5, 7, 13, 9, 3, 11, 13, 3, 15, 14, 5, 12, 3, 11, 7, 3, 7, 15, 11, 5, 5, 9, 15, 5, 13, 13, 5, 7, 7, 5, 5, 9, 15, 5, 11, 11, 12, 7, 7, 5, 5, 7, 7, 5, 3, 5, 7, 5, 9, 7, 11, 3, 5, 5, 11, 11, 3, 3, 15, 7, 5, 13, 9, 16, 3, 9, 11, 5, 7, 3, 11, 15, 5, 5, 9, 7, 13, 3, 7, 9, 11, 11, 7, 7, 5, 9, 11, 7, 13, 3, 3, 5, 5, 9, 3, 5, 5, 3, 13, 13, 3, 5, 5, 3, 9, 5, 9, 13, 3, 3, 7, 5, 11, 3, 5, 5, 7, 7, 13, 7, 9, 13, 5, 13, 11, 13, 7, 7, 5, 7, 9, 7, 7, 13, 11, 5, 13, 7, 11, 5, 11, 3, 9, 3, 7, 5, 11, 9, 9, 7, 7, 14, 9, 5, 9, 5, 5, 9, 9, 7, 5, 11, 11, 11, 17, 11, 3, 7, 9, 3, 7, 7, 9, 11, 7, 5, 9, 7, 11, 3, 9, 5, 5, 9, 9, 17, 11, 7, 13, 13, 7, 7, 11, 9, 11, 5, 7, 9, 11, 5, 3, 9, 13, 11, 9, 3, 5, 3, 7, 9, 5, 9, 7, 3, 3, 13, 13, 7, 13, 9, 3, 7, 3, 5, 7, 5, 5, 3, 17, 7, 7, 3, 11, 5, 5, 15, 5, 13, 17, 5, 3, 7, 7, 5, 11, 3, 13, 5, 7, 3, 3, 12, 9, 15, 5, 7, 11, 9, 13, 3, 5, 5, 3, 13, 13, 7, 11, 5, 15, 7, 7, 5, 13, 9, 13, 3, 5, 5, 14, 7, 5, 7, 7, 7, 7, 5, 5, 7, 9, 5, 5, 3, 12, 7, 9, 13, 7, 16, 11, 7, 3, 7, 11, 13, 7, 13, 9, 7, 5, 5, 3, 9, 9, 5, 9, 9, 7, 11, 3, 7, 7, 5, 9, 7, 7, 9, 12, 11, 9, 7, 11, 7, 3, 11, 11, 7, 17, 3, 3, 7, 15, 7, 11, 5, 3, 9, 9, 13, 5, 5, 13, 3, 11, 11, 3, 15, 3, 15, 9, 3, 7, 5, 5, 3, 15, 5, 5, 11, 5, 17, 15, 9, 11, 11, 9, 5, 11, 5, 9, 5, 5, 5, 5, 5, 11, 9, 7, 9, 7, 9, 5, 3, 5, 5, 13, 9, 17, 11, 9, 7, 7, 5, 15, 13, 7, 9, 5, 14, 11, 16, 12, 11, 5, 13, 9, 5, 11, 3, 9, 13, 7, 7, 5, 18, 11, 3, 11, 5, 7, 3, 5, 5, 7, 11, 9, 9, 11, 3, 13, 7, 9, 7, 7, 11, 11, 16, 5, 13, 11, 7, 9, 13, 7, 11, 11, 14, 9, 15, 13, 5, 13, 11, 13, 11, 13, 5, 11, 5, 5, 5, 3, 7, 5, 10, 7, 15, 9, 5, 5, 11, 13, 9, 5, 5, 11, 3, 11, 5, 13, 7, 7, 5, 7, 5, 9, 5, 3, 5, 13, 16, 12, 3, 7, 15, 9, 5, 7, 11, 15, 3, 9, 11, 5, 3, 11, 9, 5, 7, 11, 5, 7, 11, 18, 11, 5, 13, 3, 11, 13, 11, 5, 9, 5, 5, 3, 9, 13, 5, 5, 13, 13, 7, 15, 3, 9, 9, 11, 5, 5, 11, 7, 9, 7, 9, 7, 5, 7, 13, 5, 12, 11, 11, 9, 3, 3, 5, 11, 11, 3, 9, 3, 3, 3, 11, 11, 9, 19, 9, 5, 9, 9, 9, 7, 17, 9, 5, 5, 3, 13, 7, 9, 17, 17, 7, 5, 15, 5, 5, 7, 7, 9, 9, 9, 5, 7, 9, 7, 3, 9, 15, 13, 11, 11, 3, 11, 5, 3, 12, 3, 7, 13, 13, 11, 3, 9, 9, 7, 15, 5, 5, 9, 15, 3, 9, 17, 9, 9, 7, 5, 11, 15, 15, 13, 15, 17, 5, 13, 9, 15, 11, 9, 9, 3, 7, 5, 11, 5, 3, 14, 11, 5, 7, 7, 7, 5, 3, 11, 7, 7, 9, 11, 15, 15, 7, 7, 5, 11, 15, 13, 7, 7, 15, 9, 11, 13, 15, 5, 13, 3, 5, 15, 3, 11, 3, 9, 7, 5, 5, 3, 13, 5, 11, 11, 9, 13, 13, 3, 5, 5, 5, 13, 9, 3, 3, 7, 5, 15, 3, 11, 11, 11, 7, 3, 3, 11, 7, 11, 7, 5, 3, 3, 9, 17, 9, 3, 9, 9, 3, 11, 7, 11, 7, 11, 11, 7, 9, 7, 7, 5, 5, 3, 5, 13, 13, 13, 11, 7, 5, 7, 11, 9, 9, 5, 15, 9, 9, 3, 11, 5, 7, 11, 7, 3, 11, 9, 7, 11, 13, 3, 5, 11, 15, 17, 9, 11, 11, 13, 13, 7, 9, 3, 7, 11, 11, 9, 7, 7, 11, 3, 5, 9, 7, 9, 5, 7, 3, 13, 13, 3, 13, 5, 11, 15, 13, 11, 11, 9, 7, 9, 11, 17, 5, 7, 5, 3, 11, 7, 9, 7, 5, 3, 3, 3, 5, 19, 11, 5, 9, 5, 9, 5, 5, 7, 3, 3, 5, 11, 9, 3, 7, 3, 13, 13, 5, 14, 9, 7, 13, 15, 11, 5, 12, 3, 11, 7, 9, 7, 5, 3, 16, 16, 9, 5, 14, 9, 5, 7, 9, 7, 5, 9, 7, 9, 3, 9, 7, 5, 9, 3, 7, 7, 3, 14, 3, 9, 7, 7, 13, 11, 11, 5, 5, 9, 5, 7, 5, 9, 5, 13, 11, 5, 5, 3, 3, 3, 7, 3, 9, 7, 15, 9, 5, 11, 15, 7, 21, 13, 7, 13, 5, 7, 15, 13, 9, 9, 5, 5, 9, 5, 5, 14, 7, 9, 5, 3, 3, 11, 11, 5, 3, 13, 3, 7, 3, 13, 7, 3, 5, 3, 11, 3, 9, 7, 7, 9, 5, 7, 13, 11, 3, 7, 5, 11, 11, 7, 11, 7, 5, 5, 3, 13, 7, 7, 3, 11, 5, 5, 9, 9, 9, 3, 5, 13, 9, 15, 5, 9, 7, 7, 3, 15, 7, 11, 11, 7, 9, 11, 5, 15, 5, 11, 7, 13, 11, 9, 5, 12, 7, 9, 15, 11, 5, 13, 9, 13, 5, 5, 11, 13, 3, 3, 13, 5, 13, 5, 13, 5, 5, 5, 5, 7, 5, 13, 7, 5, 5, 7, 9, 13, 11, 3, 5, 9, 13, 3, 5, 11, 13, 5, 7, 7, 3, 3, 7, 5, 11, 7, 11, 13, 5, 11, 5, 7, 3, 3, 13, 7, 14, 5, 5, 5, 7, 13, 5, 7, 3, 15, 3, 11, 3, 11, 11, 5, 12, 13, 5, 7, 7, 3, 3, 7, 5, 9, 13, 11, 12, 15, 12, 11, 5, 3, 5, 5, 5, 9, 7, 13, 13, 13, 9, 5, 5, 13, 7, 3, 13, 5, 14, 5, 7, 14, 9, 7, 11, 7, 5, 5, 9, 7, 15, 7, 7, 15, 9, 11, 5, 3, 11, 7, 3, 7, 5, 7, 5, 3, 5, 9, 15, 5, 5, 5, 9, 15, 7, 7, 15, 11, 3, 9, 9, 5, 7, 11, 5, 11, 11, 5, 11, 5, 5, 7, 11, 3, 7, 9, 9, 7, 9, 3, 11, 7, 17, 5, 15, 5, 3, 5, 5, 7, 13, 9, 5, 13, 13, 3, 3, 3, 9, 3, 7, 15, 3, 5, 15, 11, 13, 11, 16, 3, 5, 17, 3, 7, 5, 11, 5, 16, 7, 11, 7, 11, 15, 7, 9, 3, 11, 14, 11, 9, 9, 11, 7, 7, 9, 15, 11, 9, 5, 3, 13, 15, 7, 5, 5, 9, 5, 7, 5, 3, 5, 7, 7, 9, 9, 9, 5, 11, 11, 7, 13, 7, 11, 5, 9, 13, 11, 5, 13, 9, 7, 5, 11, 11, 11, 3, 11, 9, 9, 7, 12, 3, 7, 5, 3, 5, 5, 5, 15, 9, 15, 3, 3, 9, 13, 13, 11, 7, 13, 15, 9, 5, 5, 5, 14, 5, 13, 3, 5, 9, 3, 16, 15, 11, 3, 3, 3, 7, 5, 13, 3, 13, 9, 9, 9, 9, 9, 3, 7, 7, 9, 7, 3, 9, 5, 7, 7, 3, 3, 11, 5, 5, 13, 9, 7, 9, 5, 11, 5, 13, 7, 5, 14, 3, 11, 3, 5, 13, 9, 9, 5, 3, 5, 13, 13, 13, 15, 7, 9, 5, 16, 3, 3, 7, 11, 7, 11, 9, 7, 13, 7, 15, 5, 13, 18, 14, 11, 3, 3, 11, 9, 11, 3, 5, 13, 9, 7, 9, 3, 15, 3, 5, 5, 5, 13, 7, 9, 13, 11, 11, 3, 9, 17, 5, 9, 13, 9, 16, 5, 9, 5, 9, 7, 9, 13, 9, 15, 9, 9, 5, 5, 3, 5, 5, 7, 9, 5, 15, 9, 9, 3, 14, 5, 3, 9, 11, 11, 7, 17, 7, 7, 3, 15, 3, 7, 9, 11, 5, 15, 7, 11, 11, 3, 9, 5, 7, 7, 3, 5, 13, 9, 11, 11, 3, 9, 5, 11, 13, 5, 11, 3, 3, 9, 5, 5, 7, 15, 3, 5, 14, 9, 12, 3, 3, 11, 5, 5, 9, 11, 9, 9, 7, 7, 9, 5, 11, 5, 7, 5, 5, 7, 5, 7, 9, 3, 15, 9, 3, 7, 5, 5, 14, 12, 3, 17, 5, 3, 9, 5, 7, 9, 15, 3, 13, 5, 11, 13, 7, 5, 11, 7, 7, 3, 9, 5, 11, 9, 3, 3, 11, 14, 11, 7, 11, 11, 7, 7, 11, 7, 11, 7, 3, 13, 16, 7, 5, 7, 17, 3, 11, 15, 11, 11, 13, 5, 7, 3, 17, 13, 15, 3, 3, 15, 3, 7, 9, 11, 3, 16, 7, 9, 13, 13, 3, 3, 3, 7, 14, 5, 7, 15, 3, 5, 7, 11, 5, 5, 3, 7, 11, 11, 5, 9, 9, 9, 9, 5, 3, 13, 7, 5, 7, 11, 7, 3, 5, 9, 15, 3, 9, 14, 5, 13, 3, 13, 9, 3, 11, 11, 9, 11, 7, 3, 3, 7, 7, 9, 5, 5, 7, 3, 7, 13, 11, 5, 9, 9, 5, 7, 7, 5, 5, 5, 9, 13, 12, 5, 15, 9, 9, 5, 9, 9, 5, 7, 7, 15, 5, 9, 13, 7, 9, 14, 3, 5, 3, 13, 11, 5, 11, 9, 5, 5, 5, 5, 7, 7, 5, 3, 11, 5, 3, 15, 11, 11, 7, 17, 9, 3, 9, 13, 13, 7, 11, 9, 9, 9, 11, 7, 13, 13, 11, 7, 11, 5, 5, 5, 11, 9, 5, 13, 3, 7, 13, 3, 7, 5, 15, 3, 5, 7, 9, 11, 13, 3, 9, 5, 5, 7, 17, 3, 11, 11, 13, 7, 13, 13, 13, 7, 9, 5, 11, 11, 3, 14, 5, 11, 5, 7, 11, 3, 15, 11, 9, 7, 5, 9, 11, 3, 7, 9, 3, 9, 5, 7, 3, 7, 9, 5, 7, 7, 5, 7, 3, 9, 9, 14, 5, 5, 7, 15, 7, 13, 9, 11, 13, 13, 5, 9, 12, 11, 3, 15, 7, 5, 5, 14, 15, 7, 5, 11, 11, 9, 3, 9, 11, 5, 5, 5, 7, 9, 5, 9, 7, 9, 13, 5, 11, 5, 9, 11, 7, 3, 16, 13, 5, 7, 9, 11, 7, 5, 13, 11, 5, 11, 11, 5, 7, 9, 11, 3, 11, 7, 5, 7, 5, 5, 11, 7, 9, 5, 13, 5, 5, 19, 5, 7, 7, 9, 11, 16, 9, 3, 12, 13, 3, 9, 5, 3, 5, 5, 5, 7, 7, 5, 15, 17, 5, 7, 5, 3, 3, 9, 7, 11, 5, 5, 11, 9, 14, 3, 11, 9, 5, 9, 16, 17, 7, 9, 5, 9, 13, 7, 13, 5, 3, 7, 3, 3, 11, 3, 13, 5, 5, 13, 11, 5, 13, 5, 7, 9, 5, 9, 5, 5, 9, 13, 9, 9, 3, 5, 3, 9, 11, 5, 13, 13, 15, 9, 3, 9, 9, 7, 17, 3, 13, 5, 11, 7, 7, 3, 13, 11, 14, 7, 9, 5, 5, 7, 5, 13, 9, 5, 3, 7, 5, 15, 5, 5, 9, 13, 3, 11, 3, 14, 15, 11, 3, 13, 3, 3, 3, 5, 7, 9, 9, 9, 13, 7, 5, 7, 17, 7, 11, 9, 7, 5, 9, 7, 3, 5, 11, 9, 11, 9, 9, 11, 15, 7, 3, 11, 7, 5, 9, 5, 9, 11, 13, 11, 5, 3, 7, 5, 5, 9, 7, 13, 5, 11, 5, 7, 3, 7, 11, 15, 5, 7, 9, 5, 7, 9, 5, 7, 11, 15, 9, 5, 9, 7, 3, 5, 5, 7, 5, 9, 7, 5, 11, 9, 11, 16, 3, 11, 11, 7, 3, 7, 9, 11, 9, 9, 7, 11, 3, 5, 13, 11, 3, 7, 7, 13, 3, 3, 11, 9, 15, 7, 11, 14, 18, 9, 7, 3, 9, 9, 18, 13, 7, 13, 3, 3, 15, 7, 7, 14, 7, 5, 11, 9, 13, 15, 7, 7, 7, 5, 9, 3, 5, 3, 5, 13, 3, 15, 11, 5, 11, 13, 5, 5, 9, 11, 7, 11, 11, 5, 13, 3, 11, 13, 3, 5, 9, 11, 9, 9, 11, 13, 3, 9, 11, 9, 7, 3, 9, 7, 3, 15, 13, 7, 7, 5, 11, 3, 3, 5, 9, 5, 5, 3, 3, 11, 3, 3, 17, 7, 3, 7, 13, 5, 14, 11, 7, 11, 9, 5, 7, 3, 3, 11, 15, 5, 13, 16, 13, 5, 11, 5, 7, 5, 11, 3, 5, 9, 9, 11, 9, 7, 9, 11, 9, 7, 3, 3, 15, 7, 7, 13, 13, 9, 7, 13, 7, 13, 9, 5, 7, 5, 5, 9, 7, 5, 5, 7, 3, 3, 5, 16, 5, 7, 11, 5, 15, 9, 9, 11, 5, 5, 7, 15, 13, 7, 7, 5, 3, 10, 5, 9, 12, 3, 5, 11, 5, 3, 11, 9, 5, 7, 9, 5, 9, 11, 7, 3, 3, 13, 9, 14, 5, 9, 13, 13, 11, 7, 11, 11, 9, 7, 5, 11, 3, 11, 12, 9, 7, 11, 5, 9, 5, 3, 5, 15, 13, 3, 15, 9, 13, 7, 3, 3, 13, 9, 5, 11, 15, 5, 5, 11, 3, 11, 5, 13, 9, 3, 7, 9, 3, 9, 3, 9, 7, 7, 5, 5, 7, 5, 7, 11, 5, 9, 11, 7, 7, 3, 9, 14, 7, 3, 7, 11, 3, 3, 7, 11, 5, 9, 15, 7, 11, 11, 3, 3, 7, 18, 3, 9, 15, 11, 13, 7, 13, 12, 7, 5, 3, 7, 3, 7, 9, 9, 3, 15, 3, 5, 3, 3, 5, 13, 11, 14, 5, 15, 13, 11, 5, 5, 7, 7, 7, 11, 5, 3, 5, 5, 13, 9, 16, 9, 5, 9, 7, 5, 15, 3, 7, 9, 3, 13, 9, 12, 9, 11, 7, 11, 5, 9, 11, 15, 5, 5, 3, 5, 9, 9, 9, 5, 15, 9, 9, 15, 14, 9, 9, 13, 5, 11, 13, 7, 5, 5, 11, 13, 11, 13, 11, 13, 9, 13, 11, 9, 5, 13, 11, 5, 5, 3, 15, 3, 5, 9, 13, 7, 9, 7, 11, 13, 11, 15, 7, 3, 3, 11, 9, 9, 7, 5, 5, 9, 3, 14, 9, 5, 7, 7, 13, 11, 3, 15, 5, 9, 11, 7, 5, 11, 7, 5, 5, 7, 11, 5, 7, 7, 9, 5, 17, 5, 11, 3, 11, 5, 12, 3, 5, 7, 5, 5, 9, 14, 3, 5, 15, 5, 5, 5, 5, 7, 9, 9, 5, 17, 15, 5, 11, 9, 11, 7, 11, 3, 5, 3, 3, 14, 13, 5, 7, 9, 5, 11, 9, 7, 7, 13, 5, 11, 3, 5, 11, 13, 7, 13, 3, 11, 11, 7, 13, 3, 3, 11, 5, 3, 3, 7, 5, 5, 13, 3, 13, 5, 15, 11, 3, 11, 3, 7, 9, 9, 14, 15, 3, 9, 7, 7, 9, 11, 11, 3, 11, 7, 7, 9, 15, 13, 15, 3, 5, 11, 11, 9, 5, 3, 7, 7, 11, 11, 7, 7, 7, 3, 11, 5, 15, 13, 11, 5, 7, 5, 3, 7, 15, 9, 3, 7, 3, 9, 5, 5, 11, 11, 13, 9, 19, 3, 9, 9, 17, 5, 11, 3, 5, 5, 7, 5, 13, 5, 3, 13, 17, 13, 3, 9, 13, 11, 7, 9, 7, 5, 11, 9, 7, 5, 5, 5, 3, 5, 9, 9, 13, 7, 7, 7, 3, 5, 9, 7, 15, 5, 5, 3, 7, 3, 11, 3, 9, 13, 7, 14, 9, 5, 5, 7, 11, 13, 5, 5, 5, 11, 7, 7, 13, 3, 5, 7, 9, 5, 7, 7, 13, 7, 3, 7, 11, 5, 17, 7, 9, 7, 11, 5, 5, 5, 11, 9, 9, 7, 9, 13, 13, 5, 11, 7, 5, 9, 7, 5, 12, 5, 5, 11, 13, 3, 9, 5, 9, 13, 11, 9, 3, 9, 3, 11, 3, 5, 3, 15, 13, 14, 16, 3, 13, 7, 5, 3, 14, 3, 5, 7, 3, 9, 7, 5, 9, 9, 9, 11, 7, 5, 9, 7, 13, 3, 5, 3, 5, 3, 11, 16, 16, 9, 7, 15, 13, 5, 3, 3, 9, 13, 15, 5, 3, 3, 11, 5, 5, 5, 3, 17, 13, 5, 5, 13, 3, 5, 5, 5, 9, 7, 3, 9, 13, 9, 9, 13, 15, 13, 5, 3, 11, 13, 5, 14, 15, 15, 7, 11, 15, 9, 11, 7, 9, 13, 3, 7, 3, 3, 5, 9, 7, 9, 9, 15, 7, 7, 13, 13, 11, 5, 3, 5, 15, 14, 11, 3, 7, 5, 11, 3, 16, 11, 3, 3, 5, 5, 21, 5, 5, 5, 13, 3, 9, 14, 3, 3, 9, 9, 11, 5, 9, 11, 13, 7, 5, 3, 9, 7, 5, 9, 11, 11, 3, 13, 3, 13, 9, 3, 13, 5, 5, 7, 5, 3, 3, 11, 13, 5, 11, 7, 11, 5, 5, 9, 9, 9, 5, 5, 7, 11, 13, 3, 5, 7, 3, 7, 3, 3, 7, 5, 7, 15, 3, 3, 11, 3, 9, 15, 5, 3, 3, 11, 11, 9, 17, 9, 15, 5, 14, 5, 13, 9, 9, 3, 3, 16, 11, 5, 7, 5, 3, 9, 9, 15, 3, 13, 3, 13, 5, 11, 13, 13, 13, 13, 3, 13, 13, 5, 5, 7, 3, 3, 5, 11, 5, 16, 15, 7, 11, 3, 5, 3, 16, 15, 9, 5, 9, 9, 11, 3, 9, 7, 3, 5, 7, 9, 9, 5, 9, 3, 17, 9, 11, 5, 7, 7, 11, 7, 3, 9, 7, 3, 7, 11, 9, 11, 3, 5, 5, 11, 11, 7, 13, 11, 15, 9, 13, 17, 5, 7, 11, 3, 14, 11, 5, 13, 11, 9, 11, 7, 13, 7, 11, 13, 11, 16, 3, 15, 5, 11, 3, 7, 5, 13, 3, 3, 5, 15, 5, 9, 13, 7, 3, 11, 3, 14, 13, 11, 13, 13, 5, 7, 9, 11, 13, 5, 5, 13, 11, 14, 3, 13, 14, 9, 11, 5, 7, 9, 3, 11, 11, 5, 3, 11, 13, 9, 7, 3, 7, 9, 7, 5, 3, 3, 3, 5, 11, 7, 13, 15, 5, 5, 9, 5, 5, 13, 7, 13, 11, 5, 9, 11, 13, 3, 15, 3, 7, 5, 5, 11, 5, 9, 5, 9, 7, 7, 3, 5, 3, 11, 9, 9, 9, 3, 7, 3, 5, 9, 14, 13, 7, 11, 5, 11, 13, 5, 7, 5, 11, 9, 9, 3, 3, 3, 15, 3, 17, 7, 7, 3, 5, 7, 9, 7, 7, 3, 7, 9, 9, 11, 5, 3, 11, 9, 9, 5, 5, 3, 13, 7, 11, 16, 5, 3, 13, 7, 14, 5, 12, 5, 9, 9, 9, 5, 3, 3, 11, 7, 7, 3, 7, 13, 3, 5, 13, 9, 5, 5, 9, 15, 13, 3, 5, 9, 15, 11, 15, 7, 11, 13, 11, 3, 9, 9, 3, 5, 13, 3, 5, 7, 9, 7, 3, 5, 13, 9, 5, 7, 13, 9, 9, 7, 9, 13, 11, 5, 13, 5, 5, 3, 11, 11, 5, 5, 13, 15, 11, 7, 13, 11, 5, 7, 9, 5, 5, 15, 9, 5, 3, 15, 13, 5, 7, 5, 9, 12, 5, 17, 13, 5, 11, 13, 11, 15, 15, 7, 3, 9, 11, 9, 5, 7, 13, 9, 11, 3, 9, 11, 5, 18, 5, 3, 5, 11, 3, 11, 5, 3, 5, 11, 11, 7, 5, 11, 3, 11, 5, 9, 7, 5, 5, 3, 9, 7, 7, 11, 9, 3, 11, 5, 13, 5, 7, 11, 3, 3, 7, 5, 7, 5, 9, 11, 9, 9, 11, 11, 18, 5, 13, 13, 13, 3, 5, 7, 5, 5, 3, 11, 7, 5, 7, 13, 5, 9, 9, 5, 13, 16, 11, 13, 7, 7, 11, 7, 16, 11, 13, 13, 3, 16, 13, 3, 13, 11, 3, 5, 5, 11, 13, 7, 3, 13, 15, 11, 5, 3, 9, 11, 15, 5, 9, 7, 9, 9, 5, 9, 7, 11, 3, 9, 5, 9, 11, 3, 17, 5, 5, 5, 3, 5, 5, 11, 9, 7, 9, 13, 14, 5, 11, 13, 9, 5, 9, 7, 13, 5, 11, 16, 3]\n"]},{"output_type":"stream","name":"stderr","text":["tokenizing...: 100%|██████████| 4173/4173 [00:00<00:00, 11396.38it/s]\n","creating examples: 100%|██████████| 4173/4173 [00:16<00:00, 248.42it/s]"]},{"output_type":"stream","name":"stdout","text":["27 2129\n","[5, 11, 5, 3, 7, 3, 7, 5, 11, 7, 7, 5, 11, 13, 11, 11, 3, 9, 7, 13, 11, 9, 9, 13, 15, 15, 15, 9, 3, 7, 9, 3, 7, 7, 17, 7, 3, 5, 7, 11, 19, 5, 9, 13, 3, 3, 15, 17, 11, 5, 7, 9, 13, 19, 7, 5, 11, 7, 13, 13, 9, 7, 5, 5, 3, 15, 11, 9, 19, 3, 11, 9, 9, 9, 11, 3, 13, 7, 3, 5, 11, 11, 15, 3, 13, 11, 11, 3, 3, 3, 5, 11, 11, 11, 3, 5, 7, 7, 9, 9, 9, 7, 11, 11, 3, 11, 13, 13, 3, 13, 7, 7, 7, 13, 3, 5, 11, 9, 5, 15, 21, 15, 17, 9, 13, 3, 9, 3, 9, 3, 9, 7, 9, 3, 3, 9, 9, 9, 7, 9, 11, 17, 7, 7, 5, 3, 5, 5, 7, 3, 11, 9, 9, 5, 5, 3, 13, 5, 11, 15, 11, 5, 7, 3, 3, 5, 13, 7, 7, 5, 13, 11, 3, 7, 7, 7, 7, 15, 3, 5, 15, 5, 7, 3, 13, 11, 5, 11, 9, 9, 13, 11, 15, 9, 13, 3, 9, 9, 3, 5, 5, 7, 15, 17, 17, 9, 9, 9, 13, 7, 11, 11, 7, 7, 5, 13, 15, 11, 9, 3, 5, 11, 7, 11, 3, 9, 5, 9, 3, 17, 23, 3, 5, 5, 5, 13, 3, 5, 5, 9, 5, 15, 17, 5, 11, 5, 15, 5, 11, 9, 15, 7, 15, 11, 5, 5, 13, 7, 9, 21, 5, 5, 11, 11, 11, 7, 9, 15, 5, 3, 7, 3, 5, 7, 11, 7, 7, 11, 9, 7, 7, 11, 5, 9, 5, 9, 3, 5, 11, 5, 5, 7, 5, 3, 11, 7, 3, 11, 11, 3, 5, 7, 5, 7, 13, 5, 15, 11, 7, 13, 7, 9, 21, 15, 3, 7, 13, 9, 5, 3, 11, 13, 9, 3, 5, 9, 7, 17, 5, 7, 3, 3, 15, 17, 3, 7, 11, 19, 3, 3, 9, 9, 11, 7, 5, 13, 9, 7, 5, 7, 11, 9, 7, 3, 3, 11, 9, 3, 3, 13, 13, 5, 13, 5, 13, 5, 21, 5, 3, 5, 3, 3, 11, 13, 7, 3, 7, 9, 5, 3, 7, 9, 17, 5, 11, 11, 5, 3, 13, 5, 3, 7, 3, 3, 7, 17, 15, 7, 9, 7, 3, 5, 7, 5, 9, 17, 9, 9, 9, 11, 5, 3, 11, 9, 3, 5, 17, 7, 15, 11, 3, 11, 11, 7, 7, 19, 13, 3, 11, 25, 5, 7, 5, 5, 9, 19, 7, 21, 5, 5, 19, 11, 5, 13, 9, 7, 9, 7, 7, 11, 13, 7, 13, 3, 3, 5, 17, 9, 3, 11, 7, 17, 7, 15, 7, 5, 3, 9, 11, 5, 9, 7, 5, 7, 11, 3, 9, 11, 11, 15, 11, 9, 13, 5, 9, 7, 11, 13, 13, 3, 7, 9, 5, 5, 3, 5, 3, 3, 3, 5, 5, 13, 7, 3, 11, 5, 15, 5, 5, 11, 11, 9, 7, 19, 13, 13, 5, 9, 3, 11, 11, 11, 5, 7, 11, 21, 3, 9, 17, 7, 13, 9, 15, 7, 13, 11, 11, 9, 15, 5, 19, 15, 7, 9, 3, 5, 15, 15, 5, 7, 17, 9, 3, 5, 3, 5, 11, 5, 9, 5, 7, 5, 11, 7, 9, 5, 5, 5, 17, 7, 7, 13, 11, 3, 7, 5, 5, 7, 9, 5, 7, 19, 7, 11, 7, 7, 3, 3, 9, 11, 17, 7, 11, 5, 5, 11, 3, 7, 3, 7, 9, 7, 3, 11, 13, 13, 13, 11, 7, 9, 13, 13, 13, 9, 7, 7, 7, 7, 3, 3, 7, 11, 11, 5, 7, 11, 11, 3, 5, 11, 9, 9, 3, 3, 11, 11, 5, 7, 5, 9, 5, 9, 3, 9, 9, 3, 7, 11, 5, 3, 13, 3, 13, 3, 11, 11, 9, 15, 11, 9, 7, 3, 9, 11, 3, 3, 3, 11, 5, 13, 5, 17, 9, 3, 7, 11, 9, 9, 9, 3, 7, 11, 11, 7, 15, 7, 13, 9, 11, 5, 3, 9, 19, 5, 7, 13, 5, 3, 9, 17, 9, 19, 11, 9, 5, 3, 9, 3, 9, 5, 7, 7, 15, 23, 9, 9, 3, 7, 17, 5, 7, 3, 9, 7, 3, 15, 5, 7, 7, 5, 19, 7, 5, 5, 5, 5, 15, 7, 15, 3, 3, 9, 7, 15, 5, 11, 9, 9, 5, 7, 3, 5, 19, 9, 7, 5, 3, 7, 3, 5, 7, 9, 9, 11, 5, 11, 11, 7, 7, 11, 7, 3, 7, 9, 7, 5, 3, 5, 7, 3, 11, 5, 9, 9, 3, 9, 7, 5, 15, 13, 9, 3, 13, 7, 7, 13, 11, 15, 11, 13, 17, 7, 13, 5, 7, 13, 11, 5, 9, 9, 3, 3, 3, 3, 5, 9, 11, 5, 7, 3, 7, 9, 7, 9, 9, 15, 5, 13, 17, 11, 3, 7, 5, 9, 9, 11, 11, 13, 7, 11, 9, 3, 15, 5, 3, 7, 13, 9, 15, 15, 7, 7, 13, 5, 11, 11, 9, 7, 3, 17, 17, 5, 9, 7, 5, 5, 5, 9, 7, 3, 17, 5, 5, 7, 7, 15, 17, 9, 7, 3, 3, 5, 11, 5, 11, 5, 11, 7, 9, 9, 11, 3, 5, 5, 5, 3, 17, 7, 15, 9, 5, 7, 13, 9, 5, 11, 15, 5, 11, 11, 19, 5, 17, 5, 11, 3, 5, 13, 7, 11, 5, 5, 7, 9, 7, 7, 13, 9, 19, 13, 11, 3, 15, 3, 11, 7, 3, 13, 5, 3, 9, 15, 9, 13, 11, 13, 11, 7, 7, 5, 17, 17, 7, 3, 9, 5, 3, 5, 13, 3, 11, 5, 9, 13, 13, 3, 9, 13, 11, 9, 19, 13, 13, 7, 13, 7, 3, 7, 5, 3, 7, 7, 9, 7, 3, 7, 3, 9, 7, 5, 9, 13, 5, 7, 7, 11, 9, 11, 3, 15, 3, 5, 15, 13, 15, 3, 11, 5, 13, 3, 17, 13, 5, 7, 5, 3, 13, 11, 5, 17, 21, 13, 3, 13, 5, 7, 11, 7, 5, 7, 7, 11, 3, 7, 11, 7, 11, 5, 7, 15, 11, 5, 7, 11, 15, 9, 5, 9, 7, 5, 3, 13, 7, 5, 25, 3, 9, 3, 9, 9, 17, 13, 17, 5, 11, 5, 13, 17, 13, 7, 25, 3, 7, 7, 7, 3, 11, 5, 9, 3, 13, 5, 9, 15, 7, 5, 11, 7, 19, 13, 9, 15, 9, 7, 7, 7, 15, 5, 5, 15, 5, 7, 7, 11, 3, 11, 15, 11, 3, 7, 7, 9, 9, 3, 7, 17, 7, 7, 9, 5, 7, 3, 5, 5, 5, 11, 3, 9, 11, 11, 7, 19, 11, 5, 5, 13, 7, 11, 7, 13, 11, 9, 13, 7, 11, 5, 13, 13, 13, 3, 3, 5, 7, 9, 5, 7, 7, 5, 7, 5, 3, 5, 7, 5, 5, 11, 13, 9, 5, 9, 3, 11, 9, 9, 7, 5, 3, 13, 7, 9, 11, 5, 9, 7, 17, 3, 9, 7, 11, 9, 11, 7, 7, 5, 7, 13, 11, 5, 11, 9, 9, 11, 7, 7, 17, 5, 3, 3, 3, 7, 11, 3, 9, 7, 11, 7, 13, 5, 3, 5, 7, 9, 13, 3, 9, 9, 11, 5, 7, 3, 7, 7, 15, 5, 13, 11, 3, 5, 5, 7, 7, 9, 15, 5, 3, 3, 17, 11, 21, 5, 5, 9, 13, 5, 11, 5, 13, 5, 9, 13, 11, 13, 9, 9, 7, 11, 11, 7, 9, 7, 11, 7, 5, 5, 17, 3, 11, 13, 11, 11, 13, 11, 5, 9, 5, 3, 7, 5, 15, 9, 7, 5, 7, 11, 7, 3, 9, 3, 5, 9, 5, 7, 5, 5, 5, 5, 3, 5, 9, 5, 11, 7, 3, 9, 7, 13, 11, 7, 9, 13, 15, 11, 7, 11, 9, 3, 11, 7, 15, 7, 9, 5, 7, 5, 13, 7, 7, 7, 13, 9, 7, 9, 13, 9, 3, 15, 3, 17, 9, 3, 3, 9, 9, 5, 5, 3, 11, 11, 5, 7, 9, 13, 13, 5, 11, 3, 9, 5, 13, 15, 5, 13, 9, 11, 5, 5, 5, 15, 5, 7, 13, 7, 7, 13, 5, 3, 13, 7, 5, 9, 17, 19, 9, 5, 7, 7, 15, 7, 15, 9, 13, 5, 11, 7, 11, 5, 3, 13, 9, 7, 9, 21, 5, 11, 9, 7, 3, 7, 7, 7, 17, 7, 11, 17, 7, 5, 3, 7, 7, 7, 11, 13, 11, 5, 13, 11, 9, 15, 13, 3, 13, 5, 11, 7, 3, 5, 7, 7, 5, 17, 5, 5, 7, 5, 7, 3, 21, 5, 7, 9, 3, 5, 5, 5, 9, 9, 17, 15, 5, 15, 7, 3, 3, 7, 17, 11, 7, 3, 25, 5, 9, 11, 9, 7, 9, 11, 3, 5, 3, 7, 5, 11, 9, 3, 9, 5, 11, 13, 5, 5, 7, 5, 5, 3, 5, 11, 13, 5, 15, 11, 3, 13, 7, 7, 5, 3, 5, 3, 5, 7, 11, 5, 5, 13, 13, 11, 5, 7, 27, 13, 11, 5, 13, 9, 11, 5, 17, 5, 11, 11, 3, 7, 11, 9, 7, 9, 7, 13, 7, 5, 5, 7, 13, 7, 17, 3, 21, 5, 9, 7, 11, 7, 11, 5, 17, 11, 3, 11, 11, 11, 7, 5, 9, 13, 5, 3, 5, 13, 5, 3, 7, 15, 3, 5, 13, 9, 9, 7, 9, 5, 13, 3, 3, 3, 5, 9, 9, 5, 21, 17, 19, 9, 11, 7, 9, 5, 13, 19, 3, 9, 13, 11, 17, 11, 5, 3, 11, 13, 11, 5, 7, 7, 15, 11, 9, 3, 5, 7, 7, 7, 13, 5, 11, 7, 3, 5, 9, 5, 5, 3, 5, 17, 5, 3, 5, 13, 7, 3, 17, 3, 5, 5, 7, 5, 3, 3, 9, 7, 9, 17, 7, 3, 15, 11, 17, 5, 5, 11, 17, 5, 9, 11, 5, 7, 9, 5, 5, 7, 5, 3, 7, 11, 5, 5, 19, 9, 5, 11, 17, 15, 13, 5, 15, 13, 9, 7, 13, 3, 11, 9, 11, 5, 11, 9, 5, 13, 3, 5, 5, 15, 3, 3, 5, 5, 3, 11, 19, 11, 5, 5, 7, 9, 7, 9, 7, 9, 7, 11, 7, 17, 3, 5, 11, 3, 9, 5, 11, 5, 5, 15, 11, 3, 9, 11, 7, 5, 11, 7, 9, 9, 5, 11, 3, 17, 11, 11, 7, 9, 9, 9, 7, 3, 11, 11, 7, 3, 11, 11, 5, 17, 5, 7, 5, 7, 3, 11, 5, 5, 5, 11, 3, 3, 15, 11, 5, 7, 5, 5, 3, 5, 9, 9, 7, 5, 3, 3, 13, 11, 13, 7, 7, 7, 7, 5, 9, 11, 19, 3, 3, 11, 5, 9, 5, 3, 13, 11, 11, 11, 11, 9, 15, 13, 5, 7, 7, 7, 7, 5, 11, 5, 3, 5, 11, 5, 19, 7, 3, 9, 17, 7, 3, 5, 7, 7, 5, 9, 11, 7, 5, 5, 13, 3, 5, 15, 5, 5, 3, 17, 13, 7, 11, 13, 3, 9, 3, 5, 11, 7, 13, 17, 11, 11, 7, 3, 3, 11, 3, 7, 5, 7, 7, 13, 3, 17, 15, 3, 11, 7, 5, 7, 13, 15, 7, 7, 13, 5, 17, 11, 5, 3, 11, 3, 7, 3, 3, 15, 13, 5, 7, 7, 15, 3, 11, 5, 3, 15, 3, 15, 3, 13, 13, 5, 9, 11, 9, 5, 9, 5, 5, 5, 11, 7, 13, 11, 11, 11, 7, 9, 3, 11, 11, 3, 3, 7, 13, 9, 21, 9, 3, 3, 7, 3, 7, 5, 13, 7, 13, 3, 3, 3, 11, 5, 13, 3, 11, 3, 7, 13, 5, 11, 11, 17, 5, 7, 9, 11, 5, 3, 11, 11, 15, 7, 7, 11, 3, 5, 9, 23, 9, 5, 7, 11, 15, 9, 11, 15, 9, 13, 11, 5, 5, 5, 13, 3, 5, 13, 3, 5, 5, 9, 3, 13, 9, 13, 17, 5, 13, 11, 13, 15, 5, 3, 9, 9, 5, 5, 15, 17, 7, 5, 17, 5, 3, 5, 7, 3, 13, 9, 9, 15, 11, 3, 15, 11, 13, 7, 11, 15, 5, 15, 7, 17, 13, 13, 11, 5, 5, 3, 11, 5, 13, 5, 7, 5, 11, 13, 3, 5, 5, 13, 3, 3, 5, 11, 11, 13, 3, 5, 13, 7, 3, 5, 7, 3, 3, 7, 3, 9, 5, 7, 7, 11, 9, 13, 15, 5, 13, 9, 7, 7, 11, 3, 13, 9, 7, 9, 3, 11, 5, 11, 7, 9, 13, 11, 7, 7, 15, 5, 5, 5, 5, 5, 5, 15, 5, 5, 13, 7, 11]\n","20 2129\n","[5, 11, 5, 3, 7, 3, 7, 5, 11, 7, 7, 5, 11, 13, 11, 11, 3, 9, 7, 13, 11, 9, 9, 13, 15, 15, 14, 9, 3, 7, 9, 3, 7, 7, 16, 7, 3, 5, 7, 11, 17, 5, 9, 13, 3, 3, 14, 13, 11, 5, 7, 9, 13, 16, 7, 5, 11, 7, 13, 13, 9, 7, 5, 5, 3, 15, 11, 9, 14, 3, 11, 9, 9, 9, 11, 3, 13, 7, 3, 5, 11, 11, 14, 3, 13, 11, 11, 3, 3, 3, 5, 11, 11, 11, 3, 5, 7, 7, 9, 9, 9, 7, 11, 11, 3, 11, 13, 13, 3, 13, 7, 7, 7, 13, 3, 5, 11, 9, 5, 15, 16, 15, 17, 9, 13, 3, 9, 3, 9, 3, 9, 7, 9, 3, 3, 9, 9, 9, 7, 9, 11, 14, 7, 7, 5, 3, 5, 5, 7, 3, 11, 9, 9, 5, 5, 3, 13, 5, 11, 15, 11, 5, 7, 3, 3, 5, 13, 7, 7, 5, 13, 11, 3, 7, 7, 7, 7, 15, 3, 5, 15, 5, 7, 3, 13, 11, 5, 11, 9, 9, 13, 11, 13, 9, 13, 3, 9, 9, 3, 5, 5, 7, 13, 16, 16, 9, 9, 9, 13, 7, 11, 11, 7, 7, 5, 13, 15, 11, 9, 3, 5, 11, 7, 11, 3, 9, 5, 9, 3, 16, 14, 3, 5, 5, 5, 13, 3, 5, 5, 9, 5, 15, 17, 5, 11, 5, 15, 5, 11, 9, 15, 7, 15, 11, 5, 5, 13, 7, 9, 13, 5, 5, 11, 11, 11, 7, 9, 11, 5, 3, 7, 3, 5, 7, 11, 7, 7, 11, 9, 7, 7, 11, 5, 9, 5, 9, 3, 5, 11, 5, 5, 7, 5, 3, 11, 7, 3, 11, 11, 3, 5, 7, 5, 7, 13, 5, 12, 11, 7, 13, 7, 9, 13, 15, 3, 7, 13, 9, 5, 3, 11, 13, 9, 3, 5, 9, 7, 17, 5, 7, 3, 3, 12, 13, 3, 7, 11, 15, 3, 3, 9, 9, 11, 7, 5, 13, 9, 7, 5, 7, 11, 9, 7, 3, 3, 11, 9, 3, 3, 13, 13, 5, 13, 5, 13, 5, 14, 5, 3, 5, 3, 3, 11, 13, 7, 3, 7, 9, 5, 3, 7, 9, 17, 5, 11, 11, 5, 3, 13, 5, 3, 7, 3, 3, 7, 14, 15, 7, 9, 7, 3, 5, 7, 5, 9, 13, 9, 9, 9, 11, 5, 3, 11, 9, 3, 5, 14, 7, 15, 11, 3, 11, 11, 7, 7, 16, 13, 3, 11, 12, 5, 7, 5, 5, 9, 14, 7, 17, 5, 5, 13, 11, 5, 13, 9, 7, 9, 7, 7, 11, 13, 7, 13, 3, 3, 5, 15, 9, 3, 11, 7, 16, 7, 15, 7, 5, 3, 9, 11, 5, 9, 7, 5, 7, 11, 3, 9, 11, 11, 14, 11, 9, 13, 5, 9, 7, 11, 10, 13, 3, 7, 9, 5, 5, 3, 5, 3, 3, 3, 5, 5, 13, 7, 3, 11, 5, 14, 5, 5, 11, 11, 9, 7, 18, 13, 12, 5, 9, 3, 11, 11, 11, 5, 7, 11, 15, 3, 9, 14, 7, 13, 9, 15, 7, 13, 11, 11, 9, 15, 5, 18, 15, 7, 9, 3, 5, 15, 15, 5, 7, 17, 9, 3, 5, 3, 5, 11, 5, 9, 5, 7, 5, 11, 7, 9, 5, 5, 5, 17, 7, 7, 13, 11, 3, 7, 5, 5, 7, 9, 5, 7, 19, 7, 11, 7, 7, 3, 3, 9, 11, 17, 7, 11, 5, 5, 11, 3, 7, 3, 7, 9, 7, 3, 11, 13, 13, 13, 11, 7, 9, 13, 13, 13, 9, 7, 7, 7, 7, 3, 3, 7, 11, 11, 5, 7, 11, 11, 3, 5, 11, 9, 9, 3, 3, 11, 11, 5, 7, 5, 9, 5, 9, 3, 9, 9, 3, 7, 11, 5, 3, 13, 3, 13, 3, 11, 11, 9, 15, 11, 9, 7, 3, 9, 11, 3, 3, 3, 11, 5, 13, 5, 16, 9, 3, 7, 11, 9, 9, 9, 3, 7, 11, 11, 7, 15, 7, 13, 9, 11, 5, 3, 9, 16, 5, 7, 13, 5, 3, 9, 16, 9, 18, 11, 9, 5, 3, 9, 3, 9, 5, 7, 7, 14, 14, 9, 9, 3, 7, 17, 5, 7, 3, 9, 7, 3, 15, 5, 7, 7, 5, 16, 7, 5, 5, 5, 5, 13, 7, 15, 3, 3, 9, 7, 14, 5, 11, 9, 9, 5, 7, 3, 5, 14, 9, 7, 5, 3, 7, 3, 5, 7, 9, 9, 11, 5, 11, 11, 7, 7, 11, 7, 3, 7, 9, 7, 5, 3, 5, 7, 3, 11, 5, 9, 9, 3, 9, 7, 5, 15, 13, 9, 3, 13, 7, 7, 13, 11, 15, 11, 13, 12, 7, 13, 5, 7, 13, 11, 5, 9, 9, 3, 3, 3, 3, 5, 9, 11, 5, 7, 3, 7, 9, 7, 9, 9, 15, 5, 10, 16, 11, 3, 7, 5, 9, 9, 11, 11, 13, 7, 11, 9, 3, 15, 5, 3, 7, 13, 9, 14, 15, 7, 7, 13, 5, 11, 11, 9, 7, 3, 17, 14, 5, 9, 7, 5, 5, 5, 9, 7, 3, 17, 5, 5, 7, 7, 15, 16, 9, 7, 3, 3, 5, 11, 5, 11, 5, 11, 7, 9, 9, 11, 3, 5, 5, 5, 3, 13, 7, 14, 9, 5, 7, 13, 9, 5, 11, 15, 5, 11, 11, 15, 5, 17, 5, 11, 3, 5, 13, 7, 11, 5, 5, 7, 9, 7, 7, 13, 9, 14, 13, 11, 3, 15, 3, 11, 7, 3, 13, 5, 3, 9, 15, 9, 13, 11, 12, 11, 7, 7, 5, 17, 17, 7, 3, 9, 5, 3, 5, 13, 3, 11, 5, 9, 13, 13, 3, 9, 13, 11, 9, 11, 13, 13, 7, 13, 7, 3, 7, 5, 3, 7, 7, 9, 7, 3, 7, 3, 9, 7, 5, 9, 13, 5, 7, 7, 11, 9, 11, 3, 15, 3, 5, 15, 13, 14, 3, 11, 5, 13, 3, 16, 13, 5, 7, 5, 3, 12, 11, 5, 16, 17, 13, 3, 13, 5, 7, 11, 7, 5, 7, 7, 11, 3, 7, 11, 7, 11, 5, 7, 15, 11, 5, 7, 11, 15, 9, 5, 9, 7, 5, 3, 13, 7, 5, 12, 3, 9, 3, 9, 9, 16, 13, 16, 5, 11, 5, 13, 17, 13, 7, 14, 3, 7, 7, 7, 3, 11, 5, 9, 3, 13, 5, 9, 15, 7, 5, 11, 7, 14, 13, 9, 15, 9, 7, 7, 7, 15, 5, 5, 13, 5, 7, 7, 11, 3, 11, 15, 11, 3, 7, 7, 9, 9, 3, 7, 13, 7, 7, 9, 5, 7, 3, 5, 5, 5, 11, 3, 9, 11, 11, 7, 19, 11, 5, 5, 13, 7, 11, 7, 13, 11, 9, 13, 7, 11, 5, 13, 13, 13, 3, 3, 5, 7, 9, 5, 7, 7, 5, 7, 5, 3, 5, 7, 5, 5, 11, 13, 9, 5, 9, 3, 11, 9, 9, 7, 5, 3, 13, 7, 9, 11, 5, 9, 7, 16, 3, 9, 7, 11, 9, 11, 7, 7, 5, 7, 13, 11, 5, 11, 9, 9, 11, 7, 7, 17, 5, 3, 3, 3, 7, 11, 3, 9, 7, 11, 7, 12, 5, 3, 5, 7, 9, 13, 3, 9, 9, 11, 5, 7, 3, 7, 7, 15, 5, 13, 11, 3, 5, 5, 7, 7, 9, 13, 5, 3, 3, 17, 11, 18, 5, 5, 9, 13, 5, 11, 5, 13, 5, 9, 13, 11, 12, 9, 9, 7, 11, 11, 7, 9, 7, 11, 7, 5, 5, 14, 3, 11, 13, 11, 11, 13, 11, 5, 9, 5, 3, 7, 5, 15, 9, 7, 5, 7, 11, 7, 3, 9, 3, 5, 9, 5, 7, 5, 5, 5, 5, 3, 5, 9, 5, 11, 7, 3, 9, 7, 13, 11, 7, 9, 13, 15, 11, 7, 11, 9, 3, 11, 7, 15, 7, 9, 5, 7, 5, 13, 7, 7, 7, 13, 9, 7, 9, 13, 9, 3, 15, 3, 16, 9, 3, 3, 9, 9, 5, 5, 3, 11, 11, 5, 7, 9, 13, 13, 5, 11, 3, 9, 5, 13, 15, 5, 13, 9, 11, 5, 5, 5, 15, 5, 7, 13, 7, 7, 13, 5, 3, 13, 7, 5, 9, 14, 18, 9, 5, 7, 7, 15, 7, 15, 9, 13, 5, 11, 7, 11, 5, 3, 13, 9, 7, 9, 14, 5, 11, 9, 7, 3, 7, 7, 7, 16, 7, 11, 14, 7, 5, 3, 7, 7, 7, 11, 13, 11, 5, 13, 11, 9, 15, 13, 3, 13, 5, 11, 7, 3, 5, 7, 7, 5, 12, 5, 5, 7, 5, 7, 3, 13, 5, 7, 9, 3, 5, 5, 5, 9, 9, 15, 14, 5, 15, 7, 3, 3, 7, 16, 11, 7, 3, 13, 5, 9, 11, 9, 7, 9, 11, 3, 5, 3, 7, 5, 11, 9, 3, 9, 5, 11, 13, 5, 5, 7, 5, 5, 3, 5, 11, 13, 5, 15, 11, 3, 13, 7, 7, 5, 3, 5, 3, 5, 7, 11, 5, 5, 13, 13, 11, 5, 7, 20, 13, 11, 5, 13, 9, 11, 5, 17, 5, 11, 11, 3, 7, 11, 9, 7, 9, 7, 13, 7, 5, 5, 7, 13, 7, 14, 3, 14, 5, 9, 7, 11, 7, 11, 5, 17, 11, 3, 11, 11, 11, 7, 5, 9, 13, 5, 3, 5, 13, 5, 3, 7, 14, 3, 5, 13, 9, 9, 7, 9, 5, 13, 3, 3, 3, 5, 9, 9, 5, 16, 17, 16, 9, 11, 7, 9, 5, 13, 16, 3, 9, 13, 11, 17, 11, 5, 3, 11, 13, 11, 5, 7, 7, 14, 11, 9, 3, 5, 7, 7, 7, 13, 5, 11, 7, 3, 5, 9, 5, 5, 3, 5, 17, 5, 3, 5, 13, 7, 3, 13, 3, 5, 5, 7, 5, 3, 3, 9, 7, 9, 16, 7, 3, 15, 11, 17, 5, 5, 11, 14, 5, 9, 11, 5, 7, 9, 5, 5, 7, 5, 3, 7, 11, 5, 5, 14, 9, 5, 11, 16, 15, 13, 5, 14, 13, 9, 7, 13, 3, 11, 9, 11, 5, 11, 9, 5, 13, 3, 5, 5, 15, 3, 3, 5, 5, 3, 11, 13, 11, 5, 5, 7, 9, 7, 9, 7, 9, 7, 11, 7, 14, 3, 5, 11, 3, 9, 5, 11, 5, 5, 15, 11, 3, 9, 11, 7, 5, 11, 7, 9, 9, 5, 11, 3, 12, 11, 11, 7, 9, 9, 9, 7, 3, 11, 11, 7, 3, 11, 11, 5, 14, 5, 7, 5, 7, 3, 11, 5, 5, 5, 11, 3, 3, 15, 11, 5, 7, 5, 5, 3, 5, 9, 9, 7, 5, 3, 3, 12, 11, 13, 7, 7, 7, 7, 5, 9, 11, 11, 3, 3, 11, 5, 9, 5, 3, 13, 11, 11, 11, 11, 9, 15, 13, 5, 7, 7, 7, 7, 5, 11, 5, 3, 5, 11, 5, 16, 7, 3, 9, 17, 7, 3, 5, 7, 7, 5, 9, 11, 7, 5, 5, 13, 3, 5, 15, 5, 5, 3, 15, 13, 7, 11, 13, 3, 9, 3, 5, 11, 7, 13, 17, 11, 11, 7, 3, 3, 11, 3, 7, 5, 7, 7, 13, 3, 17, 15, 3, 11, 7, 5, 7, 13, 15, 7, 7, 13, 5, 15, 11, 5, 3, 11, 3, 7, 3, 3, 15, 13, 5, 7, 7, 15, 3, 11, 5, 3, 15, 3, 13, 3, 13, 13, 5, 9, 11, 9, 5, 9, 5, 5, 5, 11, 7, 13, 11, 11, 11, 7, 9, 3, 11, 11, 3, 3, 7, 13, 9, 13, 9, 3, 3, 7, 3, 7, 5, 12, 7, 13, 3, 3, 3, 11, 5, 13, 3, 11, 3, 7, 12, 5, 11, 11, 16, 5, 7, 9, 11, 5, 3, 11, 11, 15, 7, 7, 11, 3, 5, 9, 15, 9, 5, 7, 11, 14, 9, 11, 15, 9, 13, 11, 5, 5, 5, 13, 3, 5, 13, 3, 5, 5, 9, 3, 13, 9, 13, 17, 5, 13, 11, 13, 14, 5, 3, 9, 9, 5, 5, 15, 17, 7, 5, 15, 5, 3, 5, 7, 3, 13, 9, 9, 14, 11, 3, 15, 11, 13, 7, 11, 15, 5, 12, 7, 16, 13, 13, 11, 5, 5, 3, 11, 5, 12, 5, 7, 5, 11, 13, 3, 5, 5, 13, 3, 3, 5, 11, 11, 13, 3, 5, 13, 7, 3, 5, 7, 3, 3, 7, 3, 9, 5, 7, 7, 11, 9, 13, 14, 5, 13, 9, 7, 7, 11, 3, 13, 9, 7, 9, 3, 11, 5, 11, 7, 9, 13, 11, 7, 7, 15, 5, 5, 5, 5, 5, 5, 15, 5, 5, 13, 7, 11]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def get_cls_report(y_true, y_pred):\n","    \"\"\" Get the report of precision, recall, and f1-score for a classification output \"\"\"\n","    return {\"precision\": precision_score(y_true, y_pred, average=None, zero_division=0)[1],\n","            \"recall\": recall_score(y_true, y_pred, average=None, zero_division=0)[1],\n","            \"f1-score\": f1_score(y_true, y_pred, average=None, zero_division=0)[1]}"],"metadata":{"id":"5oCLkLmi4kb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_eval_performance(eval_output_dir, eval_loss, all_preds, all_labels, desc):\n","    \"\"\" Get evaluation performance when the gold labels are available \"\"\"\n","    if task == \"selection\":\n","        def get_eval_performance_selection(all_preds, all_labels, threshold):\n","            report_list, average_precison_list = [], []\n","            all_preds_micro, all_labels_micro = [], []\n","            for preds, labels in zip(all_preds, all_labels):\n","                preds = preds.reshape(-1)\n","                preds_labels = np.zeros_like(preds)\n","                preds_labels[preds > threshold] = 1\n","                average_precison_list.append(average_precision_score(labels, preds))\n","                all_preds_micro.extend(preds_labels)\n","                all_labels_micro.extend(labels)\n","                report_list.append(get_cls_report(labels, preds_labels))\n","\n","            cls_report = get_cls_report(all_labels_micro, all_preds_micro)\n","            result = {\"loss\": eval_loss, \"mean_ave_prec\": np.mean(average_precison_list),\n","                      \"micro_prec\": cls_report['precision'],\n","                      \"micro_recall\": cls_report['recall'],\n","                      \"micro_f1\": cls_report['f1-score'],\n","                      \"macro_prec\": np.mean([report['precision'] for report in report_list]),\n","                      \"macro_recall\": np.mean([report['recall'] for report in report_list]),\n","                      \"macro_f1\": np.mean([report['f1-score'] for report in report_list]),\n","                      \"val_measure\": -1 * np.mean([report['f1-score'] for report in report_list]),\n","                      }\n","            return result\n","\n","        best_result, best_threshold = {\"val_measure\": 0}, None\n","        for threshold in list(np.linspace(-5, 5, num=41)):\n","            result = get_eval_performance_selection(all_preds, all_labels, threshold)\n","            if result['val_measure'] < best_result['val_measure']:\n","                best_result, best_threshold = result, threshold\n","        best_result.update({\"threshold\": best_threshold})\n","        eval_threshold = best_threshold\n","        result = best_result\n","\n","    else:\n","        raise ValueError(\"args.task not in ['generation', 'selection', 'detection'], got %s\" % task)\n","\n","    logger.info(str(result))\n","\n","    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n","    with open(output_eval_file, \"a\") as writer:\n","        logger.info(\"***** Eval results %s *****\" % desc)\n","        writer.write(\"***** Eval results %s *****\\n\" % desc)\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result\n"],"metadata":{"id":"F8G4Pacb4Sxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(eval_dataset, model: PreTrainedModel, run_batch_fn, desc=\"\") -> Dict:\n","    \"\"\" Model evaluation for knowledge seeking turn detection and knowledge selection\n","        Report evaluation results if gold labels are available\n","    \"\"\"\n","    eval_output_dir = output_dir\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","\n","    # eval_batch_size for selection must be 1 to handle different number of candidates\n","    eval_batch_size = 1\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset,\n","        sampler=eval_sampler,\n","        batch_size=eval_batch_size,\n","        collate_fn=eval_dataset.collate_fn\n","    )\n","\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","    data_infos = []\n","    all_preds = []\n","    all_labels = []\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\", disable=False):\n","        with torch.no_grad():\n","            loss, logits, labels = run_batch_fn(model, batch)\n","            if task in [\"selection\", \"detection\"]:\n","                data_infos.append(batch[-1])\n","                all_preds.append((logits[:, 1] - logits[:, 0]).detach().cpu().numpy())\n","                all_labels.append(labels.detach().cpu().numpy())\n","            eval_loss += loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","\n","    if task == \"selection\":\n","        if output_file:\n","            eval_threshold = 0\n","            sorted_pred_ids = [np.argsort(logits.squeeze())[::-1][:(logits > eval_threshold).sum()] for logits in all_preds]\n","            write_selection_preds(eval_dataset.dataset_walker, output_file, data_infos, sorted_pred_ids,\n","                                  all_preds=all_preds)\n","    else:\n","        raise ValueError(\"args.task not in ['generation', 'selection', 'detection'], got %s\" % task)\n","\n","    if not eval_only:\n","        return get_eval_performance(eval_output_dir, eval_loss, all_preds, all_labels, desc)\n"],"metadata":{"id":"RbEse5oB3t0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(train_dataset, eval_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer,\n","          run_batch_fn_train, run_batch_fn_eval) -> Tuple[int, float]:\n","    \"\"\" Model training and evaluation \"\"\"\n","    exp_name = ''\n","    log_dir = os.path.join(\"runs\", exp_name) if exp_name else None\n","    tb_writer = SummaryWriter(log_dir)\n","    output_dir = log_dir\n","\n","    train_batch_size = 4\n","\n","    train_sampler = RandomSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset,\n","        # shuffle=True,\n","        sampler=train_sampler,\n","        batch_size=train_batch_size,\n","        collate_fn=train_dataset.collate_fn\n","    )\n","\n","    gradient_accumulation_steps = 16\n","    num_train_epochs = 3\n","    learning_rate = 3e-5\n","    adam_epsilon = 1e-8\n","    warmup_steps = 500\n","    max_grad_norm = 1.0\n","\n","    t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n","    if 0 < warmup_steps < 1:\n","        warmup_steps = int(warmup_steps * t_total)\n","\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Train!\n","    global_step = 0\n","    model.zero_grad()\n","    train_iterator = trange(\n","        0, int(num_train_epochs), desc=\"Epoch\", disable=False\n","    )\n","    set_seed(42)  # for reproducibility\n","    val_loss = float('inf')\n","\n","    for _ in train_iterator:\n","        local_steps = 0  # update step\n","        tr_loss = 0.0\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n","        step = 0  # backward step\n","        total_log_loss = 0\n","        for _, batch in enumerate(epoch_iterator):\n","            model.train()\n","            for loss, _, _ in run_batch_fn_train(model, batch, global_step=global_step):\n","                step += 1\n","\n","                total_log_loss += loss.item()\n","\n","                if gradient_accumulation_steps > 1:\n","                    loss = loss / gradient_accumulation_steps\n","\n","                loss.backward()\n","                tr_loss += loss.item()\n","\n","                if (step + 1) % gradient_accumulation_steps == 0:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","                    optimizer.step()\n","                    scheduler.step()\n","                    optimizer.zero_grad()\n","                    global_step += 1\n","                    local_steps += 1\n","                    epoch_iterator.set_postfix(Loss=tr_loss / local_steps)\n","                    total_log_loss = 0\n","\n","        results = evaluate(eval_dataset, model, run_batch_fn_eval, desc=str(global_step))\n","\n","\n","        for key, value in results.items():\n","            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","        tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","        tb_writer.add_scalar(\"loss\", tr_loss / local_steps, global_step)\n","\n","        if results['val_measure'] < val_loss:\n","            logger.info(f\"Find a smaller val loss measure {results['val_measure']}\")\n","            val_loss = results['val_measure']\n","            # Save model checkpoint\n","            #save_model(output_dir, model, tokenizer)\n","        else:\n","            logger.info(f\"The val loss measure {results['val_measure']} is larger than \"\n","                        f\"the smallest val loss {val_loss}, continue to train ... \")\n","\n","    tb_writer.flush()\n","    tb_writer.close()\n","\n","    return global_step, tr_loss / local_steps"],"metadata":{"id":"N6Ehw1kc4r-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train 돌리는 코드 "],"metadata":{"id":"RCli0spZ4oEj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# entity matching"],"metadata":{"id":"hMN6z7FQ6_JE"}},{"cell_type":"code","source":["import argparse\n","import os, json\n","import re\n","from difflib import SequenceMatcher as SM\n","from nltk.util import ngrams\n","from nltk.tokenize import word_tokenize\n","import string\n","from multiprocessing import Pool, cpu_count\n","\n","from tqdm import tqdm"],"metadata":{"id":"wjUexlOF7AZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fuzzy_extract(qs, ls, threshold):\n","    \"\"\" Match an entity name (qs) with an utterance (ls) using fuzzy matching \"\"\"\n","    qs_length = len(qs.split())\n","    max_sim_val = 0\n","    max_sim_string = u\"\"\n","\n","    for ngram in ngrams(ls.split(), qs_length + int(.2 * qs_length)):\n","        ls_ngram = u\" \".join(ngram)\n","        similarity = SM(None, ls_ngram, qs).ratio()\n","        if similarity > max_sim_val:\n","            max_sim_val = similarity\n","            max_sim_string = ls_ngram\n","\n","    if max_sim_val > threshold:\n","        return max_sim_string, max_sim_val\n","    else:\n","        return None, max_sim_val\n","\n","\n","def check_substring_exist(qs, ls):\n","    \"\"\" Check if an entity mention (qs) is in an utterance (ls) \"\"\"\n","    if len(qs.split()) > 1:\n","        return qs in ls\n","    else:\n","        return qs in word_tokenize(ls)\n","\n","\n","def entity_matching(entity, log):\n","    \"\"\" Match a single entity with a dialogue history \"\"\"\n","    result = None\n","    max_fuzzy_score = 0\n","\n","    for turn_id, obj in enumerate(log):\n","        flag = False\n","\n","        utter = obj['text'].lower()\n","        if check_substring_exist(entity, utter):\n","            flag = True\n","\n","        entity_names = all_entity_names_norm.get(entity, []) + [entity]\n","        for entity_name in entity_names:\n","            if check_substring_exist(entity_name, utter):\n","                flag = True\n","\n","        # if substring exist, fuzzy_match_score = 1, otherwise fuzzy_match_score < 1\n","        for entity_name in entity_names:\n","            fuzzy_match_res, fuzzy_match_score = fuzzy_extract(entity_name, utter, 0.95)\n","            max_fuzzy_score = max(max_fuzzy_score, fuzzy_match_score)\n","            if fuzzy_match_res is not None:\n","                flag = True\n","\n","        if flag is True:\n","            result = turn_id\n","\n","    return result, max_fuzzy_score\n","\n","\n","def run_entity_matching(args):\n","    \"\"\" Run entity matching for a single instance \"\"\"\n","    idx_, (log, label) = args\n","    if label['target'] is False:\n","        return None, None\n","\n","    matching_res_ls = set()\n","    entity_scores = []\n","    for entity_tup in all_entity_names:\n","        entity_domain, entity_id, entity_name = entity_tup\n","        match_res, match_score = entity_matching(entity_name.lower(), log)\n","        entity_scores.append((entity_tup, match_score))\n","        if match_res is not None:\n","            matching_res_ls.add((entity_domain, entity_id, entity_name, match_res))\n","    matching_res_ls = sorted(list(matching_res_ls), key=lambda x: x[-1])\n","\n","    result = []\n","    if len(matching_res_ls) > 0:\n","        latest_turn_w_entity = matching_res_ls[-1][-1]\n","        for entity_domain, entity_id, entity_name, turn_id in matching_res_ls:\n","            if turn_id == latest_turn_w_entity:\n","                result.append({'domain': entity_domain, 'entity_id': int(entity_id), 'entity_name': entity_name})\n","    else:\n","        entity_scores = sorted(entity_scores, key=lambda x: -x[1])\n","        entity_tup, match_score = entity_scores[0]\n","        entity_domain, entity_id, entity_name = entity_tup\n","        result.append({'domain': entity_domain, 'entity_id': int(entity_id), 'entity_name': entity_name})\n","\n","    pred_entity_set = set([str(r['entity_id']) for r in result])\n","    return result, pred_entity_set"],"metadata":{"id":"7qrzqV5J7CbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read data\n","knowledge_file = os.path.join(dataroot, 'knowledge.json')\n","logs_file = os.path.join(dataroot + '/train', 'logs.json') # data_eval : test set에 대함\n","labels_file = \"/content/drive/MyDrive/dstc11-track5/data/train/labels.json\"\n","\n","with open(logs_file, 'r') as f:\n","    logs = json.load(f)\n","with open(knowledge_file, 'r') as f:\n","    knowledges = json.load(f)\n","with open(labels_file, 'r') as f:\n","    labels = json.load(f)\n","\n","# load entities and normalized entity mentions\n","all_entity_names = []\n","for domain, domain_dict in knowledges.items():\n","    if domain in ['train', 'taxi']:\n","        continue\n","    for doc_id, docs in domain_dict.items():\n","        all_entity_names.append((domain, doc_id, docs['name']))\n","\n","norm_dict = \"/content/drive/MyDrive/dstc11-track5/baseline/resources/entity_mapping.json\"\n","with open(norm_dict, 'r') as fr:\n","    all_entity_names_norm = json.load(fr)\n","\n","# match entities in parallel\n","results = []\n","pred_entity_sets = []\n","with Pool(processes=cpu_count()) as p:\n","    with tqdm(total=len(logs), desc='entity matching') as pbar:\n","        for result, pred_entity_set in p.imap(run_entity_matching, enumerate(zip(logs, labels))):\n","            if result is not None:\n","                results.append(result)\n","                pred_entity_sets.append(pred_entity_set)\n","            else:\n","                results.append(None)\n","            pbar.update()\n","\n","# write the matched entities in output file\n","for label, result in zip(labels, results):\n","    if label['target'] is False:\n","        assert result is None\n","    else:\n","        label['knowledge'] = result\n","\n","with open(output_dir + '/selection_train_em.json', 'w') as fw:\n","    json.dump(labels, fw, indent=4)"],"metadata":{"id":"CPqS97sN7RmU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read data\n","knowledge_file = os.path.join(dataroot, 'knowledge.json')\n","logs_file = os.path.join(dataroot + '/val', 'logs.json') # data_eval : test set에 대함\n","labels_file = \"/content/drive/MyDrive/dstc11-track5/data/val/labels.json\"\n","\n","with open(logs_file, 'r') as f:\n","    logs = json.load(f)\n","with open(knowledge_file, 'r') as f:\n","    knowledges = json.load(f)\n","with open(labels_file, 'r') as f:\n","    labels = json.load(f)\n","\n","# load entities and normalized entity mentions\n","all_entity_names = []\n","for domain, domain_dict in knowledges.items():\n","    if domain in ['train', 'taxi']:\n","        continue\n","    for doc_id, docs in domain_dict.items():\n","        all_entity_names.append((domain, doc_id, docs['name']))\n","\n","norm_dict = \"/content/drive/MyDrive/dstc11-track5/baseline/resources/entity_mapping.json\"\n","with open(norm_dict, 'r') as fr:\n","    all_entity_names_norm = json.load(fr)\n","\n","# match entities in parallel\n","results = []\n","pred_entity_sets = []\n","with Pool(processes=cpu_count()) as p:\n","    with tqdm(total=len(logs), desc='entity matching') as pbar:\n","        for result, pred_entity_set in p.imap(run_entity_matching, enumerate(zip(logs, labels))):\n","            if result is not None:\n","                results.append(result)\n","                pred_entity_sets.append(pred_entity_set)\n","            else:\n","                results.append(None)\n","            pbar.update()\n","\n","# write the matched entities in output file\n","for label, result in zip(labels, results):\n","    if label['target'] is False:\n","        assert result is None\n","    else:\n","        label['knowledge'] = result\n","\n","with open(output_dir + '/selection_val_em.json', 'w') as fw:\n","    json.dump(labels, fw, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YC_vazH7rQ0","executionInfo":{"status":"ok","timestamp":1680947685194,"user_tz":-540,"elapsed":2513756,"user":{"displayName":"이하영","userId":"16656722516517244964"}},"outputId":"12b97e5f-7570-4a71-b96c-85fd5cf09d39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["entity matching: 100%|██████████| 4173/4173 [41:52<00:00,  1.66it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LvKj1RTNHBt2"},"execution_count":null,"outputs":[]}]}